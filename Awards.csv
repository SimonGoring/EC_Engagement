"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"1540938","EarthCube IA: Collaborative Proposal: Advancing biogeoscience community standards and cyberinfrastructure via Critical Zone domain engagement in synthesis science","ICER","EarthCube","09/01/2015","08/18/2015","Aaron Packman","IL","Northwestern University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$99,836.00","","a-packman@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","GEO","8074","7433","$0.00","The Critical Zone (CZ) is the Earth's permeable near-surface layer from the atmosphere at the vegetation's canopy to the lower boundary of actively circulating groundwaters. There has been a recent movement in the US Critical Zone Observatory (CZO) program to promote cross-CZO collaborations, with a major emphasis on biogeochemistry and related microbial ecology research. The project enable the CZ community to use software via training workshops, and better use CZ biogeochemistry and microbial ecology data. These objectives will be accomplished through a set of virtual and in-person workshops where CZ scientists have the opportunity to learn how to use the new cyberinfrastructure products, and use them to synthesize important biogeosciences and microbial ecology data from across numerous CZ sites. This effort will concurrently support the development of community-led standards for data collection and sharing. Direct involvement of software development teams as IA project personnel and collaborators will facilitate the training of members of the CZ community to use newly developed software. CZ scientists will then use these tools in a set of real-life use cases, in the form of synthesis of existing CZO data and analysis of collaboratively designed cross-CZO biogeochemical and metagenomic sample collection and analysis and ancillary measurements. This effort will not only train CZ scientists to use newly emerging EC CI tools, but also solicit community input on software improvements and identify remaining gaps and needs for further EarthCube CI development.<br/><br/>This project lays the groundwork for the whole-earth analysis and simulation capability envisioned through EarthCube, by bringing critical zone scientists together with hands-on training to test available cyberinfrastructure tools with comprehensive multiparameter datasets spanning a wide range of scales. The project will further improve access to the products of critical zone research by promoting the sharing, standardization, synthesis and analysis of biogeochemical and metagenomic data via EarthCube cyberinfrastructure, enabling a broader array of geosciences communities to shape future EarthCube activities and outcomes. This effort will support synthesis of broad swaths of data currently being collected at critical zone sites in the US and worldwide, as well as identify and fill key data gaps. The project will answer key biogeochemistry and microbial ecology questions, such as 1) measuring and modeling the fate of phosphorus during soil formation, and the relative role of bedrock vs. dust inputs to ecosystem phosphorus across diverse systems, and 2) evaluating nutrient availability and its impacts on microbial communities, growth rates and functions, across diverse systems. This project will also facilitate integrative scientific applications using critical zone data. The project will engender broad scientific dissemination of key EarthCube and Critical Zone Observatory products through targeted scientific outreach activities and engagement of diverse types of scientists, including a unique interaction between the computational science and geoscience communities. Key findings will be communicated through collaborative research and synthesis papers and presentations. This project will contribute extensive capacity-building in early-career researchers through targeted workshop participation. Finally, project findings and products will be used to inform future EarthCube development through the activity of the PIs and collaborators in the EarthCube Science Committee and Technology and Architecture Committee, as well as through the broader engagement of critical zone scientists into earthcube activities."
"1440139","EarthCube Building Blocks: Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences","ICER","EarthCube","09/01/2014","08/19/2014","Mark Schildhauer","CA","University of California-Santa Barbara","Standard Grant","Eva E. Zanzerkia","08/31/2017","$481,214.00","Matthew Jones, Krzysztof Janowicz","schild@nceas.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","GEO","8074","7433","$0.00","The proposed work addresses a challenge central to the EarthCube program's success: How to employ state of the art technology for geoscience data discovery, access, and integration. The project brings together significant geosciences holdings in the ocean, earth and polar sciences to demonstrate how innovative technologies can be robustly applied to these facilities to enhance the capabilities for scientists to discover and interpret relevant geoscience data and knowledge. The end product, GEOLink, will lower barriers to cross-repository data discovery and access, while respecting and preserving repository autonomy and heterogeneity. They will demonstrate the approach through a portal that allows searching and browsing of integrated content from multiple repositories.<br/><br/>A key challenge for EarthCube is to enable data discovery, access, and integration in a sustainable way. Existing data repositories and networks must be linked, while retaining their independent missions and services to existing disciplinary communities. Cultural, conceptual, and infrastructural heterogeneities must be respected in order to maintain different perspectives and differing priorities and thus foster inclusivity in the EarthCube endeavor. In particular, individual choices made by providers of data or repositories will need to be respected in an inclusive manner, and approaches to integration must reflect this. At the same time, however, the diversity and heterogeneity of geoscience data presents a significant barrier to its discovery. In this project, the researchers involved will develop a demonstration called GEOLink based on: 1) digital publication of geoscience data and knowledge as ""Linked Open Data""; combined with 2) semantic integration using design patterns and vocabularies shared among federated repositories; and 3) an underlying cyberinfrastructure extendable in both depth and breadth, that can become a central building block for EarthCube data harmonization. The cyberinfrastructure underlying the approach is extendable, sustainable, and affordable - leveraging state of the art developments in Linked Open Data and formal semantics, grounded through shared Ontology Design Patterns. GEOLink-enabled repositories will support discovery of related resources, including Rolling Deck to Repository (R2R), the Biological and Chemical Oceanographic Data Management Office (BCO-DMO), Integrated Earth Data Applications (IEDA), the Long-Term Ecological Research Network (LTER), DataONE, and the International Ocean Discovery Program (IODP), as well content from other EarthCube Building Block projects and collaborators."
"1639753","Earthcube Building Blocks: Collaborative Proposal: Polar Data Insights and Search Analytics for the Deep and Scientific Web","ICER","EarthCube, POLAR CYBERINFRASTRUCTURE","09/01/2016","09/16/2016","Chris Mattmann","CA","University of Southern California","Standard Grant","Marc Stieglitz","08/31/2019","$514,999.00","","mattmann@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","GEO","8074, 5407","7433, 8048","$0.00","This project develops an NSF EarthCube Building Block focused on Polar Data Science. The system will build upon work in Information Retrieval and Data Science and upon existing investment from NSF Polar, EarthCube, and from DARPA and NASA in this area. The system will collect, analyze, and make interactive the wealth of textual and scientific Polar data collected to date across the Deep web of scientific information -- scientific journals, multimedia information, scientific data, web pages, etc. The system builds upon fundamental research in text analysis, search, and visualization. Its primary goal is to unlock unstructured scientific data from 90+ data formats and to scale to 10s-100s of millions of records using the NSF XSEDE supercomputing resources. The system will perform information retrieval and machine learning on data crawled from the Polar Deep and Scientific web. Crawling will be informed by science questions crowdsourced through the EarthCube and Polar communities. The project is a collaboration with NSIDC, Ronin Institute, and the broader community including the newly funded Arctic Data Center led by NCEAS, to build our proposed system.<br/><br/>The result of periodic and regular crawling will be a Crawl Data Repository (CDR) of raw textual data e.g., web pages containing richly curated dataset abstract descriptions, news stories tied to datasets, ASCII note files and dataset descriptions, and other textual data available on or pointed to by Polar repositories as well as scientific data (HDF, Grib, NetCDF, Matlab, etc.). The CDR will be made available for historical and future analysis by the broader EarthCube and Polar communities. In addition, an extraction pipeline will generate an Extraction Data Repository (EDR) of machine learning features not previously present (geospatial, temporal, people, places, scientific publications and topics, etc.) that will be the basis of interactive, visual analytics over the Polar data resources. Information collected will assist in answering scientific questions such as these derived from the President?s National Strategy for the Arctic Region. To date, the team has also crowd sourced 30+ questions from the Polar community represented on CRYOLIST https://goo.gl/4dDyIS and will continue to solicit this feedback and use the information collected to aid science as prioritized by the community. They will also engage the community to assist in validating our system. This is not a predictive tool per-se ? though it can help to enable such predictions. Its focus is on building an operational and core capability for textual scientific data analysis, both retrospective, and prospective."
"1639652","Earthcube Building Blocks: Collaborative Proposal: Polar Data Insights and Search Analytics for the Deep and Scientific Web","ICER","EarthCube, POLAR CYBERINFRASTRUCTURE","09/01/2016","09/16/2016","Ruth Duerr","NJ","Ronin Institute for Independent Scholarship Incorporated","Standard Grant","Marc Stieglitz","08/31/2019","$129,571.00","","ruth.duerr@ronininstitute.org","127 Haddon Place","Montclair","NJ","070432314","9737072485","GEO","8074, 5407","7433","$0.00","This project develops an NSF EarthCube Building Block focused on Polar Data Science. The system will build upon work in Information Retrieval and Data Science and upon existing investment from NSF Polar, EarthCube, and from DARPA and NASA in this area. The system will collect, analyze, and make interactive the wealth of textual and scientific Polar data collected to date across the Deep web of scientific information -- scientific journals, multimedia information, scientific data, web pages, etc. The system builds upon fundamental research in text analysis, search, and visualization. Its primary goal is to unlock unstructured scientific data from 90+ data formats and to scale to 10s-100s of millions of records using the NSF XSEDE supercomputing resources. The system will perform information retrieval and machine learning on data crawled from the Polar Deep and Scientific web. Crawling will be informed by science questions crowdsourced through the EarthCube and Polar communities. The project is a collaboration with NSIDC, Ronin Institute, and the broader community including the newly funded Arctic Data Center led by NCEAS, to build our proposed system.<br/><br/>The result of periodic and regular crawling will be a Crawl Data Repository (CDR) of raw textual data e.g., web pages containing richly curated dataset abstract descriptions, news stories tied to datasets, ASCII note files and dataset descriptions, and other textual data available on or pointed to by Polar repositories as well as scientific data (HDF, Grib, NetCDF, Matlab, etc.). The CDR will be made available for historical and future analysis by the broader EarthCube and Polar communities. In addition, an extraction pipeline will generate an Extraction Data Repository (EDR) of machine learning features not previously present (geospatial, temporal, people, places, scientific publications and topics, etc.) that will be the basis of interactive, visual analytics over the Polar data resources. Information collected will assist in answering scientific questions such as these derived from the President?s National Strategy for the Arctic Region. To date, the team has also crowd sourced 30+ questions from the Polar community represented on CRYOLIST https://goo.gl/4dDyIS and will continue to solicit this feedback and use the information collected to aid science as prioritized by the community. They will also engage the community to assist in validating our system. This is not a predictive tool per-se ? though it can help to enable such predictions. Its focus is on building an operational and core capability for textual scientific data analysis, both retrospective, and prospective."
"1639719","EarthCube Building Blocks: Collaborative Proposal: Deploying Multi-Facility Cyberinfrastructure in Commercial and Private Cloud-based Systems","ICER","EarthCube","09/01/2016","09/15/2016","Timothy Ahern","DC","Incorporated Research Institutions for Seismology","Standard Grant","Eva E. Zanzerkia","08/31/2019","$814,790.00","Chad Trabant","tim@iris.washington.edu","1200 New York Avenue, NW","Washington","DC","200056142","2026822220","GEO","8074","7433","$0.00","It is common to hear that it is optimal to perform computations necessary for the operation of corporations in the ?cloud? and it is true that many commercial companies are moving their information technology into that environment. Scientific data centers funded by the NSF have unique constraints that they must accommodate. Funding is limited and costs of managing data centers using cloud technology can be quite costly. Additionally, government funded research organizations typically have much smaller IT staffs than do corporations. The impact of managing IT operations in the cloud is not identical between large corporations and NSF funded data centers. In the GeoSciCloud project, two medium-size NSF funded data centers plan to deploy data collections along with cloud-based services in different environments in order to assess the feasibility and impact. These environments include:<br/>- Commercial cloud environments such as those offered by Amazon, Google, and Microsoft and<br/>- NSF supported large computing facilities that are just beginning to offer services that have characteristics of cloud computing<br/>The operation of these infrastructures in these two cloud environments will be compared to current in-house environments and assessed.<br/>This project will thereby help NSF/EarthCube identify the most suitable IT environment in which the EarthCube should deploy and support shared infrastructure. The potential reliability and cost-savings are excellent motivating factors.<br/><br/>IRIS and UNAVCO operate data centers with several hundred terabytes of data and services that match our community's needs and requirements. Each organization currently operates its own infrastructure. GeoSciCloud tasks will include moving subsets of our archives, as a test, into commercial cloud and XSEDE cloud environments where we will compare and contrast several aspects of working in different infrastructures. GeoSciCloud partners will also deploy key services developed under the GeoWS building block to enable access to data sets by domain scientists. <br/><br/>GeoSciCloud will help EarthCube compare and contrast the three environments (XSEDE, Commercial Cloud, and current infrastructure) in the following areas:<br/>- Gain an understanding of issues related to the ingestion of large data sets into the cloud and curating the data in a cloud environment.<br/>- Compare processing times for real world requests for data by practicing domain scientists<br/>- Test elasticity of the cloud for doing large amounts of digital signal processing of seismic data and reprocessing GPS solutions for long periods of time.<br/>- Compare the speed of data egress from multiple environments including tests of using higher access systems such as Grid-FTP.<br/>- Compare overall costs of operating in the three environments<br/>- Document what the best practices are that emerge from the GeoSciCloud test that should be promoted within EarthCube.<br/>- Perform conversion of data held in domain formats to more widely used formats such as HDF5 for improved interoperability.<br/>- Test the reliability of streaming real time data into the cloud.<br/>GeoSciCloud will also explore providing some infrastructure in support of other EarthCube partners so that multiple data centers can cohabitate within the GeoSciCloud. IRIS and UNAVCO will commit to ultimately demonstrate the utility of shared infrastructure and how it can improve the efficiency and economics within EarthCube and specifically shared infrastructure in a cloud environment."
"1639775","EarthCube Building Blocks: Collaborative Proposal: EarthCube Data Discovery Hub","ICER","EarthCube","09/01/2016","09/14/2016","Ruth Gates","HI","University of Hawaii","Standard Grant","Eva E. Zanzerkia","08/31/2019","$63,750.00","","rgates@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","GEO","8074","7433, 9150","$0.00","Making data discovery more efficient, comprehensive and user-friendly is a critical challenge articulated by geoscientists as well as researchers in other fields. While information discovery portals and search engines have been developed for many data repositories, and systems that simultaneously search multiple resources have been created, cross-disciplinary data discovery remains a serious issue. It becomes especially acute with rapid increases in the volume and diversity of observations, reflecting different components of the Earth System and collected by multiple research groups, government organizations and commercial companies. The main goal of the EarthCube Data Discovery Hub project is to greatly reduce the time and effort necessary to locate and evaluate geoscience information resources across disciplines, and increase the value of investment in data generation by promoting data reuse and reducing duplication of effort. Project outcomes will benefit a wide group of scientists by providing them a user-friendly and powerful gateway to information resources across multiple data facilities and community contributions, and mechanisms for improving the system to answer their research queries in a consistent manner. The project will also benefit geoscience research in several ecosystems that are being used as examples to test the data tools being developed, including rivers, coral reefs and other marine ecosystems, and the critical zone where rock, soil, water, air and living organisms interact.<br/>The EarthCube Data Discovery Hub will be developed as a comprehensive data discovery and content enhancement system, which will leverage improved and community-curated metadata descriptions and integrate previously unregistered information sources. The project will further extend, improve and operationalize the inventory catalog developed in an earlier CINERGI (Community Inventory of EarthCube Resources for Geoscience Interoperability) project, which currently includes over 2 million metadata documents from multiple sources. The key technological innovations include: pioneering the development of an automated cross-domain metadata augmentation and curation pipeline enabled by a large integrated geoscience ontology; mechanisms for ?deep registration? of geoscience data from different sources based on a novel data type registry; an online use case management system; and a methodology for processing several types of complex geoscience queries that cannot be answered by existing systems. In addition, the project will support scientific progress in several representative cross-disciplinary research scenarios, using the contexts of river geochemistry, coral reef and other marine ecosystem analysis, and critical zone science. The project will implement innovative community engagement mechanisms, including community annotation of automatically curated metadata, iterative improvement of geoscience ontology based on community feedback, and joint development of cross-disciplinary use cases semantically aligned with data descriptions."
"1639764","EarthCube Building Blocks: Collaborative Proposal: EarthCube Data Discovery Hub","ICER","EarthCube","09/01/2016","09/14/2016","Ilya Zaslavsky","CA","University of California-San Diego","Standard Grant","Eva E. Zanzerkia","08/31/2019","$1,104,750.00","Karen Stocks, Amarnath Gupta, Jeffrey Grethe","zaslavsk@sdsc.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","GEO","8074","7433","$0.00","Making data discovery more efficient, comprehensive and user-friendly is a critical challenge articulated by geoscientists as well as researchers in other fields. While information discovery portals and search engines have been developed for many data repositories, and systems that simultaneously search multiple resources have been created, cross-disciplinary data discovery remains a serious issue. It becomes especially acute with rapid increases in the volume and diversity of observations, reflecting different components of the Earth System and collected by multiple research groups, government organizations and commercial companies. The main goal of the EarthCube Data Discovery Hub project is to greatly reduce the time and effort necessary to locate and evaluate geoscience information resources across disciplines, and increase the value of investment in data generation by promoting data reuse and reducing duplication of effort. Project outcomes will benefit a wide group of scientists by providing them a user-friendly and powerful gateway to information resources across multiple data facilities and community contributions, and mechanisms for improving the system to answer their research queries in a consistent manner. The project will also benefit geoscience research in several ecosystems that are being used as examples to test the data tools being developed, including rivers, coral reefs and other marine ecosystems, and the critical zone where rock, soil, water, air and living organisms interact.<br/>The EarthCube Data Discovery Hub will be developed as a comprehensive data discovery and content enhancement system, which will leverage improved and community-curated metadata descriptions and integrate previously unregistered information sources. The project will further extend, improve and operationalize the inventory catalog developed in an earlier CINERGI (Community Inventory of EarthCube Resources for Geoscience Interoperability) project, which currently includes over 2 million metadata documents from multiple sources. The key technological innovations include: pioneering the development of an automated cross-domain metadata augmentation and curation pipeline enabled by a large integrated geoscience ontology; mechanisms for ?deep registration? of geoscience data from different sources based on a novel data type registry; an online use case management system; and a methodology for processing several types of complex geoscience queries that cannot be answered by existing systems. In addition, the project will support scientific progress in several representative cross-disciplinary research scenarios, using the contexts of river geochemistry, coral reef and other marine ecosystem analysis, and critical zone science. The project will implement innovative community engagement mechanisms, including community annotation of automatically curated metadata, iterative improvement of geoscience ontology based on community feedback, and joint development of cross-disciplinary use cases semantically aligned with data descriptions."
"1440170","EarthCube Building Blocks: Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences","ICER","EarthCube","09/01/2014","08/19/2014","Douglas Fils","DC","Consortium for Ocean Leadership, Inc","Standard Grant","Eva E. Zanzerkia","08/31/2017","$189,416.00","","dfils@oceanleadership.org","1201 New York Avenue, N W.","Washington","DC","200056108","2024481236","GEO","8074","7433","$0.00","The proposed work addresses a challenge central to the EarthCube program's success: How to employ state of the art technology for geoscience data discovery, access, and integration. The project brings together significant geosciences holdings in the ocean, earth and polar sciences to demonstrate how innovative technologies can be robustly applied to these facilities to enhance the capabilities for scientists to discover and interpret relevant geoscience data and knowledge. The end product, GEOLink, will lower barriers to cross-repository data discovery and access, while respecting and preserving repository autonomy and heterogeneity. They will demonstrate the approach through a portal that allows searching and browsing of integrated content from multiple repositories.<br/><br/>A key challenge for EarthCube is to enable data discovery, access, and integration in a sustainable way. Existing data repositories and networks must be linked, while retaining their independent missions and services to existing disciplinary communities. Cultural, conceptual, and infrastructural heterogeneities must be respected in order to maintain different perspectives and differing priorities and thus foster inclusivity in the EarthCube endeavor. In particular, individual choices made by providers of data or repositories will need to be respected in an inclusive manner, and approaches to integration must reflect this. At the same time, however, the diversity and heterogeneity of geoscience data presents a significant barrier to its discovery. In this project, the researchers involved will develop a demonstration called GEOLink based on: 1) digital publication of geoscience data and knowledge as ""Linked Open Data""; combined with 2) semantic integration using design patterns and vocabularies shared among federated repositories; and 3) an underlying cyberinfrastructure extendable in both depth and breadth, that can become a central building block for EarthCube data harmonization. The cyberinfrastructure underlying the approach is extendable, sustainable, and affordable - leveraging state of the art developments in Linked Open Data and formal semantics, grounded through shared Ontology Design Patterns. GEOLink-enabled repositories will support discovery of related resources, including Rolling Deck to Repository (R2R), the Biological and Chemical Oceanographic Data Management Office (BCO-DMO), Integrated Earth Data Applications (IEDA), the Long-Term Ecological Research Network (LTER), DataONE, and the International Ocean Discovery Program (IODP), as well content from other EarthCube Building Block projects and collaborators."
"1540966","EarthCube IA: Oceans of Data: Bringing EarthCube to the Science User","ICER","EarthCube","09/01/2015","08/18/2015","Karen Stocks","CA","University of California-San Diego Scripps Inst of Oceanography","Standard Grant","Eva E. Zanzerkia","08/31/2017","$436,815.00","Stephen Diggs","kstocks@ucsd.edu","8602 La Jolla Shores Dr","LA JOLLA","CA","920930210","8585341293","GEO","8074","7433","$0.00","The ability to find, access, and visualize data is critical to many kinds of oceanographic research, as well as to teaching oceanography. Yet ocean data is held in multiple data facilities, in different formats, and is accessible through different pathways. This creates practical problems with integrating and working across different data sets. The SeaView project is building connections between the rich data resources in five major oceanographic data facilities - R2R, BCO-DMO, CCHDO, OBIS and OOI* - and an ocean data visualization and exploration tool, the Ocean Data View (ODV), having over 40,000 registered users. To do so, it is leveraging from NSF investments into two previous EarthCube projects: CINERGI, as the registry where users will find and access data they wish to use, and GeoLink, which is providing interconnections between existing data resources, allowing users to explore a knowledge base of related information. SeaView leverages existing resources to provide improved tools and data access in support of fundamental research in two areas of ocean sciences: deep water hydrography and marine community-environment interactions. Both feed directly into research identified by the 2015 Decadal Survey of Ocean Sciences as of the highest priority. It will also engage scientists from currently underrepresented communities in EarthCube.<br/><br/>The specific oceanographic communities targeted are deep water hydrographers and marine ecologists, particularly those studying species interactions with the environment. Near the start of the project, a set of three focus groups and a Science Drivers workshop composed of end-user scientists from these communities will prioritize the specific datasets and develop science scenarios (use cases). They will meet again mid-stream for hands-on testing of the tool and feedback. The CINERGI registry will be used to expose ODV-supported formats from these repositories to ODV. The EarthCube GeoLink knowledge base will provide links to additional content (investigators, publications, etc.) for cruise-related datasets loaded in ODV."
"1344384","Collaborative Project: EarthCube Domain End-User Workshop: Developing a Community Vision of Cyberinfrastructure Needs for Coral Reef Systems Science","OCE","EarthCube","08/01/2013","08/09/2013","Ruth Gates","HI","University of Hawaii","Standard Grant","Michael Sieracki","07/31/2015","$34,329.00","","rgates@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","GEO","8074","7433","$0.00","The Geosciences EarthCube program recognizes the importance of aligning cyber-infrastructure activities with the needs of end user research communities. To that end we propose to convene 50-70 members of the coral reef community in two workshops, one held at the University of Hawaii (HIMB) and the other at the University of California Santa Barbara National Center for Ecological Analysis and Synthesis (NCEAS). The specific objectives of the workshop are to: <br/><br/>1. Define current and future (5-15 years) scientific challenges in the field<br/><br/>2. Summarize data and cyber-infrastructure constraints that prevent these challenges being realized<br/><br/>3. Collate current community data and modeling resources and their locations<br/><br/>4. Identify and recommend data infrastructure that could facilitate rapidly addressing the scientific challenges in the field<br/><br/>The coral reef research community is multidisciplinary and the data on reefs is diverse and complex, crossing biological scales from genes to ecosystems, temporal scales from nanoseconds to millennia, and spatial scales from nanometers to kilometers. The challenge is to integrate across these data sources to identify patterns and relationships that rapidly improve our understanding of coral reefs systems. This effort has been hindered to date by the lack of tools to accomplish this and ineffective means of sharing data or collaborating. This project will support workshops that engage the coral reef community to 1) develop a common vision of the grand science challenges in the field 2) highlight how data cyber-infrastructure needs will integrate the complex datasets and potentially facilitate rapid progress in key areas of coral reefs ecosystem science and 3) emphasize the value of collaboration and data sharing as a first step to changing and improving the way coral reef scientists support each other and advance the field.<br/><br/>As ecosystem engineers, corals provide the nutritional, economic, and structural basis of<br/>an ecosystem worth billions of dollars annually. This workshop proposal convenes the coral reef community and will address how cyber-infrastructure can inform coral reef systems science. The latter will ultimately accelerate understanding of reef ecosystems, broaden the scope of the questions that can be asked and build capacity to predict how these societally relevant and fragile ecosystems will face the challenges of climate change and human development. The workshops will also be attended by at least 4 postdocs and represents a significant professional development opportunity for these individuals. Results will be disseminated on the EarthCube website, the NCEAS website, and the HIMB website making them broadly accessible to the science, education and the public. The product from the proposed endeavor will be a report to NSF EarthCube summarizing the discussion for each of these objectives that will serve to define and align the needs across the Geosciences and help prioritize EarthCube activities. There is also an opportunity to use the results to develop a manuscript that articulates how cyber-infrastructure can address the science challenges facing the coral reef community and facilitate a systems level science agenda. Such a product could have high value in both the science funding and policy realm."
"1540998","EarthCube IA: Collaborative Proposal: EarthCube Integration & Test Environment","ICER","EarthCube","09/01/2015","09/09/2015","Chaowei Yang","VA","George Mason University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$144,364.00","","cyang3@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","GEO","8074","7433","$0.00","EarthCube is supporting the creation of interoperable tools and services for Earth science research, but no environment currently exists for integration and testing of these components. The EarthCube Integration and Test Environment (ECITE), an outgrowth of activities of the EarthCube Testbed Working Group. The ECITE approach focuses on integrating existing effective technologies and resources as well as capabilities being built by the EarthCube community to provide a federated and interoperable test environment. ECITE?s nationwide cyberinfrastructure for the geosciences will also advance the understanding of regional cyberinfrastructure and collaborative geosciences across geographic locations and disciplines by contributing relevant scheduling tools and a working integration and testing environment. A hallmark of the ECITE effort will be engagement of scientists and technologists from multiple disciplines and geographic regions across the geosciences community to develop requirements, prototype, design, build, and test an integration test-bed that will support cross-disciplinary research. The multi-disciplinary ECITE team is led by Sara Graves of the University of Huntsville in Alabama (UAH) and includes participants from all areas of the United States. ECITE activities will enable EarthCube to further support other members and contribute leadership to the broader scientific community. The ECITE federated Integration and Test (I&T) environment has the potential to scale and extend to an NSF wide integration and test capability that can serve as a model and example for other agencies. The proposed ECITE functionality is vital to ensure that the broader goals of the EarthCube are achieved.<br/><br/>The ECITE team will actively engage EarthCube and the wider geosciences community in definition of requirements, design, and testing of the system. ECITE will consist of a seamless federated system of scalable and location independent distributed computational resources (nodes) across the US. The hybrid federated system will provide a robust set of distributed resources to include both public and private cloud capabilities. The nodes will provide compute and storage resources requiring minimal system administration.ECITE is an important step in ensuring that EarthCube components will be able to work together to provide a successful framework that can continue to evolve to meet the needs of the geosciences community. This research addresses timely issues of integration, test and evaluation methodologies and best practices with a strong interoperability theme to advance disciplinary research through the integration of diverse and heterogeneous data, algorithms, systems and sciences. The results and findings will provide guidance for EarthCube evolution and future integration efforts. The ECITE team aims to make the Integration and Test (I&T) environment easy to use and readily available to the EarthCube community. Access to the resulting platform will enable and encourage the EarthCube community to develop prototypes, try out new technologies, and to share ideas, concepts and experiments"
"1238061","EarthCube Community Workshop: Designing A Roadmap for Workflows in Geosciences","EAR","IIS SPECIAL PROJECTS, Software Institutes, EarthCube","04/01/2012","03/27/2012","Marlon Pierce","IN","Indiana University","Standard Grant","Barbara L. Ransom","03/31/2013","$14,999.00","Chathura Herath, Suresh Marru","marpierc@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","GEO","7484, 8004, 8074","7433","$0.00","EarthCube is focused on community-driven development of an integrated and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive, process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems. This awards funds a series of broad, inclusive community interactions to gather adequate information and requirements to create a roadmap for a critical capability (workflow) in the development of EarthCube, a major new NSF initiative. Workflow in the context of EarthCube, and cyberinfrastructure in general, encompasses a broad range of topics including distributed execution management, the coupling of multiple models into composite applications, the integration of a wide range of data sources with processing, and the creation of refined data products from raw data. A key benefit of the funded work in terms of evaluating and creating community consensus on the best way forward for this capability (i.e., workflow) is the ability to document the provenance of data used in modeling and reproduce model and data-enabled scientific results. The funded workshop and information collecting activity will be open to all interested parties and is being led by a diverse and expert team of cyberinfrastructure developers, computer scientists, and geoscientists. Broader impacts of the work include converging on approaches, protocols, and standards that may be applicable across the sciences. They also include the fostering of close interaction between communities that do not commonly interact with one another and focusing them on the common goal of creating a new paradigm in data and knowledge management in the geosciences."
"1313870","Collaborative Project: EarthCube Education End-User Workshop","ICER","EarthCube","02/01/2013","01/17/2013","Cheryl Peach","CA","University of California-San Diego Scripps Inst of Oceanography","Standard Grant","Jill L. Karsten","01/31/2014","$52,998.00","","cpeach@ucsd.edu","8602 La Jolla Shores Dr","LA JOLLA","CA","920930210","8585341293","GEO","8074","","$0.00","This award is being used to convene a workshop of ~40 participants to define end-user needs related to geoscience education within the EarthCube initiative. The workshop brings together disciplinary faculty in the geosciences, educators experienced in teaching with geoscience data and developing associated curricula, representatives of NSF-sponsored research programs involved with generation of large data sets, as well as technologists, STEM education researchers, and learning scientists. The workshop is being held at the Scripps Forum (Scripps Institution of Oceanography) during the Spring of 2013. The workshop seeks to explore both the educational opportunities offered through the cyberinfrastructure capabilities of the EarthCube program and identify the educational needs for preparing undergraduate students and faculty to be the future contributors to the scientific research enabled by EarthCube. A major goal of this workshop is to establish an initial roadmap for educational activities that should be associated with or enabled by EarthCube. The workshop will consider the educational and instructional strategies not only to prepare students in undergraduate programs to be technologically-savvy users of EarthCube data and models, but also to build the future scientific capacity to advance Earth systems scientific research. Consideration will also be given to how EarthCube may serve as a platform for advancing STEM education research."
"1343813","EarthCube Conceptual Design: Enterprise Architecture for Transformative Research and Collaboration Across the Geosciences","ICER","EarthCube","09/15/2013","09/03/2015","Ilya Zaslavsky","CA","University of California-San Diego","Standard Grant","Eva E. Zanzerkia","08/31/2016","$313,640.00","Amarnath Gupta","zaslavsk@sdsc.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","GEO","8074","7433","$0.00","EarthCube design is a complex socio-technical systemof systems, in which communication between various domain subsystems and previously disconnected CI components,people and organizations enables more comprehensive, data-intensive research designs and knowledge sharing. The main features of project include an approach that:(1) follows and enhances existing patterns of data, information and knowledge exchange within and between geoscience domains, (2) integrates ?traditional? layered cyberinfrastructure components (e.g.information sources, catalogs, vocabularies, services, analysis and modeling tools) with CI components supporting scholarly communication, self-organization and social networking (e.g.research profiles, Q&A systems, annotations) and (3) supports continuous EarthCube architectural<br/>evolution. The proposed work will be done in close collaboration with other EarthCube activities,taking input from a wide group of geoscientists and CI experts engaged in EarthCube, as well as information system architects from a range of academic and commercial projects.Design parameters include system abilities to: a) evolve by factoring in the impact of maturing movements like linked<br/>data, ?big data?, and social collaborations; b) handle the volume, complexity and diversity of geoscience information; (b) incorporate new informational and analytical requirements, tools, and techniques,(c)accommodate different ideas and approaches to research and data stewardship;(d)make best use of NSFs current investment in the geoscience CI.<br/><br/>The innovative aspect of this architecture planning will include three component. It will be designed as a system of systems,i.e., the basic information objects and infrastructure of any community will be re-used, but will be modeled in a manner that higher-level operations(e.g., vocabulary mashup) can be performed on them. It will be based on emerging interchange practices and protocols for scholarly objects, a paradigm that will be designed to foster inter-community research collaboration and exchange. It will be centered on a social network of communicating scientists who will use the interchange protocols. The social network will consist of both people and the information objects they choose to share as they conduct research."
"1342148","EarthCube Domain End-User Workshop: Engaging the Atmospheric Cloud/Aerosol/Composition Community","AGS","EarthCube","07/01/2013","06/26/2013","Liping Di","VA","George Mason University","Standard Grant","Sylvia A. Edgerton","06/30/2014","$99,850.00","Akua Asa-Awuku, Athanasios Nenes, Stefan Falke","ldi@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","GEO","8074","7433, 1524","$0.00","A workshop will be held to support U.S. scientists who are conducting research on atmospheric aerosol and cloud interactions to assist with forming a community consensus on what capabilities and functional requirements might be needed to assist with the development of a common cyber-based infrastructure for the geosciences. This workshop is part of a series of geoscience domain end-user workshops to solicit the needs and requirements from end-user groups of EarthCube so that those needs and requirements can be addressed in the EarthCube design and implementation.<br/><br/>EarthCube is a community-driven activity sponsored through a partnership between the NSF Directorate of Geosciences and Office of Cyberinfrastructure to transform the conduct of geosciences research and education. EarthCube aims to create a well-connected and facile environment to share data and knowledge in an open, transparent, and inclusive manner, thus accelerating the ability of the geosciences community to understand and predict the Earth system."
"1341418","EarthCube Domain End-User Workshop: Engaging the Ocean Science -Omics Community to Archive, Access, and Analyze Massively Parallel Environmental Genomic Data","OCE","EarthCube","07/15/2013","07/02/2013","Katrina Edwards","CA","University of Southern California","Standard Grant","Antonius Post","06/30/2014","$94,918.00","Edward DeLong, E. Virginia Armbrust, John Heidelberg","kje@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","GEO","8074","1650, 7433, 9117","$0.00","Genomics, bioinformatics, and allied technologies are having wide-sweeping and dramatic impact on observation and experimentation in ocean science. ""Omics"" technologies and approaches are being rapidly adopted and employed by the ocean science research community. ""Omics"" are being broadly and effectively used in areas that include mapping the distributions of taxa and biogeography, time series analyses and biogeochemistry, regional process studies, assessing environmental change and anthropogenic impacts, and ecosystem modeling. Rapidly evolving technologies combined with exponentially decreasing costs have ""democratized"" DNA sequencing and are enabling the generation of massive ocean ""omic"" datasets by individual researchers, and collaborative efforts by the ocean science community as a whole. These massive ""omic"" datasets and their associated metadata require new cyberinfrastructures (CI) that can coordinate and facilitate data and metadata access, analyses, and modeling. The NSF EarthCube initiative recently solicited proposals for domain workshops ""designed to listen to the needs of the end-user groups that make up the geosciences and to understand better how data-enabled science can help them achieve their scientific goals."" This workshop will bring together ocean scientists and computer scientists to inform and engage them about EarthCube activities with the following objectives:<br/>1. Inform and engage 40-45 ocean scientists with CI experience and/or needs, and explore potential Earth cube opportunities to help solve common CI challenges and needs for ocean ""omic"" data mining and analyses.<br/>2. Inform and engage 10-15 bioinformatic and CI scientists about ocean ""omics"" needs and applications and opportunities in EarthCube activities to help address them.<br/>The overall goal of the workshop would be to develop a set of unifying CI requirements of ocean ""omic"" scientists, that could integrate their data and efforts, and connect and engage both domain and cyber scientists to pursue cyber solutions for ocean ""omics"" analyses.<br/>Intellectual Merit :<br/>The workshop will engage of a broad ""omic"" data user group in the ocean science community that stands to benefit from understanding new cyber-infrastructure possibilities, envisioning present and future solutions to their current needs and engaging in the EarthCube process. The EarthCube cyberscience community will benefit from understanding the challenges and needs of a broad, rapidly evolving, multidisciplinary group of ocean science omic and environmental data users.<br/>Broader Impacts :<br/>Cyber-infrastructure developed for ocean ""omic"" scientists have potential for broad public impact. Examples include improved infrastructures to develop more accurate climate models that incorporate biological processes, improve our understanding of the effects of environmental change, expand our knowledge of life in extreme habitats, and better assess ecosystem structure, function and dynamics."
"1540909","EarthCube IA: Collaborative Proposal: Interdisciplinary Earth Data Alliance as a Model for Integrating Earthcube Technology Resources and Engaging the Broad Community","ICER","EarthCube","09/01/2015","08/19/2015","Samuel Soule","MA","Woods Hole Oceanographic Institution","Standard Grant","Eva E. Zanzerkia","08/31/2017","$30,417.00","","ssoule@whoi.edu","183 OYSTER POND ROAD","WOODS HOLE","MA","025431041","5082893542","GEO","8074","7433","$0.00","A fundamental requirement for EarthCube is access to a comprehensive spectrum of well-curated, reliably re-usable, and seamlessly interoperable scientific data, but this does not exist today with many Geoscience domains still lacking sustainable data services. This project is a collaboration between an established data facility in the solid Earth sciences, IEDA (Interdisciplinary Earth Data Alliance), three scientifically related data communities in the solid Earth sciences that lack data facilities (deep seafloor processes, mineral physics, polar cryosphere), a research data collection (MetPetDB), a group of computer scientists that specialize in distributed information systems and interoperability, and a social scientist to re-structure the IEDA data facility, both organizationally and architecturally, to create the pilot of a multi-institutional and multi-disciplinary alliance of data providers. The goal is to create a model for other data facilities to partner with so far ?underserved? data communities to broaden integration of Geoscience domains into EarthCube, and advance both interdisciplinary and discipline-specific data science, while realizing economies of scale by sharing common data services. <br/><br/>Using IEDA as a testbed, the project will adopt elements of three EarthCube technologies that have been or are being developed by EarthCube Building Block projects: CINERGI (Community INventory of EarthCube Resources for Geoscience Interoperability), GeoWS (Geoscience Web Services), and GeoLink (Semantic Web technology), to build the architecture of the alliance, thereby testing, validating, and potentially improving these technologies. The technical work will focus on creating a flexible and scalable framework that will allow a growing number of partner systems to plug into shared capabilities such as applications for integrated data discovery and data submission and contribute their resources. Architectural changes at IEDA will go hand-in-hand with the transition of IEDA?s organizational structure toward the envisioned multi-institutional alliance."
"1229928","RAPID: Stakeholder Alignment for EarthCube","ACI","VIRTUAL ORGANIZATIONS, EarthCube","03/01/2012","02/23/2012","Joel Cutcher-Gershenfeld","IL","University of Illinois at Urbana-Champaign","Standard Grant","Kevin Crowston","02/28/2014","$129,030.00","Michael Haberman, Joseph Mark Nolan","joelcg@brandeis.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","7642, 8074","7433, 7642, 7914, 7969","$0.00","Large-scale collaborative science is of increasing importance, but relatively little empirical evidence is available to guide the creation and operation of these multi-stakeholder efforts. Previous social science research on stakeholder alignment in industrial relations and organizational studies is only now beginning to be applied to scientific consortia. Early results indicate that social science tools and methods can play a key role in enabling coordinated, cross-organizational alignment. New techniques for identifying stakeholders, assessing interests, and visualizing alignment are beginning to emerge, but require additional refinement. This is a time-bound, demonstration case for applying stakeholder alignment methods initially advanced under the NSF study of 'Stakeholder Alignment in Socio-Technical Systems' (NSF-VOSS 0956472). This case will demonstrate new ways for stakeholders in complex systems to better visualize and analyze core interests (common and conflicting) in order to more quickly and more comprehensively achieve the alignment needed for understanding and action. It is anticipated that this application of the methods will highlight needed areas for further instrumentation, validation, and enhancement.<br/><br/>The NSF EarthCube initiative represents a novel approach to rapid development of community-guided cyber infrastructure to integrate data and information for knowledge management across the Geosciences. Optimizing these activities will require a deep understanding of stakeholder interests, including points of alignment (or misalignment). This project will identify EarthCube stakeholders and their interests and develop, administer, and analyze the results of an initial stakeholder alignment survey to assess the state of the EarthCube cyber infrastructure, geoscience, and computer science communities prior to the planned June community meeting. Timely feedback on this survey will be central to the success of the overall EarthCube effort, and enable longitudinal analysis of changes as the EarthCube process moves from separate communities, through the initial organization of emergent interdisciplinary teams and eventual community integration. Stakeholder alignment is hypothesized to play an important role in community coalescence and team development and to affect the likelihood of successfully defining system requirements and building prototypes. This project provides an opportunity to test the applicability of innovative stakeholder alignment techniques to emerging geo-sciences, cyber infrastructure and computer science partnerships focused on developing common frameworks for sharing research data.<br/><br/>Improved stakeholder alignment will substantially enhance the success and impact of EarthCube. The resulting cyber infrastructure will create value and mitigate risk in domains touched by the geosciences. Further, based on this demonstration case, applications to a wide range of NSF investments may be appropriate. These tools and methods for stakeholder alignment represent potentially high impact enablers across our societal institutions that are of ever greater importance in an era of accelerating change."
"1256163","Envisioning Success: A Workshop for Next Generation EarthCube Scholars and Scientists","ACI","EarthCube","10/01/2012","09/12/2012","Joel Cutcher-Gershenfeld","IL","University of Illinois at Urbana-Champaign","Standard Grant","Amy Walton","09/30/2013","$99,978.00","","joelcg@brandeis.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","8074","7433","$0.00","The diversity of data and data types in the geosciences and their dispersal among various academic institutions and federal agencies, all of which have their own data formats and associated search and discovery criteria have prevented maximum effective utilization of this tremendous wealth of information. To ameliorate this situation, a new NSF initiative, called EarthCube, which is jointly funded by the Directorate of Geosciences and the Office of Cyberinfrastructure, was initiated in 2011 to create an interoperable and integrated data and knowledge management for the geo- and environmental sciences. An integral part of the process is geoscience and cyberinfrastructure community engagement, at all levels, to ensure that EarthCube's final design and implementation serves all end user needs. Crucial to the success of EarthCube is its ability to serve the future needs of geoscientists and its ability to scale to new developments in computer science and technology. To enable input from early career geo-and cyber scientists, a workshop, focused on the expected career trajectory of early career scientists likely to be end users and infrastructure developers, has been funded to examine their needs and to project into the future how these early career professionals envision how EarthCube will impact their science and career trajectories. The workshop is being held at the Carnegie Institution of Washington. It is being hosted by a diverse team of convenors and is focused on collecting input from this crucial early career demographic. The two-day workshop will involve participants from 41 different disciplines within the geo and cyber sciences from around the US. Broader impacts of the work include providing key stakeholder input into the design of a major NSF activity focused on building infrastructure for science and engaging early career scientists in the process."
"1541044","EarthCube IA: Collaborative Proposal: Advancing biogeoscience community standards and cyberinfrastructure via Critical Zone domain engagement in synthesis science","ICER","EarthCube","09/01/2015","08/18/2015","Emilio Mayorga","WA","University of Washington","Standard Grant","Eva E. Zanzerkia","08/31/2017","$65,000.00","","mayorga@apl.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","GEO","8074","7433","$0.00","The Critical Zone (CZ) is the Earth's permeable near-surface layer from the atmosphere at the vegetation's canopy to the lower boundary of actively circulating groundwaters. There has been a recent movement in the US Critical Zone Observatory (CZO) program to promote cross-CZO collaborations, with a major emphasis on biogeochemistry and related microbial ecology research. The project enable the CZ community to use software via training workshops, and better use CZ biogeochemistry and microbial ecology data. These objectives will be accomplished through a set of virtual and in-person workshops where CZ scientists have the opportunity to learn how to use the new cyberinfrastructure products, and use them to synthesize important biogeosciences and microbial ecology data from across numerous CZ sites. This effort will concurrently support the development of community-led standards for data collection and sharing. Direct involvement of software development teams as IA project personnel and collaborators will facilitate the training of members of the CZ community to use newly developed software. CZ scientists will then use these tools in a set of real-life use cases, in the form of synthesis of existing CZO data and analysis of collaboratively designed cross-CZO biogeochemical and metagenomic sample collection and analysis and ancillary measurements. This effort will not only train CZ scientists to use newly emerging EC CI tools, but also solicit community input on software improvements and identify remaining gaps and needs for further EarthCube CI development.<br/><br/>This project lays the groundwork for the whole-earth analysis and simulation capability envisioned through EarthCube, by bringing critical zone scientists together with hands-on training to test available cyberinfrastructure tools with comprehensive multiparameter datasets spanning a wide range of scales. The project will further improve access to the products of critical zone research by promoting the sharing, standardization, synthesis and analysis of biogeochemical and metagenomic data via EarthCube cyberinfrastructure, enabling a broader array of geosciences communities to shape future EarthCube activities and outcomes. This effort will support synthesis of broad swaths of data currently being collected at critical zone sites in the US and worldwide, as well as identify and fill key data gaps. The project will answer key biogeochemistry and microbial ecology questions, such as 1) measuring and modeling the fate of phosphorus during soil formation, and the relative role of bedrock vs. dust inputs to ecosystem phosphorus across diverse systems, and 2) evaluating nutrient availability and its impacts on microbial communities, growth rates and functions, across diverse systems. This project will also facilitate integrative scientific applications using critical zone data. The project will engender broad scientific dissemination of key EarthCube and Critical Zone Observatory products through targeted scientific outreach activities and engagement of diverse types of scientists, including a unique interaction between the computational science and geoscience communities. Key findings will be communicated through collaborative research and synthesis papers and presentations. This project will contribute extensive capacity-building in early-career researchers through targeted workshop participation. Finally, project findings and products will be used to inform future EarthCube development through the activity of the PIs and collaborators in the EarthCube Science Committee and Technology and Architecture Committee, as well as through the broader engagement of critical zone scientists into earthcube activities."
"1639675","EarthCube Building Blocks: Collaborative Proposal: Polar Data Insights and Search Analytics for the Deep and Scientific Web","ICER","EarthCube, POLAR CYBERINFRASTRUCTURE","09/01/2016","09/16/2016","Siri Jodha Khalsa","CO","University of Colorado at Boulder","Standard Grant","Marc Stieglitz","08/31/2019","$294,999.00","","khalsa@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","GEO","8074, 5407","7433, 1079","$0.00","This project develops an NSF EarthCube Building Block focused on Polar Data Science. The system will build upon work in Information Retrieval and Data Science and upon existing investment from NSF Polar, EarthCube, and from DARPA and NASA in this area. The system will collect, analyze, and make interactive the wealth of textual and scientific Polar data collected to date across the Deep web of scientific information -- scientific journals, multimedia information, scientific data, web pages, etc. The system builds upon fundamental research in text analysis, search, and visualization. Its primary goal is to unlock unstructured scientific data from 90+ data formats and to scale to 10s-100s of millions of records using the NSF XSEDE supercomputing resources. The system will perform information retrieval and machine learning on data crawled from the Polar Deep and Scientific web. Crawling will be informed by science questions crowdsourced through the EarthCube and Polar communities. The project is a collaboration with NSIDC, Ronin Institute, and the broader community including the newly funded Arctic Data Center led by NCEAS, to build our proposed system.<br/><br/>The result of periodic and regular crawling will be a Crawl Data Repository (CDR) of raw textual data e.g., web pages containing richly curated dataset abstract descriptions, news stories tied to datasets, ASCII note files and dataset descriptions, and other textual data available on or pointed to by Polar repositories as well as scientific data (HDF, Grib, NetCDF, Matlab, etc.). The CDR will be made available for historical and future analysis by the broader EarthCube and Polar communities. In addition, an extraction pipeline will generate an Extraction Data Repository (EDR) of machine learning features not previously present (geospatial, temporal, people, places, scientific publications and topics, etc.) that will be the basis of interactive, visual analytics over the Polar data resources. Information collected will assist in answering scientific questions such as these derived from the President?s National Strategy for the Arctic Region. To date, the team has also crowd sourced 30+ questions from the Polar community represented on CRYOLIST https://goo.gl/4dDyIS and will continue to solicit this feedback and use the information collected to aid science as prioritized by the community. They will also engage the community to assist in validating our system. This is not a predictive tool per-se ? though it can help to enable such predictions. Its focus is on building an operational and core capability for textual scientific data analysis, both retrospective, and prospective."
"1639557","EarthCube Building Blocks: Collaborative Proposal: EarthCube Data Discovery Hub","ICER","EarthCube","09/01/2016","09/14/2016","Bernhard Peucker-Ehrenbrink","MA","Woods Hole Oceanographic Institution","Standard Grant","Eva E. Zanzerkia","08/31/2019","$76,502.00","","behrenbrink@whoi.edu","183 OYSTER POND ROAD","WOODS HOLE","MA","025431041","5082893542","GEO","8074","7433","$0.00","Making data discovery more efficient, comprehensive and user-friendly is a critical challenge articulated by geoscientists as well as researchers in other fields. While information discovery portals and search engines have been developed for many data repositories, and systems that simultaneously search multiple resources have been created, cross-disciplinary data discovery remains a serious issue. It becomes especially acute with rapid increases in the volume and diversity of observations, reflecting different components of the Earth System and collected by multiple research groups, government organizations and commercial companies. The main goal of the EarthCube Data Discovery Hub project is to greatly reduce the time and effort necessary to locate and evaluate geoscience information resources across disciplines, and increase the value of investment in data generation by promoting data reuse and reducing duplication of effort. Project outcomes will benefit a wide group of scientists by providing them a user-friendly and powerful gateway to information resources across multiple data facilities and community contributions, and mechanisms for improving the system to answer their research queries in a consistent manner. The project will also benefit geoscience research in several ecosystems that are being used as examples to test the data tools being developed, including rivers, coral reefs and other marine ecosystems, and the critical zone where rock, soil, water, air and living organisms interact.<br/>The EarthCube Data Discovery Hub will be developed as a comprehensive data discovery and content enhancement system, which will leverage improved and community-curated metadata descriptions and integrate previously unregistered information sources. The project will further extend, improve and operationalize the inventory catalog developed in an earlier CINERGI (Community Inventory of EarthCube Resources for Geoscience Interoperability) project, which currently includes over 2 million metadata documents from multiple sources. The key technological innovations include: pioneering the development of an automated cross-domain metadata augmentation and curation pipeline enabled by a large integrated geoscience ontology; mechanisms for ?deep registration? of geoscience data from different sources based on a novel data type registry; an online use case management system; and a methodology for processing several types of complex geoscience queries that cannot be answered by existing systems. In addition, the project will support scientific progress in several representative cross-disciplinary research scenarios, using the contexts of river geochemistry, coral reef and other marine ecosystem analysis, and critical zone science. The project will implement innovative community engagement mechanisms, including community annotation of automatically curated metadata, iterative improvement of geoscience ontology based on community feedback, and joint development of cross-disciplinary use cases semantically aligned with data descriptions."
"1541022","Earthcube IA: Collaborative Proposal: Interdisciplinary Earth Data Alliance as a Model for Integrating Earthcube Technology Resources and Engaging the Broad Community","ICER","EarthCube","09/01/2015","08/19/2015","Kerstin Lehnert","NY","Columbia University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$418,614.00","Leslie Hsu, Vicki Ferrini, Suzanne Carbotte","lehnert@ldeo.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","GEO","8074","7433","$0.00","A fundamental requirement for EarthCube is access to a comprehensive spectrum of well-curated, reliably re-usable, and seamlessly interoperable scientific data, but this does not exist today with many Geoscience domains still lacking sustainable data services. This project is a collaboration between an established data facility in the solid Earth sciences, IEDA (Interdisciplinary Earth Data Alliance), three scientifically related data communities in the solid Earth sciences that lack data facilities (deep seafloor processes, mineral physics, polar cryosphere), a research data collection (MetPetDB), a group of computer scientists that specialize in distributed information systems and interoperability, and a social scientist to re-structure the IEDA data facility, both organizationally and architecturally, to create the pilot of a multi-institutional and multi-disciplinary alliance of data providers. The goal is to create a model for other data facilities to partner with so far ?underserved? data communities to broaden integration of Geoscience domains into EarthCube, and advance both interdisciplinary and discipline-specific data science, while realizing economies of scale by sharing common data services. <br/><br/>Using IEDA as a testbed, the project will adopt elements of three EarthCube technologies that have been or are being developed by EarthCube Building Block projects: CINERGI (Community INventory of EarthCube Resources for Geoscience Interoperability), GeoWS (Geoscience Web Services), and GeoLink (Semantic Web technology), to build the architecture of the alliance, thereby testing, validating, and potentially improving these technologies. The technical work will focus on creating a flexible and scalable framework that will allow a growing number of partner systems to plug into shared capabilities such as applications for integrated data discovery and data submission and contribute their resources. Architectural changes at IEDA will go hand-in-hand with the transition of IEDA?s organizational structure toward the envisioned multi-institutional alliance."
"1541047","EarthCube IA: Collaborative Proposal: Advancing biogeoscience community standards and cyberinfrastructure via Critical Zone domain engagement in synthesis science","ICER","EarthCube","09/01/2015","08/18/2015","Emma Aronson","CA","University of California-Riverside","Standard Grant","Eva E. Zanzerkia","08/31/2017","$627,995.00","","emma.aronson@ucr.edu","Office of Research","RIVERSIDE","CA","925211000","9518275535","GEO","8074","7433","$0.00","The Critical Zone (CZ) is the Earth's permeable near-surface layer from the atmosphere at the vegetation's canopy to the lower boundary of actively circulating groundwaters. There has been a recent movement in the US Critical Zone Observatory (CZO) program to promote cross-CZO collaborations, with a major emphasis on biogeochemistry and related microbial ecology research. The project enable the CZ community to use software via training workshops, and better use CZ biogeochemistry and microbial ecology data. These objectives will be accomplished through a set of virtual and in-person workshops where CZ scientists have the opportunity to learn how to use the new cyberinfrastructure products, and use them to synthesize important biogeosciences and microbial ecology data from across numerous CZ sites. This effort will concurrently support the development of community-led standards for data collection and sharing. Direct involvement of software development teams as IA project personnel and collaborators will facilitate the training of members of the CZ community to use newly developed software. CZ scientists will then use these tools in a set of real-life use cases, in the form of synthesis of existing CZO data and analysis of collaboratively designed cross-CZO biogeochemical and metagenomic sample collection and analysis and ancillary measurements. This effort will not only train CZ scientists to use newly emerging EC CI tools, but also solicit community input on software improvements and identify remaining gaps and needs for further EarthCube CI development.<br/><br/>This project lays the groundwork for the whole-earth analysis and simulation capability envisioned through EarthCube, by bringing critical zone scientists together with hands-on training to test available cyberinfrastructure tools with comprehensive multiparameter datasets spanning a wide range of scales. The project will further improve access to the products of critical zone research by promoting the sharing, standardization, synthesis and analysis of biogeochemical and metagenomic data via EarthCube cyberinfrastructure, enabling a broader array of geosciences communities to shape future EarthCube activities and outcomes. This effort will support synthesis of broad swaths of data currently being collected at critical zone sites in the US and worldwide, as well as identify and fill key data gaps. The project will answer key biogeochemistry and microbial ecology questions, such as 1) measuring and modeling the fate of phosphorus during soil formation, and the relative role of bedrock vs. dust inputs to ecosystem phosphorus across diverse systems, and 2) evaluating nutrient availability and its impacts on microbial communities, growth rates and functions, across diverse systems. This project will also facilitate integrative scientific applications using critical zone data. The project will engender broad scientific dissemination of key EarthCube and Critical Zone Observatory products through targeted scientific outreach activities and engagement of diverse types of scientists, including a unique interaction between the computational science and geoscience communities. Key findings will be communicated through collaborative research and synthesis papers and presentations. This project will contribute extensive capacity-building in early-career researchers through targeted workshop participation. Finally, project findings and products will be used to inform future EarthCube development through the activity of the PIs and collaborators in the EarthCube Science Committee and Technology and Architecture Committee, as well as through the broader engagement of critical zone scientists into earthcube activities."
"1541036","EarthCube IA: Collaborative Proposal: Interdisciplinary Earth Data Alliance as a Model for Integrating Earthcube Technology Resources and Engaging the Broad Community","ICER","EarthCube","09/01/2015","08/19/2015","Przemyslaw Dera","HI","University of Hawaii","Standard Grant","Eva E. Zanzerkia","08/31/2017","$34,922.00","","pdera@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","GEO","8074","7433, 9150","$0.00","A fundamental requirement for EarthCube is access to a comprehensive spectrum of well-curated, reliably re-usable, and seamlessly interoperable scientific data, but this does not exist today with many Geoscience domains still lacking sustainable data services. This project is a collaboration between an established data facility in the solid Earth sciences, IEDA (Interdisciplinary Earth Data Alliance), three scientifically related data communities in the solid Earth sciences that lack data facilities (deep seafloor processes, mineral physics, polar cryosphere), a research data collection (MetPetDB), a group of computer scientists that specialize in distributed information systems and interoperability, and a social scientist to re-structure the IEDA data facility, both organizationally and architecturally, to create the pilot of a multi-institutional and multi-disciplinary alliance of data providers. The goal is to create a model for other data facilities to partner with so far ?underserved? data communities to broaden integration of Geoscience domains into EarthCube, and advance both interdisciplinary and discipline-specific data science, while realizing economies of scale by sharing common data services. <br/><br/>Using IEDA as a testbed, the project will adopt elements of three EarthCube technologies that have been or are being developed by EarthCube Building Block projects: CINERGI (Community INventory of EarthCube Resources for Geoscience Interoperability), GeoWS (Geoscience Web Services), and GeoLink (Semantic Web technology), to build the architecture of the alliance, thereby testing, validating, and potentially improving these technologies. The technical work will focus on creating a flexible and scalable framework that will allow a growing number of partner systems to plug into shared capabilities such as applications for integrated data discovery and data submission and contribute their resources. Architectural changes at IEDA will go hand-in-hand with the transition of IEDA?s organizational structure toward the envisioned multi-institutional alliance."
"1541049","EarthCube IA: Collaborative Proposal: EarthCube Integration & Test Environment","ICER","EarthCube","09/01/2015","09/09/2015","Stanislav Djorgovski","CA","California Institute of Technology","Standard Grant","Eva E. Zanzerkia","08/31/2017","$144,529.00","","george@astro.caltech.edu","1200 E California Blvd","PASADENA","CA","911250600","6263956219","GEO","8074","7433","$0.00","EarthCube is supporting the creation of interoperable tools and services for Earth science research, but no environment currently exists for integration and testing of these components. The EarthCube Integration and Test Environment (ECITE), an outgrowth of activities of the EarthCube Testbed Working Group. The ECITE approach focuses on integrating existing effective technologies and resources as well as capabilities being built by the EarthCube community to provide a federated and interoperable test environment. ECITE?s nationwide cyberinfrastructure for the geosciences will also advance the understanding of regional cyberinfrastructure and collaborative geosciences across geographic locations and disciplines by contributing relevant scheduling tools and a working integration and testing environment. A hallmark of the ECITE effort will be engagement of scientists and technologists from multiple disciplines and geographic regions across the geosciences community to develop requirements, prototype, design, build, and test an integration test-bed that will support cross-disciplinary research. The multi-disciplinary ECITE team is led by Sara Graves of the University of Huntsville in Alabama (UAH) and includes participants from all areas of the United States. ECITE activities will enable EarthCube to further support other members and contribute leadership to the broader scientific community. The ECITE federated Integration and Test (I&T) environment has the potential to scale and extend to an NSF wide integration and test capability that can serve as a model and example for other agencies. The proposed ECITE functionality is vital to ensure that the broader goals of the EarthCube are achieved.<br/><br/>The ECITE team will actively engage EarthCube and the wider geosciences community in definition of requirements, design, and testing of the system. ECITE will consist of a seamless federated system of scalable and location independent distributed computational resources (nodes) across the US. The hybrid federated system will provide a robust set of distributed resources to include both public and private cloud capabilities. The nodes will provide compute and storage resources requiring minimal system administration.ECITE is an important step in ensuring that EarthCube components will be able to work together to provide a successful framework that can continue to evolve to meet the needs of the geosciences community. This research addresses timely issues of integration, test and evaluation methodologies and best practices with a strong interoperability theme to advance disciplinary research through the integration of diverse and heterogeneous data, algorithms, systems and sciences. The results and findings will provide guidance for EarthCube evolution and future integration efforts. The ECITE team aims to make the Integration and Test (I&T) environment easy to use and readily available to the EarthCube community. Access to the resulting platform will enable and encourage the EarthCube community to develop prototypes, try out new technologies, and to share ideas, concepts and experiments"
"1541039","EarthCube IA: Collaborative Proposal: EarthCube Integration & Test Environment","ICER","EarthCube","09/01/2015","09/09/2015","Sara Graves","AL","University of Alabama in Huntsville","Standard Grant","Eva E. Zanzerkia","08/31/2017","$211,104.00","Kenneth Keiser","sgraves@itsc.uah.edu","301 Sparkman Drive","Huntsville","AL","358051911","2568246120","GEO","8074","7433, 9150","$0.00","EarthCube is supporting the creation of interoperable tools and services for Earth science research, but no environment currently exists for integration and testing of these components. The EarthCube Integration and Test Environment (ECITE), an outgrowth of activities of the EarthCube Testbed Working Group. The ECITE approach focuses on integrating existing effective technologies and resources as well as capabilities being built by the EarthCube community to provide a federated and interoperable test environment. ECITE?s nationwide cyberinfrastructure for the geosciences will also advance the understanding of regional cyberinfrastructure and collaborative geosciences across geographic locations and disciplines by contributing relevant scheduling tools and a working integration and testing environment. A hallmark of the ECITE effort will be engagement of scientists and technologists from multiple disciplines and geographic regions across the geosciences community to develop requirements, prototype, design, build, and test an integration test-bed that will support cross-disciplinary research. The multi-disciplinary ECITE team is led by Sara Graves of the University of Huntsville in Alabama (UAH) and includes participants from all areas of the United States. ECITE activities will enable EarthCube to further support other members and contribute leadership to the broader scientific community. The ECITE federated Integration and Test (I&T) environment has the potential to scale and extend to an NSF wide integration and test capability that can serve as a model and example for other agencies. The proposed ECITE functionality is vital to ensure that the broader goals of the EarthCube are achieved.<br/><br/>The ECITE team will actively engage EarthCube and the wider geosciences community in definition of requirements, design, and testing of the system. ECITE will consist of a seamless federated system of scalable and location independent distributed computational resources (nodes) across the US. The hybrid federated system will provide a robust set of distributed resources to include both public and private cloud capabilities. The nodes will provide compute and storage resources requiring minimal system administration.ECITE is an important step in ensuring that EarthCube components will be able to work together to provide a successful framework that can continue to evolve to meet the needs of the geosciences community. This research addresses timely issues of integration, test and evaluation methodologies and best practices with a strong interoperability theme to advance disciplinary research through the integration of diverse and heterogeneous data, algorithms, systems and sciences. The results and findings will provide guidance for EarthCube evolution and future integration efforts. The ECITE team aims to make the Integration and Test (I&T) environment easy to use and readily available to the EarthCube community. Access to the resulting platform will enable and encourage the EarthCube community to develop prototypes, try out new technologies, and to share ideas, concepts and experiments"
"1343661","EarthCube Conceptual Design: A Scalable Community Driven Architecture","ICER","EarthCube","06/15/2014","06/09/2014","Stanislav Djorgovski","CA","California Institute of Technology","Standard Grant","Eva E. Zanzerkia","05/31/2017","$299,994.00","Daniel Pilone","george@astro.caltech.edu","1200 E California Blvd","PASADENA","CA","911250600","6263956219","GEO","8074","7433","$0.00","The PIs develop a conceptual architecture for the EarthCube program. The conceptual architecture<br/>will serve as the blueprint for the definition, construction, and deployment of both existing<br/>and new components to ensure that they can be unified and integrated into a evolutionary national<br/>infrastructure for EarthCube. They intend to create a concept that incorporates findings and<br/>requirements from ongoing EarthCube activities as well as other cross-agency Earth Science<br/>informatics efforts. The architecture models will be a roadmap for building an extensible<br/>and sustainable EarthCube system that facilitates new science and inspires substantive participation<br/>of a broad spectrum of geoscientists. The project team is led by a group of computer scientists<br/>from National Aeronautics and Space Administration (NASA) and private industry that has extensive<br/>experience and a proven track record leading the architecture, design and development of complex<br/>and data intensive science data systems. They will specifically focus on the development of<br/>a guiding architecture report and specification. <br/><br/>The results of this EarthCube architecture study can intellectually<br/>contribute to other scientific and agency efforts as they are studying new architectural models<br/>to address scientific data management and discovery in the big data era."
"1266399","Shaping the Development of EarthCube to Enable Advances in Data Assimilation and Ensemble Prediction Workshop; Boulder, Colorado; December 17-18, 2012","AGS","EarthCube","12/15/2012","11/08/2012","Mohan Ramamurthy","CO","University Corporation For Atmospheric Res","Standard Grant","A. Gannet Hallar","11/30/2013","$41,225.00","","mohan@ucar.edu","3090 Center Green Drive","Boulder","CO","803012252","3034971000","GEO","8074","1525, 4444, 9145, OTHR","$0.00","Intellectual Merit: <br/>Data intensive science has rapidly emerged as the Fourth Paradigm of scientific discovery after empirical, theoretical, and computational methods. This is particularly true in the area of data assimilation and ensemble prediction. Yet, significant barriers exist in using the data efficiently or integrating them into data assimilation or ensemble prediction systems as the scientific community lacks easy-to-use common cyberinfrastructure frameworks. By some estimates, researchers may spend 80 percent of their time dealing with data discovery, access, and processing, and only 20 percent ""doing science"" by way of interpretation, synthesis, and knowledge creation.<br/><br/>The goal of the National Science Foundation's EarthCube initiative is to transform the conduct of research by supporting the development of community-guided cyberinfrastructure. It is critical that EarthCube is both shaped by as well as benefits the different scientific communities to which it is targeted.<br/><br/>This project will fund a workshop to bring the research, education, and information technology communities together to discuss some of the science, technology and cyberinfrastructure issues related to distributed but shared mesoscale modeling, data assimilation, and ensemble prediction. The title of the workshop, which is planned to be held 17-18 December 2012 in Boulder, CO, is ""Shaping the Development of EarthCube to Enable Advances in Data Assimilation and Ensemble Prediction.""<br/><br/>One of the goals of the workshop is to shape the development of EarthCube and help in building a cyberinfrastructure and work toward a scientific ecosystem in which ""data friction"" is reduced, and data transparency and ease-of-use are significantly increased. We believe achieving the workshop goals will help mesoscale ensemble prediction and data assimilation communities to work toward a transformation in the conduct of data-centric research and education. To that end, we would like to assemble a team from across the country to develop a multi-institutional, multi-model, multi-data-assimilation regional scale ensemble prediction and analysis system that is capable of real-time forecasts, as well as historical reanalysis. It is anticipated that workshop participants will come from U. S. universities, NCAR and UCAR, NOAA, NSF, and other research organizations.<br/><br/>Broad Impacts: <br/>There is an urgent need for educating and training the next generation of students in mesoscale modeling, data assimilation, ensemble and probabilistic forecasting in the United States. The workshop will engage students pursuing careers in the aforementioned three areas of research. It is envisioned that the products from the planned data assimilation and ensemble prediction systems will be readily accessed by a broad community of university researchers, students and educators for exploring dynamics, physics of the atmosphere, as well as for educating the next generation of students to gain knowledge and expertise in advanced numerical weather prediction topics. The real-time ensemble prediction system can be used as a complementary tool by operational forecasters, especially in terms of probabilistic forecasting of severe weather and tropical cyclones. Finally, this workshop will help build capacity among the community of researchers and users of ensemble prediction and data assimilation and will foster further collaborative efforts to advance research in mesoscale meteorology."
"1252238","EarthCube Domain End-User Workshop: Engaging the Critical Zone community to bridge long tail science with big data","EAR","EarthCube","10/01/2012","09/26/2012","Anthony Aufdenkampe","PA","Stroud Water Research Center","Standard Grant","Enriqueta Barrera","09/30/2013","$99,922.00","Gregory Tucker, Christopher Duffy","aufdenkampe@stroudcenter.org","970 Spencer Road","Avondale","PA","193119514","6102682153","GEO","8074","7433","$0.00","Critical Zone (CZ) scientists take as their charge the effort to integrate theory, models and data from the multitude of disciplines studying processes on the Earth's surface - from the atmosphere at the vegetation's canopy to the lower boundary of actively cycling ground waters. As such, critical zone scientists and their data managers are at the front line of efforts to effectively compile and use the ""dark data in the Long Tail"" of earth science and integrate that data with the ""Big Data"" produced by hydrologists, atmospheric scientists, geospatial modelers and molecular biologists. <br/><br/>The NSF EarthCube initiative recently solicited proposals for domain workshops ""designed to listen to the needs of the end-user groups that make up the geosciences and to understand better how data-enabled science can help them achieve their scientific goals."" The proponents will convene a workshop to bring together critical zone domain scientists with computer scientists active in EarthCube. <br/><br/>This workshop would thus serve two objectives: (1) engage approximately 45 cyber-literate critical zone scientists in the EarthCube process; and (2) inform about 20 of EarthCube's cyberscientists of the diversity needs of CZ science. The overall goal of the workshop would be to develop a set of unifying requirements for the integration of ""long tail"" data and ""big data"" and to develop an interactive community of domain and cyber scientists to pursue solutions. <br/><br/>There are many examples of how cyber-infrastructure developed for geoscientists have broader impacts to the public. The national weather service data and model forecasts are highlighted on television and other media outlets. Fishermen, rafters and canoeists rely on USGS gauging data for their recreational activities. The Model My Watershed platform is harnessing GIS and hydrological modeling for educational purposes in classrooms and informal settings and also by citizen scientists."
"1252324","Calling All Experimentalists: EarthCube domain end-user workshop to address community needs for sharing and managing experimental data and techniques: Year 1 Experimental stratigr","EAR","EarthCube","09/01/2012","09/19/2012","Wonsuck Kim","TX","University of Texas at Austin","Standard Grant","H. Richard Lane","08/31/2013","$35,470.00","","delta@jsg.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","GEO","8074","7433","$0.00","CALLING ALL EXPERIMENTALISTS <br/>A WORKSHOP TO BUILD A COMMUNITY NETWORK FOR SHARING AND MANAGING EXPERIMENTAL <br/>DATA AND TECHNIQUES - YEAR 1: EXPERIMENTAL STRATIGRAPHY <br/><br/>By <br/><br/>Wonsuck Kim, Leslie Hsu, Raleigh Martin, and Brandon McElroy <br/><br/>EAR-1250525, University of Texas, Austin <br/><br/>ABSTRACT <br/>Research in experimental Earth surface processes and subsurface stratal development is in a data-rich era with rapid expansion of high-resolution, digitally based data sets that were not available even a few years ago. Multiple millions of dollars have been invested into recent updates in flume laboratories for the science of surface processes and subsurface architecture. These facilities are evolving along with advanced technology and methodology to allow a greater number of more sophisticated experiments at larger scales and finer resolutions than those that could ever be achieved before. In anticipation of the need for storing vast amounts of raw and analyzed data, a coherent effort is required at the community level. PIs envision guiding development of resources to increase the utility of laboratory data beyond its original study, adding an efficient channel for collecting and sharing experimental data, and fostering greater connectivity between the experimentalist community, computer modelers, and field geologists in the context of experimental data. They intend to provide two-way communication between EarthCube and workshop participants. First, the results of this workshop will feed into the EarthCube effort by providing detailed information from disciplinary scientists. PIs will solicit data and informatics needs from the community and contribute these requirements to the EarthCube effort in the relevant discussions and groups (e.g. Data Discovery, Interop, and Semantics groups) on the EarthCube website. Second, they will serve as spokespersons for the EarthCube effort by informing their community of the current developments and needs that have been learned from attending EarthCube events (Hsu has attended the November charrette and has applied to attend the June charrette)."
"1238216","EarthCube Community Workshop: Designing A Roadmap for Workflows in Geosciences","EAR","IIS SPECIAL PROJECTS, Software Institutes, EarthCube","04/01/2012","03/27/2012","Yolanda Gil","CA","University of Southern California","Standard Grant","Barbara L. Ransom","03/31/2013","$55,000.00","Ewa Deelman","gil@isi.edu","University Park","Los Angeles","CA","900890001","2137407762","GEO","7484, 8004, 8074","7433","$0.00","EarthCube is focused on community-driven development of an integrated and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive, process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems. This awards funds a series of broad, inclusive community interactions to gather adequate information and requirements to create a roadmap for a critical capability (workflow) in the development of EarthCube, a major new NSF initiative. Workflow in the context of EarthCube, and cyberinfrastructure in general, encompasses a broad range of topics including distributed execution management, the coupling of multiple models into composite applications, the integration of a wide range of data sources with processing, and the creation of refined data products from raw data. A key benefit of the funded work in terms of evaluating and creating community consensus on the best way forward for this capability (i.e., workflow) is the ability to document the provenance of data used in modeling and reproduce model and data-enabled scientific results. The funded workshop and information collecting activity will be open to all interested parties and is being led by a diverse and expert team of cyberinfrastructure developers, computer scientists, and geoscientists. Broader impacts of the work include converging on approaches, protocols, and standards that may be applicable across the sciences. They also include the fostering of close interaction between communities that do not commonly interact with one another and focusing them on the common goal of creating a new paradigm in data and knowledge management in the geosciences."
"1704896","EarthCube Building Blocks: Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences","ICER","EarthCube","10/01/2016","11/09/2016","Thomas Narock","MD","College of Notre Dame of Maryland","Standard Grant","Eva E. Zanzerkia","08/31/2017","$50,718.00","","tnarock@ndm.edu","4701 North Charles Street","Baltimore","MD","212102404","4105325314","GEO","8074","7433","$0.00","The proposed work addresses a challenge central to the EarthCube program's success: How to employ state of the art technology for geoscience data discovery, access, and integration. The project brings together significant geosciences holdings in the ocean, earth and polar sciences to demonstrate how innovative technologies can be robustly applied to these facilities to enhance the capabilities for scientists to discover and interpret relevant geoscience data and knowledge. The end product, GEOLink, will lower barriers to cross-repository data discovery and access, while respecting and preserving repository autonomy and heterogeneity. They will demonstrate the approach through a portal that allows searching and browsing of integrated content from multiple repositories.<br/><br/>A key challenge for EarthCube is to enable data discovery, access, and integration in a sustainable way. Existing data repositories and networks must be linked, while retaining their independent missions and services to existing disciplinary communities. Cultural, conceptual, and infrastructural heterogeneities must be respected in order to maintain different perspectives and differing priorities and thus foster inclusivity in the EarthCube endeavor. In particular, individual choices made by providers of data or repositories will need to be respected in an inclusive manner, and approaches to integration must reflect this. At the same time, however, the diversity and heterogeneity of geoscience data presents a significant barrier to its discovery. In this project, the researchers involved will develop a demonstration called GEOLink based on: 1) digital publication of geoscience data and knowledge as ""Linked Open Data""; combined with 2) semantic integration using design patterns and vocabularies shared among federated repositories; and 3) an underlying cyberinfrastructure extendable in both depth and breadth, that can become a central building block for EarthCube data harmonization. The cyberinfrastructure underlying the approach is extendable, sustainable, and affordable - leveraging state of the art developments in Linked Open Data and formal semantics, grounded through shared Ontology Design Patterns. GEOLink-enabled repositories will support discovery of related resources, including Rolling Deck to Repository (R2R), the Biological and Chemical Oceanographic Data Management Office (BCO-DMO), Integrated Earth Data Applications (IEDA), the Long-Term Ecological Research Network (LTER), DataONE, and the International Ocean Discovery Program (IODP), as well content from other EarthCube Building Block projects and collaborators."
"1440195","EarthCube Building Blocks: Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences","ICER","EarthCube","09/01/2014","08/19/2014","Thomas Narock","VA","Marymount University","Standard Grant","Eva E. Zanzerkia","12/31/2016","$144,401.00","","tnarock@ndm.edu","2807 NORTH GLEBE ROAD","ARLINGTON","VA","222074299","7035266978","GEO","8074","7433","$0.00","The proposed work addresses a challenge central to the EarthCube program's success: How to employ state of the art technology for geoscience data discovery, access, and integration. The project brings together significant geosciences holdings in the ocean, earth and polar sciences to demonstrate how innovative technologies can be robustly applied to these facilities to enhance the capabilities for scientists to discover and interpret relevant geoscience data and knowledge. The end product, GEOLink, will lower barriers to cross-repository data discovery and access, while respecting and preserving repository autonomy and heterogeneity. They will demonstrate the approach through a portal that allows searching and browsing of integrated content from multiple repositories.<br/><br/>A key challenge for EarthCube is to enable data discovery, access, and integration in a sustainable way. Existing data repositories and networks must be linked, while retaining their independent missions and services to existing disciplinary communities. Cultural, conceptual, and infrastructural heterogeneities must be respected in order to maintain different perspectives and differing priorities and thus foster inclusivity in the EarthCube endeavor. In particular, individual choices made by providers of data or repositories will need to be respected in an inclusive manner, and approaches to integration must reflect this. At the same time, however, the diversity and heterogeneity of geoscience data presents a significant barrier to its discovery. In this project, the researchers involved will develop a demonstration called GEOLink based on: 1) digital publication of geoscience data and knowledge as ""Linked Open Data""; combined with 2) semantic integration using design patterns and vocabularies shared among federated repositories; and 3) an underlying cyberinfrastructure extendable in both depth and breadth, that can become a central building block for EarthCube data harmonization. The cyberinfrastructure underlying the approach is extendable, sustainable, and affordable - leveraging state of the art developments in Linked Open Data and formal semantics, grounded through shared Ontology Design Patterns. GEOLink-enabled repositories will support discovery of related resources, including Rolling Deck to Repository (R2R), the Biological and Chemical Oceanographic Data Management Office (BCO-DMO), Integrated Earth Data Applications (IEDA), the Long-Term Ecological Research Network (LTER), DataONE, and the International Ocean Discovery Program (IODP), as well content from other EarthCube Building Block projects and collaborators."
"1344385","Collaborative Project: EarthCube Domain End-User Workshop: Developing a Community Vision of Cyberinfrastructure Needs for Coral Reef Systems Science","OCE","EarthCube","08/01/2013","07/10/2013","Mark Schildhauer","CA","University of California-Santa Barbara","Standard Grant","Michael Sieracki","07/31/2015","$65,760.00","","schild@nceas.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","GEO","8074","7433","$0.00","The Geosciences EarthCube program recognizes the importance of aligning cyber-infrastructure activities with the needs of end user research communities. To that end we propose to convene 50-70 members of the coral reef community in two workshops, one held at the University of Hawaii (HIMB) and the other at the University of California Santa Barbara National Center for Ecological Analysis and Synthesis (NCEAS). The specific objectives of the workshop are to: <br/><br/>1. Define current and future (5-15 years) scientific challenges in the field<br/><br/>2. Summarize data and cyber-infrastructure constraints that prevent these challenges being realized<br/><br/>3. Collate current community data and modeling resources and their locations<br/><br/>4. Identify and recommend data infrastructure that could facilitate rapidly addressing the scientific challenges in the field<br/><br/>The coral reef research community is multidisciplinary and the data on reefs is diverse and complex, crossing biological scales from genes to ecosystems, temporal scales from nanoseconds to millennia, and spatial scales from nanometers to kilometers. The challenge is to integrate across these data sources to identify patterns and relationships that rapidly improve our understanding of coral reefs systems. This effort has been hindered to date by the lack of tools to accomplish this and ineffective means of sharing data or collaborating. This project will support workshops that engage the coral reef community to 1) develop a common vision of the grand science challenges in the field 2) highlight how data cyber-infrastructure needs will integrate the complex datasets and potentially facilitate rapid progress in key areas of coral reefs ecosystem science and 3) emphasize the value of collaboration and data sharing as a first step to changing and improving the way coral reef scientists support each other and advance the field.<br/><br/>As ecosystem engineers, corals provide the nutritional, economic, and structural basis of<br/>an ecosystem worth billions of dollars annually. This workshop proposal convenes the coral reef community and will address how cyber-infrastructure can inform coral reef systems science. The latter will ultimately accelerate understanding of reef ecosystems, broaden the scope of the questions that can be asked and build capacity to predict how these societally relevant and fragile ecosystems will face the challenges of climate change and human development. The workshops will also be attended by at least 4 postdocs and represents a significant professional development opportunity for these individuals. Results will be disseminated on the EarthCube website, the NCEAS website, and the HIMB website making them broadly accessible to the science, education and the public. The product from the proposed endeavor will be a report to NSF EarthCube summarizing the discussion for each of these objectives that will serve to define and align the needs across the Geosciences and help prioritize EarthCube activities. There is also an opportunity to use the results to develop a manuscript that articulates how cyber-infrastructure can address the science challenges facing the coral reef community and facilitate a systems level science agenda. Such a product could have high value in both the science funding and policy realm."
"1623751","EarthCube Science Support Office (ESSO)","ICER","EarthCube","05/01/2016","09/21/2016","Mohan Ramamurthy","CO","University Corporation For Atmospheric Res","Cooperative Agreement","Eva E. Zanzerkia","04/30/2019","$1,036,937.00","","mohan@ucar.edu","3090 Center Green Drive","Boulder","CO","803012252","3034971000","GEO","8074","7433","$0.00","EarthCube is a community-driven effort with the goal of transforming the conduct of geoscience research and education by creating a well-integrated and facile environment to share scientific data, information tools and services, and knowledge in an open, transparent, and inclusive manner. Under the leadership of University Corporation for Atmospheric Research (UCAR) and in partnership with the EarthCube community, its governance, and other stakeholders and collaborators, the EarthCube Science Support Office (ESSO) will support efforts to advance EarthCube's mission. ESSO's role will be to provide a logistical, organizational, and administrative foundation to facilitate the advancement of EarthCube goals to catalyze scientific breakthroughs in the geosciences by fostering advances in information and computational sciences. ESSO will endeavor to ensure a high quality of service to EarthCube stakeholders, delivered with professionalism, efficiency, transparency, and nimbleness.<br/><br/>ESSO will provide logistical support to the EarthCube community and its governance groups in order to stimulate and manage community dialog, strengthen efforts to define and resolve common challenges using a consensus-oriented approach, and help realize EarthCube's full potential and vision. ESSO will provide leadership to improve the coherence and impact of EarthCube's efforts, bringing a coordinated and well-integrated approach to managing and supporting governance, science, and technology activities. To accomplish this, UCAR will draw on the expertise of two of its community programs -- Unidata and the Joint Office for Science Support (JOSS) -- to provide the services requested of the ESSO. In addition, ESSO will collaborate with the Earth Science Information Partners (ESIP) Federation to leverage their long experience with the geoscience cyberinfrastructure community for the mutual benefit of both organizations and their communities. ESSO will also spearhead outreach and community engagement activities by participating in national and international scientific society meetings, scientific career fairs, and other events. ESSO will reach out to broader audiences through the EarthCube website, newsletters, and social media. It will leverage the presence of geoscientists and cyberinfrastructure professionals to offer in-person and virtual seminars, promoting the work of funded projects, data facilities, and providing backbone support for education, training, and workforce development activities."
"1639709","EarthCube Building Blocks: Collaborative Proposal: Deploying Multi-Facility Cyberinfrastructure in Commercial and Private Cloud-based Systems. (GeoSciCloud)","ICER","EarthCube","09/01/2016","09/15/2016","Charles Meertens","CO","UNAVCO, Inc.","Standard Grant","Eva E. Zanzerkia","08/31/2019","$605,204.00","Frances Boler","meertens@unavco.org","6350 Nautilus Dr.","Boulder","CO","803015394","3033817636","GEO","8074","7433","$0.00","It is common to hear that it is optimal to perform computations necessary for the operation of corporations in the ?cloud? and it is true that many commercial companies are moving their information technology into that environment. Scientific data centers funded by the NSF have unique constraints that they must accommodate. Funding is limited and costs of managing data centers using cloud technology can be quite costly. Additionally, government funded research organizations typically have much smaller IT staffs than do corporations. The impact of managing IT operations in the cloud is not identical between large corporations and NSF funded data centers. In the GeoSciCloud project, two medium-size NSF funded data centers plan to deploy data collections along with cloud-based services in different environments in order to assess the feasibility and impact. These environments include:<br/>- Commercial cloud environments such as those offered by Amazon, Google, and Microsoft and<br/>- NSF supported large computing facilities that are just beginning to offer services that have characteristics of cloud computing<br/>The operation of these infrastructures in these two cloud environments will be compared to current in-house environments and assessed.<br/>This project will thereby help NSF/EarthCube identify the most suitable IT environment in which the EarthCube should deploy and support shared infrastructure. The potential reliability and cost-savings are excellent motivating factors.<br/><br/>IRIS and UNAVCO operate data centers with several hundred terabytes of data and services that match our community's needs and requirements. Each organization currently operates its own infrastructure. GeoSciCloud tasks will include moving subsets of our archives, as a test, into commercial cloud and XSEDE cloud environments where we will compare and contrast several aspects of working in different infrastructures. GeoSciCloud partners will also deploy key services developed under the GeoWS building block to enable access to data sets by domain scientists. <br/><br/>GeoSciCloud will help EarthCube compare and contrast the three environments (XSEDE, Commercial Cloud, and current infrastructure) in the following areas:<br/>- Gain an understanding of issues related to the ingestion of large data sets into the cloud and curating the data in a cloud environment.<br/>- Compare processing times for real world requests for data by practicing domain scientists<br/>- Test elasticity of the cloud for doing large amounts of digital signal processing of seismic data and reprocessing GPS solutions for long periods of time.<br/>- Compare the speed of data egress from multiple environments including tests of using higher access systems such as Grid-FTP.<br/>- Compare overall costs of operating in the three environments<br/>- Document what the best practices are that emerge from the GeoSciCloud test that should be promoted within EarthCube.<br/>- Perform conversion of data held in domain formats to more widely used formats such as HDF5 for improved interoperability.<br/>- Test the reliability of streaming real time data into the cloud.<br/>GeoSciCloud will also explore providing some infrastructure in support of other EarthCube partners so that multiple data centers can cohabitate within the GeoSciCloud. IRIS and UNAVCO will commit to ultimately demonstrate the utility of shared infrastructure and how it can improve the efficiency and economics within EarthCube and specifically shared infrastructure in a cloud environment."
"1540945","EarthCube IA: Collaborative Proposal: Interdisciplinary Earth Data Alliance as a Model for Integrating Earthcube Technology Resources and Engaging the Broad Community","ICER","EarthCube","09/01/2015","08/19/2015","Ilya Zaslavsky","CA","University of California-San Diego","Standard Grant","Eva E. Zanzerkia","08/31/2017","$286,000.00","Amarnath Gupta","zaslavsk@sdsc.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","GEO","8074","7433","$0.00","A fundamental requirement for EarthCube is access to a comprehensive spectrum of well-curated, reliably re-usable, and seamlessly interoperable scientific data, but this does not exist today with many Geoscience domains still lacking sustainable data services. This project is a collaboration between an established data facility in the solid Earth sciences, IEDA (Interdisciplinary Earth Data Alliance), three scientifically related data communities in the solid Earth sciences that lack data facilities (deep seafloor processes, mineral physics, polar cryosphere), a research data collection (MetPetDB), a group of computer scientists that specialize in distributed information systems and interoperability, and a social scientist to re-structure the IEDA data facility, both organizationally and architecturally, to create the pilot of a multi-institutional and multi-disciplinary alliance of data providers. The goal is to create a model for other data facilities to partner with so far ?underserved? data communities to broaden integration of Geoscience domains into EarthCube, and advance both interdisciplinary and discipline-specific data science, while realizing economies of scale by sharing common data services. <br/><br/>Using IEDA as a testbed, the project will adopt elements of three EarthCube technologies that have been or are being developed by EarthCube Building Block projects: CINERGI (Community INventory of EarthCube Resources for Geoscience Interoperability), GeoWS (Geoscience Web Services), and GeoLink (Semantic Web technology), to build the architecture of the alliance, thereby testing, validating, and potentially improving these technologies. The technical work will focus on creating a flexible and scalable framework that will allow a growing number of partner systems to plug into shared capabilities such as applications for integrated data discovery and data submission and contribute their resources. Architectural changes at IEDA will go hand-in-hand with the transition of IEDA?s organizational structure toward the envisioned multi-institutional alliance."
"1440114","EarthCube Building Blocks: Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences","ICER","EarthCube","09/01/2014","08/19/2014","Cynthia Chandler","MA","Woods Hole Oceanographic Institution","Standard Grant","Eva E. Zanzerkia","08/31/2017","$286,780.00","","cchandler@whoi.edu","183 OYSTER POND ROAD","WOODS HOLE","MA","025431041","5082893542","GEO","8074","7433","$0.00","The proposed work addresses a challenge central to the EarthCube program's success: How to employ state of the art technology for geoscience data discovery, access, and integration. The project brings together significant geosciences holdings in the ocean, earth and polar sciences to demonstrate how innovative technologies can be robustly applied to these facilities to enhance the capabilities for scientists to discover and interpret relevant geoscience data and knowledge. The end product, GEOLink, will lower barriers to cross-repository data discovery and access, while respecting and preserving repository autonomy and heterogeneity. They will demonstrate the approach through a portal that allows searching and browsing of integrated content from multiple repositories.<br/><br/>A key challenge for EarthCube is to enable data discovery, access, and integration in a sustainable way. Existing data repositories and networks must be linked, while retaining their independent missions and services to existing disciplinary communities. Cultural, conceptual, and infrastructural heterogeneities must be respected in order to maintain different perspectives and differing priorities and thus foster inclusivity in the EarthCube endeavor. In particular, individual choices made by providers of data or repositories will need to be respected in an inclusive manner, and approaches to integration must reflect this. At the same time, however, the diversity and heterogeneity of geoscience data presents a significant barrier to its discovery. In this project, the researchers involved will develop a demonstration called GEOLink based on: 1) digital publication of geoscience data and knowledge as ""Linked Open Data""; combined with 2) semantic integration using design patterns and vocabularies shared among federated repositories; and 3) an underlying cyberinfrastructure extendable in both depth and breadth, that can become a central building block for EarthCube data harmonization. The cyberinfrastructure underlying the approach is extendable, sustainable, and affordable - leveraging state of the art developments in Linked Open Data and formal semantics, grounded through shared Ontology Design Patterns. GEOLink-enabled repositories will support discovery of related resources, including Rolling Deck to Repository (R2R), the Biological and Chemical Oceanographic Data Management Office (BCO-DMO), Integrated Earth Data Applications (IEDA), the Long-Term Ecological Research Network (LTER), DataONE, and the International Ocean Discovery Program (IODP), as well content from other EarthCube Building Block projects and collaborators."
"1440202","EarthCube Building Blocks: Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences","ICER","EarthCube","09/01/2014","09/22/2015","Pascal Hitzler","OH","Wright State University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$416,745.00","Timothy Finin, Michelle Cheatham","pascal.hitzler@wright.edu","3640 Colonel Glenn Highway","Dayton","OH","454350001","9377752425","GEO","8074","7433, 9251","$0.00","The proposed work addresses a challenge central to the EarthCube program's success: How to employ state of the art technology for geoscience data discovery, access, and integration. The project brings together significant geosciences holdings in the ocean, earth and polar sciences to demonstrate how innovative technologies can be robustly applied to these facilities to enhance the capabilities for scientists to discover and interpret relevant geoscience data and knowledge. The end product, GEOLink, will lower barriers to cross-repository data discovery and access, while respecting and preserving repository autonomy and heterogeneity. They will demonstrate the approach through a portal that allows searching and browsing of integrated content from multiple repositories.<br/><br/>A key challenge for EarthCube is to enable data discovery, access, and integration in a sustainable way. Existing data repositories and networks must be linked, while retaining their independent missions and services to existing disciplinary communities. Cultural, conceptual, and infrastructural heterogeneities must be respected in order to maintain different perspectives and differing priorities and thus foster inclusivity in the EarthCube endeavor. In particular, individual choices made by providers of data or repositories will need to be respected in an inclusive manner, and approaches to integration must reflect this. At the same time, however, the diversity and heterogeneity of geoscience data presents a significant barrier to its discovery. In this project, the researchers involved will develop a demonstration called GEOLink based on: 1) digital publication of geoscience data and knowledge as ""Linked Open Data""; combined with 2) semantic integration using design patterns and vocabularies shared among federated repositories; and 3) an underlying cyberinfrastructure extendable in both depth and breadth, that can become a central building block for EarthCube data harmonization. The cyberinfrastructure underlying the approach is extendable, sustainable, and affordable - leveraging state of the art developments in Linked Open Data and formal semantics, grounded through shared Ontology Design Patterns. GEOLink-enabled repositories will support discovery of related resources, including Rolling Deck to Repository (R2R), the Biological and Chemical Oceanographic Data Management Office (BCO-DMO), Integrated Earth Data Applications (IEDA), the Long-Term Ecological Research Network (LTER), DataONE, and the International Ocean Discovery Program (IODP), as well content from other EarthCube Building Block projects and collaborators."
"1440221","EarthCube Building Blocks: Collaborative Proposal: GeoLink - Leveraging Semantics and Linked Data for Data Sharing and Discovery in the Geosciences","ICER","EarthCube","09/01/2014","08/19/2014","Robert Arko","NY","Columbia University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$369,179.00","Suzanne Carbotte, Kerstin Lehnert","arko@ldeo.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","GEO","8074","7433","$0.00","The proposed work addresses a challenge central to the EarthCube program's success: How to employ state of the art technology for geoscience data discovery, access, and integration. The project brings together significant geosciences holdings in the ocean, earth and polar sciences to demonstrate how innovative technologies can be robustly applied to these facilities to enhance the capabilities for scientists to discover and interpret relevant geoscience data and knowledge. The end product, GEOLink, will lower barriers to cross-repository data discovery and access, while respecting and preserving repository autonomy and heterogeneity. They will demonstrate the approach through a portal that allows searching and browsing of integrated content from multiple repositories.<br/><br/>A key challenge for EarthCube is to enable data discovery, access, and integration in a sustainable way. Existing data repositories and networks must be linked, while retaining their independent missions and services to existing disciplinary communities. Cultural, conceptual, and infrastructural heterogeneities must be respected in order to maintain different perspectives and differing priorities and thus foster inclusivity in the EarthCube endeavor. In particular, individual choices made by providers of data or repositories will need to be respected in an inclusive manner, and approaches to integration must reflect this. At the same time, however, the diversity and heterogeneity of geoscience data presents a significant barrier to its discovery. In this project, the researchers involved will develop a demonstration called GEOLink based on: 1) digital publication of geoscience data and knowledge as ""Linked Open Data""; combined with 2) semantic integration using design patterns and vocabularies shared among federated repositories; and 3) an underlying cyberinfrastructure extendable in both depth and breadth, that can become a central building block for EarthCube data harmonization. The cyberinfrastructure underlying the approach is extendable, sustainable, and affordable - leveraging state of the art developments in Linked Open Data and formal semantics, grounded through shared Ontology Design Patterns. GEOLink-enabled repositories will support discovery of related resources, including Rolling Deck to Repository (R2R), the Biological and Chemical Oceanographic Data Management Office (BCO-DMO), Integrated Earth Data Applications (IEDA), the Long-Term Ecological Research Network (LTER), DataONE, and the International Ocean Discovery Program (IODP), as well content from other EarthCube Building Block projects and collaborators."
"1343816","EarthCube Building Blocks: Community Inventory of EarthCube Resources for Geoscience Interoperability (CINERGI)","ICER","EarthCube","09/15/2013","08/26/2013","Ilya Zaslavsky","CA","University of California-San Diego","Standard Grant","Eva E. Zanzerkia","08/31/2017","$900,000.00","","zaslavsk@sdsc.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","GEO","8074","7433","$0.00","EarthCube Building Blocks: Community Inventory of EarthCube Resources for Geoscience Interoperability<br/>(CINERGI) Collaborating Institutions: University of California San Diego, Arizona Geological<br/>Survey, University of Chicago, Columbia University, The Open Geospatial Consortium This building<br/>block project focuses on constructing a community inventory and knowledgebase on geoscience<br/>information resources to extend work on interoperability-readiness and meet the challenge of finding resources across<br/>disciplines, assessing their fitness for use in specific research scenarios, and providing<br/>tools for integrating and re-using data from multiple domains. This capability is a key EarthCube<br/>mission mentioned in reports of several EarthCube domain workshops and roadmaps. We envision<br/>a comprehensive system linking geoscience resources, users, publications, usage information,<br/>and cyberinfrastructure (CI) components. It will supplement information included in existing<br/>data discovery catalogs by integrating feedback from users on their experience with resources,<br/>by providing characterization of resources in an interoperability assessment framework, and<br/>by supporting registration of mappings between information models and vocabularies to assist<br/>data integration. To assess interoperability among components an open source validation mechanism<br/>will be implemented. The system will enable community input and access by geoscientists via<br/>online user interfaces, and will provide documented web service APIs so that inventory information<br/>can be easily browsed, analyzed, and integrated within the emerging EarthCube CI. The project<br/>team will collaborate with related EarthCube efforts, including Building Blocks, RCNs, domain<br/>workshop and the Test Enterprise Governance. The PIs will work with researchers from selected geoscience domains<br/>(stratigraphy, hydrology, critical zone science) to validate and demonstrate advanced features<br/>of CINERGI in specific research context.<br/><br/>CINERGI is a direct response to the communitys need for easy discovery, assessment, and utilization<br/>of CI resources, expressed by many EarthCube stakeholders. It is a fundamental building block<br/>of an Earth Science CI and will serve geoscientists across all domains to efficiently and<br/>in more informed manner use existing and emerging resources for productive and transformative<br/>research. It will also help CI experts and computer scientists to align new developments better<br/>with existing resources such as vocabularies, ontologies, data exchange protocols, or metadata<br/>schemas."
"1440066","EarthCube RCN: An EarthCube Oceanography and Geobiology Environmental Omics Research Coordination Network (ECOGEO RCN)","ICER","EarthCube","09/01/2014","08/17/2015","Edward DeLong","HI","University of Hawaii","Standard Grant","Eva E. Zanzerkia","02/28/2017","$359,995.00","","edelong@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","GEO","8074","7433, 9150, OTHR, 0000","$0.00","The network elements of the ECOGEO RCN reach across diverse communities of ocean scientists, geoscientists, computer scientists and bioinformaticians, and will forge new cross-disciplinary connections. Although the scientific goals of the proposed ECOGEO community network are diverse, common challenges and requirements for big data analyses be identified across this broad community. This project will provide new solutions and ideas that reach beyond disciplinary boundaries, since the challenges of rich omic datasets share commonalities across areas as diverse as soil science, oceanography, geobiology and studies of the human microbiome. Best practices and use case scenarios developed in this project will integrate across challenges of diverse science domains, and provide well documented approaches for omic data management and analyses, that will serve as models and test cases for new cyberinfrascructure systems. These efforts will impact not only ocean scientists and geobiologists, but also other allied areas that use the same approaches, that range from environmental assessment to human health. <br/><br/>Inexpensive sequencing has facilitated the generation of billions of environmental DNA sequences, and allied techniques to survey gene expression (metatranscriptomics) and protein expression (metaproteomics) are advancing as well. The large and complex environmental omic datasets now present major challenges to the ocean and geoscience communities. These omic datasets are diverse, complex, and exponentially expanding, and require the construction, curation, and query of diverse federated databases, as well as development of shared interoperable, big-data capable analytical tools. To help address these current big data challenges, this project establishes a virtual network called EarthCube Oceanography and Geobiology Environmental Omics Research Coordination Network (ECOGEO RCN), that will foster collaborations, communication, innovation, and education in omic data management and analyses in the oceanography and geobiology communities. The effort will identify and communicate needed data standards, sharing and access mechanisms and analytical strategies across the broader community of ocean and geosciences. Major outcomes of ECOGEO RCN will be: 1)Establishment of a virtual network that coordinates collaboration and communication in omics, data sharing and analyses; 2)Training of a cyber-savvy generation of ocean and geo science graduate students, postdocs and young professionals in the rapidly evolving environmental omics and bioinformatics field. 3)Identification and elaboration of environmental omic data standards, ontologies, sharing mechanisms, and analytical strategies; 4)Development of use case scenarios that will inspire creation of a new palette of user friendly inter-operative community data management, analytical and visualization tools for oceanography and geobiology omic science and beyond.<br/><br/>The establishment of the ECOGEO RCN will provide a collection of online resources to enable the access, management and discovery of oceanographic and geobiology omic data, metadata, analysis tools, methodologies, and other user-driven needs. An EarthCube hosted ECOGEO-Wiki will serve as open forum for network participants to share content and link to data repositories, models, and tools. The ECOGEO centralized network and web-based portal will promote better communication within and between ECOGEO microbial oceanography and geobiology scientists and the broader scientific community. This will enable greater access and organization of large and heterogeneous datasets, greater efficiencies in scientific discovery, and broader collaborations based on both survey and experimental data. The overall result will be to facilitate access and use of existing and rapidly accumulating new omic datasets for a wide range of ocean science and geoscience users, to observe measure and model community composition, biological and biogeochemical activities and ecosystem structure and function from ocean surface waters to the deep subsurface."
"1541017","Earthcube IA: Collaborative Proposal: Interdisciplinary Earth Data Alliance as a Model for Integrating Earthcube Technology Resources and Engaging the Broad Community","ICER","EarthCube","09/01/2015","08/19/2015","Frank Spear","NY","Rensselaer Polytechnic Institute","Standard Grant","Eva E. Zanzerkia","08/31/2017","$29,920.00","Sibel Adali","spearf@rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","GEO","8074","7433","$0.00","A fundamental requirement for EarthCube is access to a comprehensive spectrum of well-curated, reliably re-usable, and seamlessly interoperable scientific data, but this does not exist today with many Geoscience domains still lacking sustainable data services. This project is a collaboration between an established data facility in the solid Earth sciences, IEDA (Interdisciplinary Earth Data Alliance), three scientifically related data communities in the solid Earth sciences that lack data facilities (deep seafloor processes, mineral physics, polar cryosphere), a research data collection (MetPetDB), a group of computer scientists that specialize in distributed information systems and interoperability, and a social scientist to re-structure the IEDA data facility, both organizationally and architecturally, to create the pilot of a multi-institutional and multi-disciplinary alliance of data providers. The goal is to create a model for other data facilities to partner with so far ?underserved? data communities to broaden integration of Geoscience domains into EarthCube, and advance both interdisciplinary and discipline-specific data science, while realizing economies of scale by sharing common data services. <br/><br/>Using IEDA as a testbed, the project will adopt elements of three EarthCube technologies that have been or are being developed by EarthCube Building Block projects: CINERGI (Community INventory of EarthCube Resources for Geoscience Interoperability), GeoWS (Geoscience Web Services), and GeoLink (Semantic Web technology), to build the architecture of the alliance, thereby testing, validating, and potentially improving these technologies. The technical work will focus on creating a flexible and scalable framework that will allow a growing number of partner systems to plug into shared capabilities such as applications for integrated data discovery and data submission and contribute their resources. Architectural changes at IEDA will go hand-in-hand with the transition of IEDA?s organizational structure toward the envisioned multi-institutional alliance."
"1343759","Earth Cube Conceptual Design: Developing a Data-Oriented Human-centric Enterprise Architecture for EarthCube","ICER","EarthCube","09/15/2013","08/01/2014","Chaowei Yang","VA","George Mason University","Standard Grant","Eva E. Zanzerkia","08/31/2016","$288,272.00","Chen Xu","cyang3@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","GEO","8074","7433","$0.00","This EarthCube enterprise conceptual architecture approach looks to develop a data-driven and human-centric EarthCube enterprise architecture for achieving the goal of EarthCube as a community-driven activity to transform the conduct of geoscience research and education. The proposed EarthCube enterprise architecture will have geoscientists and domain experts at its center and facilitate them to communicate and collaborate through data sharing, and ultimately bring geosciences forward in a holistic fashion. This project seeks to design a conceptual architecture that can bring geoscientists, computing scientists, and social scientists together to collaborate on networks of data, technology, applications, business models, and stakeholders. The design approach is guided by the following principles. It designs a new architecture as well as operational procedures for achieving the architecture based on comprehensive review and assessment of current enterprise architectures. Second, it suggests several important mechanisms to cross the disciplinary chasms, as EarthCube seeking to harmonize the geosciences communities? diverse approaches. Third, it proposes methods for forming collaborative networks of data, tools, standards and people as supported by geoscience cyberinfrastructure technology. Finally, the proposed project incorporates the concept of collaborative networks for maturing the conceptual design of the EarthCube enterprise architecture by including academia, agencies, industry, and other organizations as autonomous participants that continuously seek common ground for collectively improving geosciences.<br/><br/>The proposed EarthCube enterprise conceptual design will be validated through the EarthCube workshops, research coordination networks, building blocks, and other venues. The Federation of Earth Science Information Partners (ESIP) will provide validation from many NSF and non-NSF funded projects. The project will be sustained and make a long standing impact in geoscience communities as well as the geoscience cyberinfrastructure communities with a scalable, interoperable, sustainable, and evolvable conceptual architecture"
"1321479","Engaging the Sedimentary Geology Community in EarthCube (Workshop)","EAR","EarthCube","02/01/2013","02/11/2013","Marjorie Chan","UT","University of Utah","Standard Grant","Judith Ellen Skog","01/31/2016","$99,947.00","David Budd","marjorie.chan@utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","GEO","8074","7433, 9150","$0.00","A workshop is proposed to identify and articulate the cyberinfrastructure (CI) needs and<br/>potential applications in the broad scientific domain encompassing sedimentary geology. The<br/>effort is intended to build consensus within the diverse sedimentary geology community (SGC)<br/>with respect to the EarthCube effort. The SGC focuses on the processes that form, shape, and<br/>affect Earth's sedimentary crust, and distribute key resources such as hydrocarbons, coal, and<br/>water. The sedimentary records studied by this community are the archives of Earth's past<br/>surface processes, climates, oceans, and biosphere. The SGC collects a great diversity of<br/>qualitative and quantitative data that characterizes diverse attributes of sedimentary rocks at<br/>spatial scales that span 13-orders of magnitude. Most data is based on physical samples; some is<br/>continuous. Derivative products based on the data are published, but the data itself are typically<br/>not archived or readily available to other researchers.<br/><br/>The domain workshop will focus on: 1) defining the current nature of SGC data and workflows,<br/>including the challenges and impediments to sharing and using that data; 2) establish what types<br/>of data, repositories, software, and tools (analytical, modeling, and visualization) would enable<br/>community-based, 'big science' collaborations within the SGC; 3) evaluate the potential<br/>importance of mining legacy data; 4) identify examples of the kind of scientific challenges the<br/>SGC would attack given an ideal CI; and 5) evaluate how EarthCube, if populated with the type<br/>of data and tools articulated in the above bullets, would impact the SGC's teaching. The overall<br/>product of the workshop will be a report to NSF that defines the issues and challenges that must<br/>be met for the integration of the SGC with EarthCube.<br/><br/>Sedimentary rocks are the most abundant rock type on the surface of the Earth and are rich in<br/>geologic data and history. The intellectual merit of the proposal is that the summary outcomes<br/>will provide SGC guidance on the priorities and use of sedimentary data to the EarthCube<br/>framework of Earth systems.<br/><br/>The broader of impacts of the proposed workshop are to integrate SGC with one of the most<br/>important cyberinfrastructure initiatives to NSF integrating information and data across the<br/>geosciences."
"1338425","EarthCube Domain End-User Workshop: Integrating Real-time Data into the EarthCube Framework; Boulder, Colorado; June 17-19, 2013","AGS","EarthCube","04/15/2013","04/05/2013","Michael Daniels","CO","University Corporation For Atmospheric Res","Standard Grant","Linnea M. Avallone","11/30/2014","$95,634.00","","daniels@ucar.edu","3090 Center Green Drive","Boulder","CO","803012252","3034971000","GEO","8074","4444, 7433, OTHR","$0.00","This grant supports a workshop entitled ""EarthCube Domain End-User Workshop: Integrating Real-time Data into the EarthCube Framework"" to be held in June 2013 in Boulder, Colorado. The primary objective of this meeting is to bring together users and providers of real-time data across geosciences disciplines to address community needs for effectively and efficiently handling and applying this type of data. Through oral presentations and in breakout sessions, attendees from universities, federal agencies and industry will develop example cases and explore issues related to gathering and quality control of real-time data that can be used to inform the cyber-infrastructure development within EarthCube.<br/><br/><br/>Real-time geoscientific data has the potential to revolutionize the application of scientific data in contexts of importance to a broader audience. Such data streams are key inputs, for example, to operational forecast models and warning systems that inform the general public of impending hazardous weather. This workshop will have a broader impact by helping to build capacity among the community of real-time technologists and researchers whose work affects a wide range of users, including water resource managers, energy planners, farmers, school districts, disaster mitigation and relief planners, urban managers, utilities, cities, etc."
"1313866","Collaborative Project: EarthCube Education End-User Workshop","ICER","EarthCube","02/01/2013","01/17/2013","Kim Kastens","MA","Education Development Center","Standard Grant","Jill L. Karsten","01/31/2014","$46,053.00","Ruth Krumhansl","kkastens@edc.org","43 Foundry Avenue","Waltham","MA","024538313","6176182227","GEO","8074","","$0.00","This award is being used to convene a workshop of ~40 participants to define end-user needs related to geoscience education within the EarthCube initiative. The workshop brings together disciplinary faculty in the geosciences, educators experienced in teaching with geoscience data and developing associated curricula, representatives of NSF-sponsored research programs involved with generation of large data sets, as well as technologists, STEM education researchers, and learning scientists. The workshop is being held at the Scripps Forum (Scripps Institution of Oceanography) during the Spring of 2013. The workshop seeks to explore both the educational opportunities offered through the cyberinfrastructure capabilities of the EarthCube program and identify the educational needs for preparing undergraduate students and faculty to be the future contributors to the scientific research enabled by EarthCube. A major goal of this workshop is to establish an initial roadmap for educational activities that should be associated with or enabled by EarthCube. The workshop will consider the educational and instructional strategies not only to prepare students in undergraduate programs to be technologically-savvy users of EarthCube data and models, but also to build the future scientific capacity to advance Earth systems scientific research. Consideration will also be given to how EarthCube may serve as a platform for advancing STEM education research."
"1238951","Workshops for a Community Roadmap for Governance of Geoscience Cyberinfrastructure (EarthCube)","EAR","EarthCube","04/01/2012","03/27/2012","M. Lee Allison","AZ","Arizona Geological Survey","Standard Grant","Barbara L. Ransom","03/31/2013","$99,999.00","Hannes Leetaru, Gary Crane, Geoffrey Fox, David Arctur","lee.allison@azgs.az.gov","416 W. Congress St, #100","Tucson","AZ","857011381","5207703500","GEO","8074","7433","$0.00","EarthCube is focused on community-driven development of an integrated and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive, process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems. This awards funds a series of broad, inclusive community interactions to gather adequate information and requirements to create a roadmap for a critical capability (governance) in the development of EarthCube, a major new NSF initiative. Community/stakeholder buy-in and adoption of standards; common tools and aproaches, if possible; best practices; cyberinfrastructure protocols; and workflows are essential to any holistic approach to creating an interoperable and service-oriented architecture that serves the needs of the geoscience research community wishing to do data-enabled science. The funded series of online/virtual workshops that will engage a brod spectrum of the geoscience community were considered innovative and exciting, especially the proposed application of social networking outreach utilities to engage early career scientists and students. A prime deliverable of the project will be a road map of how to move forward in terms of setting up broadly agreed upon structures to oversee the development of EarthCube activities in the associated working groups and concept grants. Broader impacts of the work include converging on mutually agreed upon processes to allow decision making with regard to whether or not standards or specific protocols should be established, and if so what they should be. They also include the fostering of close interaction between communities that do not commonly interact with one another (the geosciences and those in cyberinfrastructure and computer science) and focusing them on the common goal of creating a new paradigm in data and knowledge management in the geosciences."
"1252574","Furthering EarthCube: A Roadmap Coordination Workshop","ACI","EarthCube","09/01/2012","08/24/2012","Siri Jodha Khalsa","CO","University of Colorado at Boulder","Standard Grant","Amy Walton","08/31/2013","$49,999.00","","khalsa@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","CSE","8074","7433","$0.00","EarthCube is a joint venture between the Directorate of Geosciences and the Office of Cyberinfrastructure at the National Science Foundation. It is a community-driven effort to design and implement an effective data and knowledge management system for the geosciences that will integrates disparate data sets and web services and serves all members of the geoscience community. This 2-day workshop at the University of Colorado brings together investigators and other interested parties who have been tasked with developing cyberinfrastructure components that are potential candidates for inclusion in the final architecture and design of EarthCube. Participants at the workshop will be tasked to synthesize community input from the June EarthCube meeting and sequence the series of proposed milestones and events included in community-created road maps of key cyberinfrastructure capabilities that were generated over the course of the last six months. The overarching goals of the workshop will be to propose a workable cyberinfrastructure framework for EarthCube and work out a provisional timeline for its implementation. Participants will consist of key individuals already working on potential EarthCube architecture components, as well as those from newly formed special interest groups such as those interesting in having EarthCube link to and incorporate biological datasets; those seeking to serve the needs of geoscientists who work with unique sample-based data, as opposed to large homogeneous datasets coming from sensor arrays; and those trying to develop software to allow direct ingestion of data from laboratory instruments. Broader impacts of the workshop lie in the area of building infrastructure for science and engineering."
"1252279","EarthCube Domain End-User Workshop for Structural Geology and Tectonics","EAR","EarthCube","09/01/2012","09/19/2012","J. Douglas Walker","KS","University of Kansas Center for Research Inc","Standard Grant","Stephen S. Harlan","08/31/2014","$50,000.00","","jdwalker@ku.edu","2385 IRVING HILL RD","LAWRENCE","KS","660457568","7858643441","GEO","8074","1572, 7433, 9150","$0.00","This project is supporting a two-day workshop that will be held identify the possible interactions between the Structural Geology and Tectonics community (SGTC) with the EarthCube effort. The workshop will assemble a group of about 40 Structural Geology and Tectonics researchers to define better the cyberinfrastructure needs as well as the required interactions within the community as well as with the EarthCube to take the next steps in creating a more integrated digital framework. This effort includes: 1) establishing science drivers and challenges of the SGTC; 2) identifying the impediments to using data and tools both within and external to the SGTC; 3) listing existing and more critically needed data, tools, and visualization to form a cyberinfrastructure for the community; 4) creating several use cases that demonstrate how the cyberinfrastructure will be used to address the science drivers or provide critical connections for teaching and research; and 5) initiating conversation with existing databases on how to interact constructively. A catalyzing issue of the workshop concerns the nature of field data. Structural data is collected on an extremely wide range of spatial (10-8 m to 104 m) and temporal scales, and the collection requires observation, inference, and interpretation at most of these scales. These data are critical to any tectonic modeling and inference. This data at the core of Structural Geology and Tectonics and presents a fundamental challenge to digital representation/integration that can be aided by the interaction with the EarthCube effort.<br/><br/>This project is important for both the scientific and cyberinfrastructure development of the geosciences. Future progress of the geosciences will be based on the integration of rich and diverse datasets. This workshop will identify the needs of one of the most important and data-rich as well as data complex areas in geology. There will be a vast array of intellectually challenging tasks in describing and integrating data across a spectrum of scales as well as granularity.<br/><br/>The construction of a cyberinfrastructure for Structural Geology and Tectonics data will make these data accessible to a much larger group of researchers. This field describes and quantitatively documents the surface geology of the Earth. That itself has impacts into individuals, groups, and organizations that study the earth. In addition, the digital presentation of such data can be used by private and governmental organizations across the local to global spectrum. Lastly, the integration of Structural Geology and Tectonics data and models into the EarthCube effort will be fundamental to the success of EarthCube."
"1240394","Workshops for Creating a Community Roadmap for EarthCube Services for Data Discovery, Mining and Access: Data Mining Services","EAR","EarthCube","05/01/2012","04/17/2013","Rahul Ramachandran","AL","University of Alabama in Huntsville","Standard Grant","Barbara L. Ransom","10/31/2013","$99,394.00","Sara Graves","rramachandran@itsc.uah.edu","301 Sparkman Drive","Huntsville","AL","358051911","2568246120","GEO","8074","7433, 9150","$0.00","EarthCube, a major new NSF initiative, is focused on community-driven development of an integrated and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems. This awards funds a series of broad, inclusive community interactions to gather adequate information and requirements to create a roadmap for a critical capability (data mining and algorithm/data analytic techniques) that will enable the development of EarthCube. The focus of the community conversations include exploration of present data analysis approaches and possible new novel approaches; data filtering; pattern recognition and machine learning as applied to geoscience datasets; and search algorithm identification and development. Intensive interaction will also take place with awardees and participants in the other EarthCube community groups and concept development awards. Broader impacts of the work include: helping EarthCube realize its potential to dramatically improve the infrastructure for science, actively engaging early career geoscience researchers in the process, and supporting investigators at an institution in an EPSCoR state."
"1238036","EarthCube Community Workshop: Designing A Roadmap for Workflows in Geosciences","EAR","IIS SPECIAL PROJECTS, Software Institutes, EarthCube","04/01/2012","03/27/2012","Christopher Duffy","PA","Pennsylvania State Univ University Park","Standard Grant","Barbara L. Ransom","03/31/2013","$15,000.00","","cxd11@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","GEO","7484, 8004, 8074","7433","$0.00","EarthCube is focused on community-driven development of an integrated and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive, process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems. This awards funds a series of broad, inclusive community interactions to gather adequate information and requirements to create a roadmap for a critical capability (workflow) in the development of EarthCube, a major new NSF initiative. Workflow in the context of EarthCube, and cyberinfrastructure in general, encompasses a broad range of topics including distributed execution management, the coupling of multiple models into composite applications, the integration of a wide range of data sources with processing, and the creation of refined data products from raw data. A key benefit of the funded work in terms of evaluating and creating community consensus on the best way forward for this capability (i.e., workflow) is the ability to document the provenance of data used in modeling and reproduce model and data-enabled scientific results. The funded workshop and information collecting activity will be open to all interested parties and is being led by a diverse and expert team of cyberinfrastructure developers, computer scientists, and geoscientists. Broader impacts of the work include converging on approaches, protocols, and standards that may be applicable across the sciences. They also include the fostering of close interaction between communities that do not commonly interact with one another and focusing them on the common goal of creating a new paradigm in data and knowledge management in the geosciences."
"1238196","EarthCube Community Workshop: Designing A Roadmap for Workflows in Geosciences","EAR","Software Institutes, IIS SPECIAL PROJECTS, EarthCube","04/01/2012","03/27/2012","Martyn Clark","CO","University Corporation For Atmospheric Res","Standard Grant","Barbara L. Ransom","03/31/2013","$15,000.00","","mclark@ucar.edu","3090 Center Green Drive","Boulder","CO","803012252","3034971000","GEO","8004, 7484, 8074","7433","$0.00","EarthCube is focused on community-driven development of an integrated and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive, process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems. This awards funds a series of broad, inclusive community interactions to gather adequate information and requirements to create a roadmap for a critical capability (workflow) in the development of EarthCube, a major new NSF initiative. Workflow in the context of EarthCube, and cyberinfrastructure in general, encompasses a broad range of topics including distributed execution management, the coupling of multiple models into composite applications, the integration of a wide range of data sources with processing, and the creation of refined data products from raw data. A key benefit of the funded work in terms of evaluating and creating community consensus on the best way forward for this capability (i.e., workflow) is the ability to document the provenance of data used in modeling and reproduce model and data-enabled scientific results. The funded workshop and information collecting activity will be open to all interested parties and is being led by a diverse and expert team of cyberinfrastructure developers, computer scientists, and geoscientists. Broader impacts of the work include converging on approaches, protocols, and standards that may be applicable across the sciences. They also include the fostering of close interaction between communities that do not commonly interact with one another and focusing them on the common goal of creating a new paradigm in data and knowledge management in the geosciences."
"1256235","Community Engagement to Inform EarthCube Governance","ACI","DATANET, EarthCube","09/01/2012","03/21/2013","Genevieve Pearthree","AZ","Arizona Geological Survey","Standard Grant","Amy Walton","10/31/2013","$252,506.00","Gary Crane, James Bowring","genevieve.pearthree@azgs.az.gov","416 W. Congress St, #100","Tucson","AZ","857011381","5207703500","CSE","7726, 8074","0000, 7433, OTHR, 7726","$0.00","EarthCube is a joint venture between the Directorate of Geosciences and the Office of Cyberinfrastructure at the National Science Foundation. It is a community-driven effort to design and implement an effective data and knowledge management system for the geosciences that will integrates disparate data sets and web services and serves all members of the geoscience community. This planning and assesment project collects and synthesizes the prodigious amount of geoscience and cyberinfrastrucutre community input on possible governance structures for EarthCube that were generated in the run up to the June 2012 EarthCube meeting and actities that have happened during the post meeting timeframe. The project focuses on broadening grass roots geoscience engagement in the process, deepening the input and collecting science-drivers from geoscience communities, and organizing and summarinzing all information so it can be used effectively by the initial EarthCube governance body that will be selected in early 2013. The PI and his outreach team will hold face-to-face and virtual meetings as well as attend and run Town Hall meeings at professional society meetings to engage stakeholders. An important aspect of the project will be to identify community needs and incorporate their suggestions into the final summaries. Project goals also include building stakeholder alignment around shared goals in terms of producing ways to establish standardization of data practices and aspects of its management as well as create a community consensus structure for the evaluation of new tools and utilities. Broader impacts of the work are focused primarily on building infrastructure for science in terms of informing the development of an effective and well received community governance structure."
"1340233","EarthCube Test Enterprise Governance: An Agile Approach","ICER","EarthCube, DATANET","09/15/2013","09/21/2016","Tina Lee","AZ","University of Arizona","Cooperative Agreement","Eva E. Zanzerkia","09/30/2016","$3,599,687.00","Ilya Zaslavsky, Christopher Keane, Erin Robinson, Kimberly Patten","tinal@email.arizona.edu","888 N Euclid Ave","Tucson","AZ","857194824","5206266000","GEO","8074, 7726","7433","$0.00","This project for Test Enterprise Governance outlines an agile model to identify, test and evaluate governance models to manage the development of Geosciences cyberinfrastructure. This model seeks broad engagement and participation of the EarthCube stakeholders to define and assess governance models while seeking evaluation and cross-checks from advisory committees and evaluation mechanisms.<br/><br/>This proposal employs an iterative deployment across the range of EarthCube stakeholders to encourage transparency, consensus, and inclusiveness. A broad coalition of stakeholder groups will comprise the ""Assembly? to serve as a preliminary venue for evaluating and testing governance models in Stage I, while a ""Secretariat"" will act as the coordinating body throughout the project, carrying out duties such as planning, organizing, communicating, and reporting and serve as an a priori governance test scenario itself. To ensure broader end-user participation in evaluating governance models, a ""Crowd-Source? approach will be used for members not involved in the Assembly.<br/><br/>In Stage II, a community selected test governance pilot will be deployed. The organizational structure will be demonstrated and evaluated. The structure and activities related to Stage II demonstration will depend heavily on the outcomes of Stage I. The role of the test governance demonstration is to facilitate community convergence on a reference architecture, procedures for standards, and coordination among emerging EarthCube elements. <br/><br/>The agile approach for Test Enterprise Governance has the potential to advance knowledge by providing community-guided solutions to the governance of cyberinfrastructure for the geosciences. It intends to incorporate multiple science disciplines and encourage broader participation of early career scientists. This proposal encourages cross-disciplinary research and discovery, not only across core science disciplines but also the computer and information sciences.<br/><br/>By building a collaborative, virtual community of practice, this proposal will enable distributed knowledge communities to cooperate, pool resources and work together across disciplines, geography, and cultures. Building upon existing NSF investments in cyberinfrastructure, this proposal allows for, and enables, a diverse set of end users previously unengaged in discussions within cyberinfrastructure - to define expectations, decision-making and leadership processes, leading to a sustainable and adaptable cyberinfrastructure for the geosciences that is extensible and scalable.<br/><br/>A significant responsibility of the Test Enterprise Governance is facilitation of geosciences community activities related to cyberinfrastructure, data policies and standards, and outreach related to these issues. The project will provide web services, forum and other engagement activities to facilitiate this outreach."
"1343761","EarthCube Building Blocks: Specifying and Implementing ODSIP, A Data-Service Invocation Protocol","ICER","EarthCube","09/15/2013","09/19/2013","David Fulker","RI","Open Source Project for Network Data Access Protocols","Standard Grant","Eva E. Zanzerkia","01/31/2017","$802,000.00","Mohan Ramamurthy, Steven Businger, Brian Blanton, Peter Cornillon","d.fulker@opendap.org","165 Dean Knauss Drive","Narragansett","RI","028821124","4012841304","GEO","8074","7433, 9150","$0.00","This EarthCube Building Blocks project intends to build ODSIP (Open Data Services Invocation Protocol) to provide a range of open specification in client/server libraries. The core idea is that key parts of EarthCube can be built effectively around clients and servers that employ a common and conceptually rich protocols for data acquisition. The components will be developed 1) an open specification for ODSIP (as a DAP4 extension); 2) a reference implementation of ODSIP in open-source libraries; and<br/>3) client-server demonstrations that show how ODSIP supports three selected geoscience scenarios, each demonstration to be guided by a geoscientist. The three scenarios are: 1) accelerated visualization/analysis of model outputs on non-rectangular<br/>meshes (over coastal North Carolina); 2) dynamic downscaling of climate predictions for regional utility (over Hawaii); and 3) feature-oriented retrievals of satellite imagery (focusing on satellite-derived sea-surface-temperature fronts).<br/><br/>The broader implications of ODSIP include democratizing the use of geoscience data, illustrated in particular by how two of the three geoscience scenarios will benefit emergency managers and inform decision makers about region-specific risks of climate change. The broader implications also include strengthening common understandings across the EarthCube community."
"1254928","EarthCube GEO Domain Workshop: Cyberinfrastructure for Paleogeoscience","EAR","EarthCube","09/15/2012","11/19/2015","Anders Noren","MN","University of Minnesota-Twin Cities","Standard Grant","Judith Ellen Skog","08/31/2016","$99,994.00","","noren021@umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","GEO","8074","7433","$0.00","EarthCube is a joint venture between the Directorate of Geosciences and the Office of Cyberinfrastructure at the National Science Foundation. It is a community-driven effort to design and implement an effective data and knowledge management system for the geosciences that will integrates disparate data sets and web services and serves all members of the geoscience community. <br/><br/>This award is for a workshop to be convened in Winter 2013, organized around a scientific domain (theme) called ?Paleogeoscience?. The defining characteristics of this broad domain are 1) its focus on past earth system processes and 2) that all scientific inferences in this domain are ultimately based on the collection of physical samples in the field, from which many kinds of geochemical, geobiological, and geophysical measurements are extracted. This domain includes scientists working on paleorecords from: cores drilled in the seafloor, lakebeds, peatlands, continental crust, glaciers or ice sheets, or trees; rock samples hammered from outcrops; fossil remains retrieved from various depositional environments; speleothems; and corals.<br/><br/>Participants will consist of key individuals already working on EarthCube activities, as well as those from this newly formed special interest group. Special efforts will be made to reach out to all members of this diverse community in order to gather as much information about user requirements and other aspects of EarthCube relevant to the ?long tail? of data.<br/><br/>Broader impacts involve the potential to change dramatically the way paleogeoscientists interact with data, whether through discovery of existing data, providing context for new data, characterizing and comparing disparate datasets, or archiving data, in ways that will enable new questions to be answered and existing challenges to be addressed. The impact will likely be at least as great, and possibly greater, for students at the graduate, undergraduate, and even secondary levels (and their teachers), as the simplification of data discovery, visualization, and comparison will allow people with less training to interact with paleogeoscience data in a meaningful way. These tools will facilitate the communication of scientific findings even to policymakers and the public at large."
"1234050","Workshop: MYRES V - The Sedimentary Record of Landscape Dynamics","EAR","GEOPHYSICS, GEOMORPHOLOGY & LAND USE DYNAM, SEDIMENTARY GEO & PALEOBIOLOGY, EarthCube","08/15/2012","08/21/2012","Elizabeth Hajek","PA","Pennsylvania State Univ University Park","Standard Grant","H. Richard Lane","07/31/2014","$70,000.00","","hajek@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","GEO","1574, 7458, 7459, 8074","7433","$0.00","Workshop: MYRES V - The Sedimentary Record of Landscape Dynamics<br/><br/>by <br/><br/>Elizabeth Hajek, EAR-1234050, PennState Univ. <br/><br/>ABSTRACT<br/>Sedimentary deposits comprise important records of information necessary to 1) quantitatively reconstruct and predict landscape dynamics across a range of timescales, 2) identify ancient tectonic and climatic conditions on Earth, and 3) understand landscape response to tectonic and climatic forcing. An outstanding challenge for geoscientists is to decode this archive in order to understand the evolution of Earth's environments over a range of temporal and spatial scales. To this end, the research interests of geomorphologists, sedimentologists, and stratigraphers have started to converge on processes that produce, transport, and deposit sediment over millennial timescales and beyond. Virtual Workshop and the final two days will revolve around discussion-stimulating field trips through erosional landscapes and stratigraphic deposits in Central Utah. This will be the fifth biennial Meeting of Young Researchers in Earth Science (MYRES) meeting. Early-career faculty and research scientists who participated in previous MYRES workshops have become leaders in their fields and helped build foundations for ongoing interdisciplinary collaborations. Continued support of MYRES will sustain and strengthen this grassroots initiative that has helped jumpstart research in important cutting-edge areas of Earth science. As part of interdisciplinary community building and communication during MYRES V, time will be dedicated to learning about the NSF's EarthCube initiative and discussing how collaborative efforts between geodynamicists, geomorphologists, sedimentologists and stratigraphers (and others) could be aided by EarthCube. To this end, plenary discussion on the third day of the workshop will comprise a virtual workshop about EarthCube. This workshop will be hosted online (e.g., via Skype), will include EarthCube representatives, and, if possible, other interested virtual attendees. Throughout the MYRES V workshop we will be discussing many topics listed in the EarthCube GEO Domain Virtual Workshop Goals, including 1) science drivers within and beyond MYRES V fields in the immediate future and up to 15 years out, 2) current challenges and limitations to interdisciplinary science (including data discovery, modeling, integrating disparate data types and sources, etc.), 3) existing database and modeling resources, and 4) tools, databases, and modeling capabilities that MYRES V communities would like to see developed."
"1440294","EarthCube Building Blocks: CyberConnector: Bridging the Earth Observations and Earth Science Modeling for Supporting Model Validation, Verification, and Inter-comparison","ICER","EarthCube","09/01/2014","08/12/2014","Liping Di","VA","George Mason University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$1,000,000.00","Ben Domenico, Xiaoqing Wu, Haosheng Huang, Quansong Tong","ldi@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","GEO","8074","7433","$0.00","The project will 1) significantly increase research productivity in the Earth science modeling community, 2) enable the effective use of the existing Sensor Web data and Earth Observations through open Web interfaces and metadata standards, 3) foster collaborations among Earth system modelers, geospatial information scientists, and information technologists, and 4) enhance infrastructure for Earth science research and education. CyberConnector will free scientists from the laborious preparation of model inputs and release of model outputs. It will automatically process the Earth Observation data into the right products in the right form needed for Earth Systems Model initialization, validation, and inter-comparison.<br/><br/>This project developes an EarthCube building block, called CyberConnector, for facilitating the automatic preparation and feeding of both historic and near-real time Earth Observation customized data and on-demand derived products into Earth science models. will automatically process the EO data into the right products in the right form needed for ESM initialization, validation, and inter-comparison. It can support many different ESMs through its standard interfaces under a unified framework. CyberConnector can also automatically serve the model outputs in interoperable forms through standard data services to facilitate rapid inter-model comparison and support the societal applications of the model outputs. Recent EarthCube end-user workshops indicate the proposed capabilities of the CyberConnector are at the top of the wish lists of multiple Earth science communities. To achieve these capabilities, this project leverages the online availability of huge volume of EO data at EO cyberinfrastructure of NSF (e.g., Unidata, NEON), other federal agencies (NASA, NOAA, USGS), and international EO organizations (e.g., CEOS members), advancements in standard-based geospatial web service and sensor web technologies, and successful cyber-systems built by the investigators of this proposal and others (e.g., GeoBrain, SEPS, GEOSS, and CWIC). The proposed project will closely collaborate with other EarthCube building block teams and end-user communities. The ISO geospatial data and metadata standards and standard-based geospatial web service, workflows, and sensor web technologies are the foundation for this project.The Cloud-Resolving Model (CRM), the Community Multi-scale Air Quality Model (CMAQ), the Finite Volume Coastal Ocean Model (FVCOM), and the Grassland and Agroecosystem Dynamics Model (CENTURY) will be used as examples in this project to test, validate, and demonstrate the capabilities and functionality of CyberConnector.The CyberConnector approach is a general one that can support many different Earth system models through the standard interfaces and the geospatial processing model (GPM) mechanism"
"1338892","EarthCube GEO Domain Workshop: Articulating Cyberinfrastructure Needs of the Ocean Ecosystem Dynamics Community","OCE","EarthCube","04/15/2013","04/10/2013","Danie Kinkade","MA","Woods Hole Oceanographic Institution","Standard Grant","Barbara L. Ransom","03/31/2015","$97,114.00","Robert Groman, Peter Wiebe, David Glover, Cynthia Chandler","dkinkade@whoi.edu","183 OYSTER POND ROAD","WOODS HOLE","MA","025431041","5082893542","GEO","8074","0000, 7433, OTHR","$0.00","Ocean ecosystem dynamics encompasses a broad array of disciplines that seek to increase our understanding of the interplay between the physical, biological, and chemical processes in the ocean. Ocean ecosystem dynamics studies include ocean productivity, population dynamics, biogeography, and biogeochemistry. It is an interdisciplinary science that produces highly diverse data types that pose unique challenges for data management, integration, and analysis. The goal of this workshop is to surface requirements in this important ocean science arena for a major new NSF data and knowledge management initiative (i.e., EarthCube) that is dedicated to revolutionizing geoscience by providing easy access to, discovery of, and visualization of data from across the geo- and environmental sciences. This workshop will bring together ~50 ocean water column scientists to identify science drivers in the next 15 years in the ocean ecosystem dynamics field and inform the EarthCube process about the data and cyberinfrastructure needs of the associated scientific community. Issues of different scales in time and space of both data and modeling efforts will be discussed in reference to oceans, coastal waters, and the Great Lakes. The workshop will also include cyber/computer science experts; and together workshop participants will collectively define future science goals and focus on identifying the most critical, widespread, cyberinfrastructure and data management issues and problems holding back scientific advances in the area of ocean ecosystem dynamics. Workshop participants will also discuss needs in software and visualization that are needed to better understand and model both present and new data. Broader impacts of the work include building infrastructure for science by identifying needs that will help to shape the final form of EarthCube cyberinfrastructure, support of two PIs whose gender is under-represented in the sciences and engineering, and engagement of early career scientists. A virtual component of the workshop will be held to help broaden participation beyond those present on-site."
"1240144","EarthCube Assessment of the 2012 State of Geoinformatics: A Community and Interagency Exploration of the LifeCycle, Citation, and Integration of Geoscience Data","EAR","EarthCube","06/01/2012","02/12/2014","Peter Fox","NY","Rensselaer Polytechnic Institute","Standard Grant","Barbara L. Ransom","05/31/2015","$99,999.00","","foxp@rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","GEO","8074","7433","$0.00","EarthCube is focused on community-driven development of an integrated and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems. This award funds broad, inclusive community interactions and a follow-on workshop to GeoData 2011 which will address gaps in the funding portfolio and development of EarthCube, a major new NSF initiative. Some of these gaps include unresolved issues related to data accessibility and attribution. Others involve interagency planning for improving interoperability and integration of large Federal data repositories with academic datasets and data management facilities. The funded workshop and associated conversations will be open and available to the public via virtual participation of interested parties not included in the list of invitees. Broader impacts of the work include fostering of close interaction between communities and federal agencies that do not presently effectively interact with one another and to build alignment around a common goal of creating a new, interoperable paradigm in data and knowledge management in the geosciences."
"1239841","Toward Cyber-Infrastructure 2025: Addressing Critical Milestones for EarthCube","EAR","EarthCube","04/01/2012","03/28/2012","Siri Jodha Khalsa","CO","University of Colorado at Boulder","Standard Grant","Barbara L. Ransom","03/31/2013","$218,524.00","Ruth Duerr, Mark Parsons, Francoise Pearlman, Jay Pearlman","khalsa@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","GEO","8074","7433, 7916","$0.00","This EAGER award promotes a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube. Led by a team of experts from academia and the private section, the funded work is focused on developing the key EarthCube cyberinfrastructure capability of brokering, which among other things enables sharing of very diverse data across disciplinary and technological boundaries. It also allows data repositories to easily expose and make discoverable their data to potential users via multiple standards and services. The approach employed utilizes an inclusive, community-driven, collaborative approach to the problem and emphasizes the testing and evaluation of different brokering technologies using community-agreed upon standard datasets and applications, such as water sustainability, geohazards, biodiversity loss, and climate change. The work substantially and positively impacts our ability to carry out quantitative data-enabled research in the geo- and environmental sciences. The project includes technical assessments of existing technologies, the development of a brokering roadmap that will mature ideas and technology over the next few years, and will engage a broad and diverse community of geoscientists, cyberinfrastructure developers, and computer scientists. Broader impacts of the work include maturation of a key capability that is required for the realization of EarthCube, a new NSF initiative in geoscience knowledge and data management, the engagement of a broad spectrum of individuals from the geoscience, cyberinfrastructure, and computer science communities, the inclusion of members of under-represented groups in the leadership team, and international collaboration with partners in France, Germany, and Canada."
"1340301","EarthCube RCN: C4P: Collaboration and Cyberinfrastructure for Paleogeosciences","ICER","EarthCube","09/15/2013","08/23/2013","Kerstin Lehnert","NY","Columbia University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$299,381.00","John Williams, Christopher Jenkins, Mark Uhen","lehnert@ldeo.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","GEO","8074","7433","$0.00","This project establishes and operates the EarthCube Research Coordination Network (RCN)<br/>Collaboration and Cyberinfrastructure for Paleogeosciences (C4P) to advance the role of cyberinfrastructure<br/>(CI) in unraveling the large-scale, long-term evolution of the Earth-Life System through the<br/>study of the geological record.Paleogeosciences research into our large-scale, long-term Earth-Life system is an ambitious<br/>program that informs public debate on human stewardship of the earth and has - since its inception<br/>- caught public imagination on issues such as species survival under environmental changes.<br/>In the last decade, fresh discoveries, plus the application of new technologies of measurement,<br/>data analysis, and modeling have revitalized the science. Bringing to bear recent advances<br/>in computing and mathematics will further quicken the pace of discoveries, synthesis and publication<br/>in the science. This RCN intends to stimulate and grow CI-focused collaborations and<br/>partnerships among paleogeoscientists, paleobiologists, bioinformaticists, stratigraphers,<br/>geochronologists, geographers, data scientists, and computer scientists that will help dissolve<br/>existing intellectual barriers to dramatically improve the application of modern data management<br/>approaches, data mining technologies, and computational methods to better analyze the heterogeneous<br/>and sparse data of the Earth record in sediments, rocks, and ice within the paleogeosciences<br/>and other domains and disciplines.<br/><br/>Activities envisioned include a series of coordinated workshops and webinars, web-enabled networking, outreach events such<br/>as symposia and town-hall meetings, and cross-EarthCube coordination, and creation of an interoperable<br/>C4P resource catalog that will be integrated with other EarthCube resource inventories. High-priority<br/>themes in C4P are the management and representation of age and age uncertainty in data models<br/>and computation to advance interoperability among and analysis of time-referenced data types,<br/>the integration of physical samples into digital data infrastructure, and the need to properly<br/>track and attribute provenance of data to ensure trust in the data and credit to authors."
"1343130","EarthCube domain end-user workshop: Bringing Geochronology into the EarthCube framework","EAR","EarthCube","08/01/2013","07/11/2013","Bradley Singer","WI","University of Wisconsin-Madison","Standard Grant","Russell C. Kelz","07/31/2014","$100,000.00","Shanan Peters","bsinger@geology.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","GEO","8074","7433","$0.00","1343130 <br/>Singer<br/><br/>This grant supports a GEO EarthCube topical workshop with a focus on cyberinfrastructure issues germane to geological dating techniques and their digital publication. The workshop seeks to engage approximately 70 geochronologists and geoscientists with the intent to: 1) develop a set of unifying requirements for the organization of geochronology data; and 2) explore methods for developing and sustaining an interactive community of domain and cyber-scientists to pursue next-generation solutions to the identified challenges. The workshop will include invited talks followed by multiple breakout groups to discuss and produce draft documents focused on: 1) specific scientific challenges and opportunities in Geochronology over the next 5-15 years; 2) identification of the data and cyber-infrastructure obstacles to meeting those challenges; 3) a compilation of known community data and modeling resources; 4) description of data and cyber-capabilities required to meet challenges; and 5) development of ideas for at least two ?proof-of-concept? projects or test cases for scientifically transformative CI activities.<br/><br/>Nothing is more fundamental to understanding Earth history and processes than geochronology and the expense incurred in producing robust and high resolution dates implores NSF to help find a modern digital solution(s) for maintaining the integrity of these data sets and promoting access as broadly as possible in support of the advancement of the geosciences. This workshop will help to address many of the issues that continue to hamper geochonological data curation, digital publication and community access."
"1419015","EarthCube Domain End-User Workshop: Science-Driven Cyberinfrastructure Needs in Solar-Terrestrial Research; Newark, New Jersey; Spring 2014","AGS","EarthCube","03/01/2014","02/19/2014","Gelu Nita","NJ","New Jersey Institute of Technology","Standard Grant","Ilia I. Roussev","02/28/2015","$99,979.00","Alexander Kosovichev, Dale Gary, Gregory Fleishman, Andrew Gerrard","gnita@njit.edu","323 DOCTOR MARTIN LUTHER","Newark","NJ","071021982","9735965275","GEO","8074","1523, 4444, 7433, 7556, OTHR","$0.00","The purpose of this 1-year project is to organize a 2.5-day EarthCube Workshop that brings together experts in observations, theory, data analysis, data-driven 3D modeling, data management and high performance computing of the Sun-Earth system. The goal is to identify the current challenges and cyberinfrastructure needs related the access, sharing, visualization and synthesis of the existing and future large, multi-wavelength datasets covering solar-terrestrial observations and modeling all the way from the surface of the Sun to the Earth's upper atmosphere. The intellectual merit of this activity will materialize in two ways. The workshop will introduce the solar-terrestrial community to the general vision behind the EarthCube framework while providing consensus feedback from this community to the EarthCube initiative. The scientific challenges and related cyberinfrastructure needs identified during this workshop will drive subsequent activities aiming to implement cyberinfrastructure solutions. These activities will result in expanding the computing infrastructure of the participating universities and accommodate postdoctoral and graduate student involvement from a wide range of disciplines including physics, computer sciences, and mathematics; thus, these activities will advance discovery and understanding while promoting teaching, training and learning, which will directly impact the students' careers. Such activities will facilitate the transfer of innovative data analysis, data visualization, and data-driven modeling techniques to other fields of research that may benefit from a similar framework."
"1639759","EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications","ICER","EarthCube","09/01/2016","09/16/2016","Tanu Malik","IL","DePaul University","Standard Grant","Eva E. Zanzerkia","08/31/2018","$783,999.00","Ian Foster","tanu@cdm.depaul.edu","1 East Jackson Boulevard","Chicago","IL","606042287","3123627595","GEO","8074","7433","$0.00","Scientific reproducibility -- the ability to independently verify the work of other scientists -- continues to be a critical barrier towards achieving the vision of cross-disciplinary science. Federal agencies and publishers increasingly mandate and incentivize scientists to, at a minimum, establish computational reproducibility of scientific experiments. To comply scientists must connect descriptions of scientific experiments in scholarly publications with the underlying data and code used to produce the published results and findings. However, in practice, computational reproducibility is hard to achieve since it entails isolating necessary and sufficient computational artifacts and then preserving those artifacts in a standard way for later re-execution. Both isolation and preservation present challenges in large part due to the complexity of existing software and systems as well as the implicit dependencies, resource distribution, and shifting compatibility of systems that evolve over time -- all of which conspire to break the reproducibility of an experiment. The goal of the GeoTrust project is to understand the research lifecycle of scientific experiments from conception to publication and establish a framework that will improve their reproducibility. <br/><br/>GeoTrust will develop sandboxing-based systems and tools that help scientists effectively isolate computational artifacts associated with an experiment, use languages and semantics to preserve artifacts, and re-execute /reproduce experiments by deploying the artifacts, changing datasets, algorithms, models, environments, etc. This reproducible framework will be adopted by and integrated within community infrastructures of three geoscience sub-disciplines viz. Hydrology, Solid Earth, and Space Science. Using cross-disciplinary science uses cases from these sub-disciplines, and engaging independent evaluators, we will assess the effectiveness of the framework in achieving reproducibility of computational experiments. Finally, verified results will be associated with ?stamps of reproducibility?, establishing community recognition of computational experiments. The framework will be developed as an EarthCube capability, with software developed and released as per EarthCube requirements. Early adopters across other geoscience sub-disciplines will be continually sought."
"1639706","EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications","ICER","EarthCube","09/01/2016","09/16/2016","Eunseo Choi","TN","University of Memphis","Standard Grant","Eva E. Zanzerkia","08/31/2018","$80,000.00","","echoi2@memphis.edu","Administration 315","Memphis","TN","381523370","9016782533","GEO","8074","7433, 9150","$0.00","Scientific reproducibility -- the ability to independently verify the work of other scientists -- continues to be a critical barrier towards achieving the vision of cross-disciplinary science. Federal agencies and publishers increasingly mandate and incentivize scientists to, at a minimum, establish computational reproducibility of scientific experiments. To comply scientists must connect descriptions of scientific experiments in scholarly publications with the underlying data and code used to produce the published results and findings. However, in practice, computational reproducibility is hard to achieve since it entails isolating necessary and sufficient computational artifacts and then preserving those artifacts in a standard way for later re-execution. Both isolation and preservation present challenges in large part due to the complexity of existing software and systems as well as the implicit dependencies, resource distribution, and shifting compatibility of systems that evolve over time -- all of which conspire to break the reproducibility of an experiment. The goal of the GeoTrust project is to understand the research lifecycle of scientific experiments from conception to publication and establish a framework that will improve their reproducibility. <br/><br/>GeoTrust will develop sandboxing-based systems and tools that help scientists effectively isolate computational artifacts associated with an experiment, use languages and semantics to preserve artifacts, and re-execute /reproduce experiments by deploying the artifacts, changing datasets, algorithms, models, environments, etc. This reproducible framework will be adopted by and integrated within community infrastructures of three geoscience sub-disciplines viz. Hydrology, Solid Earth, and Space Science. Using cross-disciplinary science uses cases from these sub-disciplines, and engaging independent evaluators, we will assess the effectiveness of the framework in achieving reproducibility of computational experiments. Finally, verified results will be associated with ?stamps of reproducibility?, establishing community recognition of computational experiments. The framework will be developed as an EarthCube capability, with software developed and released as per EarthCube requirements. Early adopters across other geoscience sub-disciplines will be continually sought."
"1541009","EarthCube IA: Magnetosphere-Ionosphere-Atmosphere Coupling","ICER","EarthCube","09/15/2015","09/15/2015","Jesper Gjerloev","MD","Johns Hopkins University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$697,809.00","Gary Bust, Robin Barnes, Ethan Miller, Brian Anderson","Jesper.Gjerloev@jhuapl.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","GEO","8074","7433","$0.00","The scientific work proposed here will carry out the research and development necessary to create a new, unique set of high-latitude electro-dynamic, ionospheric-thermospheric-&#8208;magnetospheric cyberbased tools and products that will be available to the entire geosciences community. In combination, the data products from this project will allow the derivation of a first principle electromagnetic solution for the auroral ionosphere. Project will develop a new set of data resources for the geoscience community in the form of a complete electromagnetic solution of the auroral ionosphere and will focus on developing the ?Data Infrastructure for Communities? component of the EarthCube Integrative Activities. The project will thus allow access to not only the desired derived products, but also provide support for other modeling efforts by allowing access to the database of input data and intermediary products. The system will also be designed to be extensible, allowing additional data products and models to be integrated into the system. The system will fully support existing standards that are used in the broader geosciences community such as the Data Access Protocol (DAP).The research undertaken in this proposal will enable transformative research in two otherwise separated fields: magnetosphere-&#8208;ionosphere and neutral atmosphere. <br/><br/>The MIAC project addresses the complete electromagnetic solution of the auroral ionosphere, through an implementation that matches the goals of the EarthCube program. The intent is to develop a series of interlocking web services that provide access to the underlying MIAC datasets (AMPERE, SuperDARN and SuperMAG), that apply the science algorithms to derive the desired electro- dynamic products, and provide data translation and visualization services. This mesh of services will be open to the community and will allow users to access any individual service. The research undertaken in this project will enable transformative research in two otherwise separated fields: magnetosphere-&#8208;ionosphere and neutral atmosphere through a) the high-&#8208;latitude electro-&#8208;dynamics couple to the incoming solar wind and magnetosphere along magnetic field lines; b) the changes in the ionosphere and thermosphere at high latitudes provide changes to the conductivities throughout the polar region, which then effect the dynamics in the magnetosphere; c) the electrodynamic energy and momentum inputs get deposited in the upper atmosphere and launch neutral winds that then couple to ion velocities and transport compositional changes to the mid and low latitudes; d) the winds and composition couple to waves impinging from the lower atmosphere."
"1308994","Collaborative Research: An EarthCube Domain Workshop integrating the inland-waters biogeochemistry and fluvial sedimentology communities, April 22-24.","EAR","EarthCube","04/01/2013","03/29/2013","Emilio Mayorga","WA","University of Washington","Standard Grant","hailiang dong","03/31/2014","$10,900.00","","mayorga@apl.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","GEO","8074","7433","$0.00","Continental surface waters represent distinct environments that are hot spots of biogeochemical storage and transformation, as well as conduits for large-scale material transport to the oceans and atmosphere. These systems are integral components of global geochemical cycles, are intertwined with human health and economic activity, and are highly sensitive to anthropogenic impacts. Without data from a wide variety of disciplines, such as organic and physical chemistry, ecosystem science, sedimentology, landscape evolution, water-rock interaction, and element and material cycles (weathering products, trace elements, carbon burial, nutrient fluxes, mineral particles, etc.), it is not possible to realistically model these important surface water systems and understand the complex interactions between their various physical and biological components. Data necessary to populate such models comes from field-based, experimental, laboratory, and theoretical work, involving short research projects, long-term research observatories, and water quality monitoring systems. The goal of this workshop is to surface requirements in the fields of river and fresh water biogeochemical studies for a major new NSF data and knowledge management initiative (i.e., EarthCube) that is dedicated to revolutionizing geoscience by providing easy access to, discovery of, and visualization of data from across the geo- and environmental sciences. This workshop will bring together ~60 geoscientists from across the US who come from relevant disciplines, including cyber/computer science experts, this coallition of parties will have a job to collectively define future science goals in this important arena. It will also be used to identify the most critical, widespread needs shared by those working on surface water and fresh water biogeochemical problems and to guide the development of NSF EarthCube cyberinfrastructure for this community. The workshop will also focus on strategies that help scientists and data that they need to cross sub-discipline barriers. Discussions will encompass all aspects of experimental, in-situ, geospatial, and modeling data as well as address issues related to quantitative analytical and scaling approaches that enable the integration of observations. Workshop participants will also address topics such as process rates along flow paths ranging from short scales such as sediment-water interfaces, to continental-scale basins. Progress addressing these needs in a coordinated fashion across sub-disciplines has the potential to lead to transformative advancements in this dispersed but critical intersection of research communities. Broader impacts of the work center primarily on building infrastructure for science."
"1343133","EarthCube End-User Domain Workshop for Rock Deformation and Mineral Physics Research","EAR","EarthCube","06/15/2013","06/07/2013","Chris Marone","PA","Pennsylvania State Univ University Park","Standard Grant","Robin Reichlin","05/31/2015","$99,999.00","Jay Bass","cjm38@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","GEO","8074","7433","$0.00","This workshop is to bring together the Rock Mechanics and COMPRESS Mineral Physics communities to gather requirements for the NSF-funded EarthCube initiative whose goal is to design and implement a new data and knowledge management system for the geosciences. The workshop will assemble a group of about 70 experts in rock deformation and high-pressure mineral physics to discuss their cyberinfrastructure needs in terms of data, modeling, and visualization. Goals will be to surface cyberinfrastructure needs that are presently holding these communities back and to enable their ability to address fault-slip behaviors, brittle-ductile transitions in lithologic materials, scientific drilling, deformation processes in subduction zones, and the physical, chemical, and electronic properties of geologic materials in the deep Earth. The two and a half day workshop will be held in Alexandria, Virginia in early November of 2013. A catalyzing issue of the workshop concerns the nature and reporting of experimental and observational data. Addressing these cyberinfrastructure needs represents a fundamental challenge to digital representation/integration and allowance of broad public access to data from this field that can be aided by involvement with EarthCube. This project is important for both the scientific and cyberinfrastructure development of the geosciences. Future progress of the geosciences will be based on the integration of rich and diverse datasets. This workshop will identify the needs of one of the most important and societally relevant groups in Earth Science. There will be a vast array of intellectually challenging tasks in describing and integrating data across a spectrum of scales as well as granularity that will be addressed at the workshop. Broader impacts of the work include provisions for improving public access to data from these fields, especially for those interested in studying earthquakes or assessing and manageing their impacts. it also builds infrastructure for science in terms of helping create more effective and interoperable data and modeling frameworks. The workshop will also emphasize the inclusion of early career researchers, thus ensuring the needs are met of the next generation of rock deformation professionals."
"1310644","Collaborative Research: An EarthCube Domain Workshop integrating the inland-waters biogeochemistry and fluvial sedimentology communities, April 22-24.","EAR","EarthCube","04/01/2013","03/29/2013","Albert Kettner","CO","University of Colorado at Boulder","Standard Grant","Hailiang Dong","03/31/2015","$88,622.00","","kettner@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","GEO","8074","7433","$0.00","Continental surface waters represent distinct environments that are hot spots of biogeochemical storage and transformation, as well as conduits for large-scale material transport to the oceans and atmosphere. These systems are integral components of global geochemical cycles, are intertwined with human health and economic activity, and are highly sensitive to anthropogenic impacts. Without data from a wide variety of disciplines, such as organic and physical chemistry, ecosystem science, sedimentology, landscape evolution, water-rock interaction, and element and material cycles (weathering products, trace elements, carbon burial, nutrient fluxes, mineral particles, etc.), it is not possible to realistically model these important surface water systems and understand the complex interactions between their various physical and biological components. Data necessary to populate such models comes from field-based, experimental, laboratory, and theoretical work, involving short research projects, long-term research observatories, and water quality monitoring systems. The goal of this workshop is to surface requirements in the fields of river and fresh water biogeochemical studies for a major new NSF data and knowledge management initiative (i.e., EarthCube) that is dedicated to revolutionizing geoscience by providing easy access to, discovery of, and visualization of data from across the geo- and environmental sciences. This workshop will bring together ~60 geoscientists from across the US who come from relevant disciplines, including cyber/computer science experts, this coallition of parties will have a job to collectively define future science goals in this important arena. It will also be used to identify the most critical, widespread needs shared by those working on surface water and fresh water biogeochemical problems and to guide the development of NSF EarthCube cyberinfrastructure for this community. The workshop will also focus on strategies that help scientists and data that they need to cross sub-discipline barriers. Discussions will encompass all aspects of experimental, in-situ, geospatial, and modeling data as well as address issues related to quantitative analytical and scaling approaches that enable the integration of observations. Workshop participants will also address topics such as process rates along flow paths ranging from short scales such as sediment-water interfaces, to continental-scale basins. Progress addressing these needs in a coordinated fashion across sub-disciplines has the potential to lead to transformative advancements in this dispersed but critical intersection of research communities. Broader impacts of the work center primarily on building infrastructure for science."
"1343709","EarthCube Building Blocks: Deploying Web Services Across Multiple Geoscience Domains","ICER","EarthCube","09/15/2013","09/09/2013","Timothy Ahern","DC","Incorporated Research Institutions for Seismology","Standard Grant","Eva E. Zanzerkia","08/31/2016","$1,783,919.00","Ilya Zaslavsky, Michael Gurnis, Mohan Ramamurthy, Suzanne Carbotte","tim@iris.washington.edu","1200 New York Avenue, NW","Washington","DC","200056142","2026822220","GEO","8074","7433","$0.00","This Building Blocks project intends to extend the promotion of simple web services to simplify the task of discovering, accessing and using data from multiple sources. The investigators will promote the use of this system to manage data from the long tail of science and make it discoverable, removing it from the domain of ""dark data"". Long tail data will come from both funded partner centers and from collaborators. They will extend their approach of exposing data sets through web services to those managed by non-NSF data centers both within the US as well as international data sets by providing resources to stand up web services<br/>to expose the data holdings of other centers. A recurring theme in the EarthCube Domain Workshops was the need to simplify the workflows for sharing and discovery of data in geosciences. A significant amount of time is currently spent as ""hunters and gatherers"" of information and once finding that information to determine<br/>how to understand and use data from domains outside a given researcher?s area of expertise. The development of the web services building block will significantly change the way in which much of the preparatory work will be accomplished. This building block will also develop the ability to expose ""dark data"". The balance between the time spent on preparing and doing science will be reversed from the current state where the majority of time is spent in preparation and the minority of the time spent on doing the science. This will in itself have extremely broad impacts in geosciences research. The web services building blocks inherently enable horizontal integration across the geosciences with a resulting impact on the breadth of geosciences<br/>problems that can be addressed.<br/><br/>The proposed expansion of simple web services into the geosciences will fundamentally change the way geoscientists do their research, combine information from across disciplines and communicate their results to the public, policy makers and educators.Exposing such data will significantly add to the body of knowledge<br/>that can be brought to bear on geosciences problems. As problems become more and more complex, the diversity of data sets that must be considered and integrated for a better understanding of a vast range of geoscience problems will increase, and enhanced technologies and procedures will be required to synthesize and communicate the resulting knowledge between scientist and with the public. This building block is an effort to support that transition by engaging EarthCube cyberinfrastructure in developing, establishing and adopting international standards to allow geoscientists to focus on the science, thus increasing their productivity."
"1440084","EarthCube Building Blocks: Collaborative Proposal: Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS)","ICER","EarthCube","09/01/2014","08/06/2014","Frank Vernon","CA","University of California-San Diego Scripps Inst of Oceanography","Standard Grant","Eva E. Zanzerkia","08/31/2016","$20,000.00","","flvernon@ucsd.edu","8602 La Jolla Shores Dr","LA JOLLA","CA","920930210","8585341293","GEO","8074","7433","$0.00","The importance of real-time scientific data is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Furthermore, advances in the distribution of real-time data are leading many new transient phenomena in space-time to be observed. Presently however, realtime decision-making is infeasible in many cases that require streaming scientific data to be coupled with complex models. While EarthCube will provide an unprecedented framework for disseminating data sources, the use of real-time data raises an additional set of complex challenges that must be considered. This project is a pilot to demonstrate the importance of coodinating the geosciences around their real-time data gathering and use. The work will demonstrate a Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS)<br/><br/>The vision behind CHORDS is to provide a real-time data management infrastructure that will: a)Provide a system to archive, navigate and distribute real-time data streams via the Internet; b)Be easily deployed and configured; c)Run on cloud infrastructure; d)Use transactions built on RESTful protocols (i.e. via URLs); e)Employ data and metadata formats that adhere to standards, which simplify the user experience; f)Be free and open source.Science derived from observing platform data is the result of years of planning before a deployment, for example, and millions of dollars are spent on the deployment itself in hopes of obtaining the desired dataset. Many geo-scientific experiments are often resource constrained. In such cases it is vital to guarantee the optimal allocation of resources to ensure that important events do not go unobserved. In geo-scientific domains it is not uncommon to analyze data after a field campaigns, only to detect sensor faults, calibration offsets or anomalous behaviors when it is already too late. Real-time data will enable the optimal allocation of constrained experimental resources by automating the detection of faults and anomalies. CHORDS will provide a framework to enable adaptive sampling, discovery and fusion of various real-time geoscientific data sources, thus facilitating a new means by which geoscience experiments are carried out. The use cases will illustrate this by showing traditional experiments would have missed events of interest due to lack of access to real-time data. Focus on the initial work of defining requirements, design and specifications. Begin to ingest a small subset of geosciences data streams into a prototype CHORDS structure built in the cloud. Participate in activities that strengthen the integration of real-time data being ingested via CHORDS into other EarthCube Building Block systems that are under development. They will focus on some initial test cases, in hydrology sensor data, radar data streams, the NCAR Lower Atmosphere Observing Facilities, and outreach to earth and oceans communities."
"1541007","EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory","ICER","EarthCube","09/01/2015","07/28/2015","J. Michael Ruohoniemi","VA","Virginia Polytechnic Institute and State University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$72,116.00","","mikeruo@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","GEO","8074","7433","$0.00","The habitability of planet Earth depends on a complex interaction between interior regions, solid surface, oceans, atmosphere, near-earth space environment, and Sun. Yet, study of this Sun-Earth system is traditionally broken up into separate geoscience disciplines, so that progress can be made by scientists working in reasonably-sized communities that share a common language and base of knowledge. To broach the bigger question of the interaction of the subsystems studied by the separate communities, it is necessary to overcome the barriers of communication posed by different observational instruments, software tools for interpreting data, and modeling methods. In answer to this challenge, the Integrated Geoscience Observatory is a pilot project that creates an online platform for integrating data and associated software tools contributed by separate geoscience research communities, into a unified toolset that brings them together. The vision is to expand the individual domains of geoscience research toward study of the whole Sun-Earth system, and in so doing to uncover the system level effects critical to the habitability of planet Earth.<br/><br/>EarthCube aims to develop a framework for assisting researchers in understanding the Earth system. This systems science challenge is recognized in the Decadal Survey in Solar and Space Physics [2012], with the conclusion ""Data from diverse space- and ground-based instruments need to be routinely combined in order to maximize their multi-scale potential."" The Integrated Geoscience Observatory is a pilot project that explores realization of this vision by focusing on the limited context of geospace research. The observatory creates an integrated package of software tools contributed by researchers with specific capabilities, and designed to enable integration of diverse observational data. Features of the toolkit include: (A) linking diverse data sets from multiple data repositories and automatically mapping them to a common user-specified coordinate grid; (B) implementing the well-known Assimilative Mapping of Ionospheric Electrodynamics (AMIE) procedure for assimilation of this data to yield a global picture; and (C) utilization of the EarthCube building blocks GeoSoft, for communicating ontology, and GeoDataspace, for attributing credit to contributors through publication of processed data. The toolset can be accessed and used either through a web-based computing environment, or through download packages for local installation, with a nearly seamless transition between the two."
"1639741","EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications","ICER","EarthCube","09/01/2016","09/16/2016","Asti Bhatt","CA","SRI International","Standard Grant","Eva E. Zanzerkia","08/31/2018","$104,999.00","","asti.bhatt@sri.com","333 RAVENSWOOD AVE","Menlo Park","CA","940253493","6508592651","GEO","8074","7433","$0.00","Scientific reproducibility -- the ability to independently verify the work of other scientists -- continues to be a critical barrier towards achieving the vision of cross-disciplinary science. Federal agencies and publishers increasingly mandate and incentivize scientists to, at a minimum, establish computational reproducibility of scientific experiments. To comply scientists must connect descriptions of scientific experiments in scholarly publications with the underlying data and code used to produce the published results and findings. However, in practice, computational reproducibility is hard to achieve since it entails isolating necessary and sufficient computational artifacts and then preserving those artifacts in a standard way for later re-execution. Both isolation and preservation present challenges in large part due to the complexity of existing software and systems as well as the implicit dependencies, resource distribution, and shifting compatibility of systems that evolve over time -- all of which conspire to break the reproducibility of an experiment. The goal of the GeoTrust project is to understand the research lifecycle of scientific experiments from conception to publication and establish a framework that will improve their reproducibility. <br/><br/>GeoTrust will develop sandboxing-based systems and tools that help scientists effectively isolate computational artifacts associated with an experiment, use languages and semantics to preserve artifacts, and re-execute /reproduce experiments by deploying the artifacts, changing datasets, algorithms, models, environments, etc. This reproducible framework will be adopted by and integrated within community infrastructures of three geoscience sub-disciplines viz. Hydrology, Solid Earth, and Space Science. Using cross-disciplinary science uses cases from these sub-disciplines, and engaging independent evaluators, we will assess the effectiveness of the framework in achieving reproducibility of computational experiments. Finally, verified results will be associated with ?stamps of reproducibility?, establishing community recognition of computational experiments. The framework will be developed as an EarthCube capability, with software developed and released as per EarthCube requirements. Early adopters across other geoscience sub-disciplines will be continually sought."
"1639696","EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications","ICER","EarthCube","09/01/2016","09/16/2016","Jonathan Goodall","VA","University of Virginia Main Campus","Standard Grant","Eva E. Zanzerkia","08/31/2018","$110,000.00","","goodall@virginia.edu","P.O. BOX 400195","CHARLOTTESVILLE","VA","229044195","4349244270","GEO","8074","7433","$0.00","Scientific reproducibility -- the ability to independently verify the work of other scientists -- continues to be a critical barrier towards achieving the vision of cross-disciplinary science. Federal agencies and publishers increasingly mandate and incentivize scientists to, at a minimum, establish computational reproducibility of scientific experiments. To comply scientists must connect descriptions of scientific experiments in scholarly publications with the underlying data and code used to produce the published results and findings. However, in practice, computational reproducibility is hard to achieve since it entails isolating necessary and sufficient computational artifacts and then preserving those artifacts in a standard way for later re-execution. Both isolation and preservation present challenges in large part due to the complexity of existing software and systems as well as the implicit dependencies, resource distribution, and shifting compatibility of systems that evolve over time -- all of which conspire to break the reproducibility of an experiment. The goal of the GeoTrust project is to understand the research lifecycle of scientific experiments from conception to publication and establish a framework that will improve their reproducibility. <br/><br/>GeoTrust will develop sandboxing-based systems and tools that help scientists effectively isolate computational artifacts associated with an experiment, use languages and semantics to preserve artifacts, and re-execute /reproduce experiments by deploying the artifacts, changing datasets, algorithms, models, environments, etc. This reproducible framework will be adopted by and integrated within community infrastructures of three geoscience sub-disciplines viz. Hydrology, Solid Earth, and Space Science. Using cross-disciplinary science uses cases from these sub-disciplines, and engaging independent evaluators, we will assess the effectiveness of the framework in achieving reproducibility of computational experiments. Finally, verified results will be associated with ?stamps of reproducibility?, establishing community recognition of computational experiments. The framework will be developed as an EarthCube capability, with software developed and released as per EarthCube requirements. Early adopters across other geoscience sub-disciplines will be continually sought."
"1639547","EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications","ICER","EarthCube","09/01/2016","09/16/2016","Scott Peckham","CO","University of Colorado at Boulder","Standard Grant","Eva E. Zanzerkia","08/31/2018","$99,837.00","","Scott.Peckham@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","GEO","8074","7433","$0.00","Scientific reproducibility -- the ability to independently verify the work of other scientists -- continues to be a critical barrier towards achieving the vision of cross-disciplinary science. Federal agencies and publishers increasingly mandate and incentivize scientists to, at a minimum, establish computational reproducibility of scientific experiments. To comply scientists must connect descriptions of scientific experiments in scholarly publications with the underlying data and code used to produce the published results and findings. However, in practice, computational reproducibility is hard to achieve since it entails isolating necessary and sufficient computational artifacts and then preserving those artifacts in a standard way for later re-execution. Both isolation and preservation present challenges in large part due to the complexity of existing software and systems as well as the implicit dependencies, resource distribution, and shifting compatibility of systems that evolve over time -- all of which conspire to break the reproducibility of an experiment. The goal of the GeoTrust project is to understand the research lifecycle of scientific experiments from conception to publication and establish a framework that will improve their reproducibility. <br/><br/>GeoTrust will develop sandboxing-based systems and tools that help scientists effectively isolate computational artifacts associated with an experiment, use languages and semantics to preserve artifacts, and re-execute /reproduce experiments by deploying the artifacts, changing datasets, algorithms, models, environments, etc. This reproducible framework will be adopted by and integrated within community infrastructures of three geoscience sub-disciplines viz. Hydrology, Solid Earth, and Space Science. Using cross-disciplinary science uses cases from these sub-disciplines, and engaging independent evaluators, we will assess the effectiveness of the framework in achieving reproducibility of computational experiments. Finally, verified results will be associated with ?stamps of reproducibility?, establishing community recognition of computational experiments. The framework will be developed as an EarthCube capability, with software developed and released as per EarthCube requirements. Early adopters across other geoscience sub-disciplines will be continually sought."
"1639655","EarthCube Building Blocks: Collaborative Proposal: GeoTrust: Improving Sharing and Reproducibility of Geoscience Applications","ICER","EarthCube","09/01/2016","09/16/2016","David Tarboton","UT","Utah State University","Standard Grant","Eva E. Zanzerkia","08/31/2018","$140,000.00","Anthony Castronova","dtarb@usu.edu","Sponsored Programs Office","Logan","UT","843221415","4357971226","GEO","8074","7433, 9150","$0.00","Scientific reproducibility -- the ability to independently verify the work of other scientists -- continues to be a critical barrier towards achieving the vision of cross-disciplinary science. Federal agencies and publishers increasingly mandate and incentivize scientists to, at a minimum, establish computational reproducibility of scientific experiments. To comply scientists must connect descriptions of scientific experiments in scholarly publications with the underlying data and code used to produce the published results and findings. However, in practice, computational reproducibility is hard to achieve since it entails isolating necessary and sufficient computational artifacts and then preserving those artifacts in a standard way for later re-execution. Both isolation and preservation present challenges in large part due to the complexity of existing software and systems as well as the implicit dependencies, resource distribution, and shifting compatibility of systems that evolve over time -- all of which conspire to break the reproducibility of an experiment. The goal of the GeoTrust project is to understand the research lifecycle of scientific experiments from conception to publication and establish a framework that will improve their reproducibility. <br/><br/>GeoTrust will develop sandboxing-based systems and tools that help scientists effectively isolate computational artifacts associated with an experiment, use languages and semantics to preserve artifacts, and re-execute /reproduce experiments by deploying the artifacts, changing datasets, algorithms, models, environments, etc. This reproducible framework will be adopted by and integrated within community infrastructures of three geoscience sub-disciplines viz. Hydrology, Solid Earth, and Space Science. Using cross-disciplinary science uses cases from these sub-disciplines, and engaging independent evaluators, we will assess the effectiveness of the framework in achieving reproducibility of computational experiments. Finally, verified results will be associated with ?stamps of reproducibility?, establishing community recognition of computational experiments. The framework will be developed as an EarthCube capability, with software developed and released as per EarthCube requirements. Early adopters across other geoscience sub-disciplines will be continually sought."
"1343760","EarthCube Building Blocks: A Cognitive Computer Infrastructure for Geoscience","ICER","EarthCube","09/15/2013","07/24/2015","Shanan Peters","WI","University of Wisconsin-Madison","Standard Grant","Eva E. Zanzerkia","08/31/2017","$1,497,798.00","Christopher Re, Shanan Peters, Miron Livny","peters@geology.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","GEO","8074","7433","$0.00","This is an era when access to information and data is often less of a problem than the ability<br/>to efficiently process and use it. In some cases, these problems are caused by massive, monolithic<br/>datasets that are difficult to store, transfer, and/or analyze. In other cases, the first-order<br/>problem is discovering and then aggregating relevant data that are widely disseminated in<br/>many different locations and formats, such as in the tables, text, and figures of published<br/>papers, government agency reports, spreadsheets, and websites. Geosciences currently lacks<br/>a cyberinfrastructure that can efficiently, cheaply, and with high precision and accuracy<br/>find, extract, and organize many different types of data that are critical to advancing science<br/>and leveraging current and past investments in data acquisition. Instead, there are dozens<br/>of isolated, sometimes redundant, geosciences data mining efforts that use humans as the primary<br/>mechanism for finding data and then keystroking them into structured databases. This mode<br/>of operation is not only costly and slow, but it is also an inefficient use of human resources<br/>and scientific expertise. This project develops a geoscience-oriented trained computing<br/>system that can serve as a cross-disciplinary tool for rapidly finding, extracting, and organizing<br/>geosciences data. Unlike traditional data processing systems, trained systems use statistical, or machine learning, techniques to provide rich answers to complex queries of data that are much less structured. <br/><br/>The longer-term vision is to establish an EarthCube trained computing system that can aid in finding, extracting, and aggregating data, as well as in processing, summarizing, and synthesizing them in a way that helps geoscientists to tackle new problems<br/>and better understand and model Earth systems. This project brings together a unique interdisciplinary team that is committed to building, testing, and operating an EarthCube Building Block that will bring the power of trained computing systems<br/>technologies to the broader geoscience community. Trained computing systems offer an entirely new breed of tools for data processing."
"1540937","EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory","ICER","EarthCube","09/01/2015","07/28/2015","Yolanda Gil","CA","University of Southern California","Standard Grant","Eva E. Zanzerkia","08/31/2017","$20,000.00","","gil@isi.edu","University Park","Los Angeles","CA","900890001","2137407762","GEO","8074","7433","$0.00","The habitability of planet Earth depends on a complex interaction between interior regions, solid surface, oceans, atmosphere, near-earth space environment, and Sun. Yet, study of this Sun-Earth system is traditionally broken up into separate geoscience disciplines, so that progress can be made by scientists working in reasonably-sized communities that share a common language and base of knowledge. To broach the bigger question of the interaction of the subsystems studied by the separate communities, it is necessary to overcome the barriers of communication posed by different observational instruments, software tools for interpreting data, and modeling methods. In answer to this challenge, the Integrated Geoscience Observatory is a pilot project that creates an online platform for integrating data and associated software tools contributed by separate geoscience research communities, into a unified toolset that brings them together. The vision is to expand the individual domains of geoscience research toward study of the whole Sun-Earth system, and in so doing to uncover the system level effects critical to the habitability of planet Earth.<br/><br/>EarthCube aims to develop a framework for assisting researchers in understanding the Earth system. This systems science challenge is recognized in the Decadal Survey in Solar and Space Physics [2012], with the conclusion ""Data from diverse space- and ground-based instruments need to be routinely combined in order to maximize their multi-scale potential."" The Integrated Geoscience Observatory is a pilot project that explores realization of this vision by focusing on the limited context of geospace research. The observatory creates an integrated package of software tools contributed by researchers with specific capabilities, and designed to enable integration of diverse observational data. Features of the toolkit include: (A) linking diverse data sets from multiple data repositories and automatically mapping them to a common user-specified coordinate grid; (B) implementing the well-known Assimilative Mapping of Ionospheric Electrodynamics (AMIE) procedure for assimilation of this data to yield a global picture; and (C) utilization of the EarthCube building blocks GeoSoft, for communicating ontology, and GeoDataspace, for attributing credit to contributors through publication of processed data. The toolset can be accessed and used either through a web-based computing environment, or through download packages for local installation, with a nearly seamless transition between the two."
"1440133","EarthCube Building Blocks: Collaborative Proposal: Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS)","ICER","EarthCube","09/01/2014","08/06/2014","Michael Daniels","CO","University Corporation For Atmospheric Res","Standard Grant","Eva E. Zanzerkia","08/31/2017","$284,673.00","","daniels@ucar.edu","3090 Center Green Drive","Boulder","CO","803012252","3034971000","GEO","8074","7433","$0.00","The importance of real-time scientific data is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Furthermore, advances in the distribution of real-time data are leading many new transient phenomena in space-time to be observed. Presently however, realtime decision-making is infeasible in many cases that require streaming scientific data to be coupled with complex models. While EarthCube will provide an unprecedented framework for disseminating data sources, the use of real-time data raises an additional set of complex challenges that must be considered. This project is a pilot to demonstrate the importance of coodinating the geosciences around their real-time data gathering and use. The work will demonstrate a Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS)<br/><br/>The vision behind CHORDS is to provide a real-time data management infrastructure that will: a)Provide a system to archive, navigate and distribute real-time data streams via the Internet; b)Be easily deployed and configured; c)Run on cloud infrastructure; d)Use transactions built on RESTful protocols (i.e. via URLs); e)Employ data and metadata formats that adhere to standards, which simplify the user experience; f)Be free and open source.Science derived from observing platform data is the result of years of planning before a deployment, for example, and millions of dollars are spent on the deployment itself in hopes of obtaining the desired dataset. Many geo-scientific experiments are often resource constrained. In such cases it is vital to guarantee the optimal allocation of resources to ensure that important events do not go unobserved. In geo-scientific domains it is not uncommon to analyze data after a field campaigns, only to detect sensor faults, calibration offsets or anomalous behaviors when it is already too late. Real-time data will enable the optimal allocation of constrained experimental resources by automating the detection of faults and anomalies. CHORDS will provide a framework to enable adaptive sampling, discovery and fusion of various real-time geoscientific data sources, thus facilitating a new means by which geoscience experiments are carried out. The use cases will illustrate this by showing traditional experiments would have missed events of interest due to lack of access to real-time data. Focus on the initial work of defining requirements, design and specifications. Begin to ingest a small subset of geosciences data streams into a prototype CHORDS structure built in the cloud. Participate in activities that strengthen the integration of real-time data being ingested via CHORDS into other EarthCube Building Block systems that are under development. They will focus on some initial test cases, in hydrology sensor data, radar data streams, the NCAR Lower Atmosphere Observing Facilities, and outreach to earth and oceans communities."
"1440116","EarthCube Building Blocks: Collaborative Proposal: Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS)","ICER","EarthCube","09/01/2014","08/06/2014","Branko Kerkez","MI","University of Michigan Ann Arbor","Standard Grant","Eva E. Zanzerkia","08/31/2016","$40,000.00","","bkerkez@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","GEO","8074","7433","$0.00","The importance of real-time scientific data is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Furthermore, advances in the distribution of real-time data are leading many new transient phenomena in space-time to be observed. Presently however, realtime decision-making is infeasible in many cases that require streaming scientific data to be coupled with complex models. While EarthCube will provide an unprecedented framework for disseminating data sources, the use of real-time data raises an additional set of complex challenges that must be considered. This project is a pilot to demonstrate the importance of coodinating the geosciences around their real-time data gathering and use. The work will demonstrate a Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS)<br/><br/>The vision behind CHORDS is to provide a real-time data management infrastructure that will: a)Provide a system to archive, navigate and distribute real-time data streams via the Internet; b)Be easily deployed and configured; c)Run on cloud infrastructure; d)Use transactions built on RESTful protocols (i.e. via URLs); e)Employ data and metadata formats that adhere to standards, which simplify the user experience; f)Be free and open source.Science derived from observing platform data is the result of years of planning before a deployment, for example, and millions of dollars are spent on the deployment itself in hopes of obtaining the desired dataset. Many geo-scientific experiments are often resource constrained. In such cases it is vital to guarantee the optimal allocation of resources to ensure that important events do not go unobserved. In geo-scientific domains it is not uncommon to analyze data after a field campaigns, only to detect sensor faults, calibration offsets or anomalous behaviors when it is already too late. Real-time data will enable the optimal allocation of constrained experimental resources by automating the detection of faults and anomalies. CHORDS will provide a framework to enable adaptive sampling, discovery and fusion of various real-time geoscientific data sources, thus facilitating a new means by which geoscience experiments are carried out. The use cases will illustrate this by showing traditional experiments would have missed events of interest due to lack of access to real-time data. Focus on the initial work of defining requirements, design and specifications. Begin to ingest a small subset of geosciences data streams into a prototype CHORDS structure built in the cloud. Participate in activities that strengthen the integration of real-time data being ingested via CHORDS into other EarthCube Building Block systems that are under development. They will focus on some initial test cases, in hydrology sensor data, radar data streams, the NCAR Lower Atmosphere Observing Facilities, and outreach to earth and oceans communities."
"1440351","Earthcube RCN: iSAmplEs: The Internet of Samples in the Earth Sciences","ICER","EarthCube","09/01/2014","08/06/2014","Kerstin Lehnert","NY","Columbia University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$299,965.00","Yue Cai","lehnert@ldeo.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","GEO","8074","7433","$0.00","Across many Earth Science disciplines, research depends on the availability of representative samples collected above, at, and beneath Earth?s surface, on the moon and in space, or generated in experiments. These samples are fundamental references that are studied to generate new knowledge about the earth and the entire universe and a deeper understanding of the processes that created and shaped it, the availability of natural resources and the risk of natural hazards. Many samples have been collected at great cost and with substantial difficulty, are rare or unique and irreplaceable. The use of information technology and the internet to make these samples easily accessible, to ensure persistent access to relevant sample metadata, to allow unambiguous linking of the physical objects to the digital data in a distributed data infrastructure, will have a broad impact across the entire Earth Sciences. It will open new opportunities to reexamine existing samples in response to new societal issues, environmental concerns, scientific interpretations, and analytical techniques. The activities of this coordination network will allow domain scientists, curators, and computer and information scientists to learn from each other about the requirements of physical and digital sample and collection management and to articulate a vision of and a path forward toward an Internet of Samples in the Earth Sciences.<br/><br/>The EarthCube Research Coordination Network iSamplES (Internet of Samples in the Earth Sciences) is intended to advance the use of innovative cyberinfrastructure to connect physical samples and sample collections across the Earth Sciences with digital data infrastructures to revolutionize their utility for science. The ultimate goal of this RCN is to dramatically improve the discovery, access, sharing, analysis, and curation of physical samples and the data generated by their study for the benefit of science and society as part of the EarthCube program. In order to work toward this objective, the project will help build, grow, and foster domain scientists, curators of sample repositories and collections, computer and information scientists, software developers and technology innovators to engage in and collaborate on defining, articulating, and addressing the needs and challenges of physical samples as a critical component of digital data and information infrastructures (theme 1: socialization). The RCN will compile information about existing resources (technologies, architectures, tools, profiles, workflows) that facilitate the management of samples, sample collections, and sample-based data in the field, in the lab, in repositories, in data systems and scientific publications, and identify critical gaps and needs (theme 2: knowledge creation). The RCN will recognize and promote best practices and standards for sample identification, documentation, citation, curation, and sharing across the entire Earth Science community as a foundation to building a shared cyber-infrastructure (theme 3: best practices)."
"1440109","EarthCube Building Blocks: Collaborative Proposal: Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS)","ICER","EarthCube","09/01/2014","08/06/2014","V. Chandrasekar","CO","Colorado State University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$40,000.00","","chandra@engr.colostate.edu","601 S Howes St","Fort Collins","CO","805232002","9704916355","GEO","8074","7433","$0.00","The importance of real-time scientific data is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Furthermore, advances in the distribution of real-time data are leading many new transient phenomena in space-time to be observed. Presently however, realtime decision-making is infeasible in many cases that require streaming scientific data to be coupled with complex models. While EarthCube will provide an unprecedented framework for disseminating data sources, the use of real-time data raises an additional set of complex challenges that must be considered. This project is a pilot to demonstrate the importance of coodinating the geosciences around their real-time data gathering and use. The work will demonstrate a Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS)<br/><br/>The vision behind CHORDS is to provide a real-time data management infrastructure that will: a)Provide a system to archive, navigate and distribute real-time data streams via the Internet; b)Be easily deployed and configured; c)Run on cloud infrastructure; d)Use transactions built on RESTful protocols (i.e. via URLs); e)Employ data and metadata formats that adhere to standards, which simplify the user experience; f)Be free and open source.Science derived from observing platform data is the result of years of planning before a deployment, for example, and millions of dollars are spent on the deployment itself in hopes of obtaining the desired dataset. Many geo-scientific experiments are often resource constrained. In such cases it is vital to guarantee the optimal allocation of resources to ensure that important events do not go unobserved. In geo-scientific domains it is not uncommon to analyze data after a field campaigns, only to detect sensor faults, calibration offsets or anomalous behaviors when it is already too late. Real-time data will enable the optimal allocation of constrained experimental resources by automating the detection of faults and anomalies. CHORDS will provide a framework to enable adaptive sampling, discovery and fusion of various real-time geoscientific data sources, thus facilitating a new means by which geoscience experiments are carried out. The use cases will illustrate this by showing traditional experiments would have missed events of interest due to lack of access to real-time data. Focus on the initial work of defining requirements, design and specifications. Begin to ingest a small subset of geosciences data streams into a prototype CHORDS structure built in the cloud. Participate in activities that strengthen the integration of real-time data being ingested via CHORDS into other EarthCube Building Block systems that are under development. They will focus on some initial test cases, in hydrology sensor data, radar data streams, the NCAR Lower Atmosphere Observing Facilities, and outreach to earth and oceans communities."
"1541057","EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory","ICER","EarthCube","09/01/2015","07/28/2015","Asti Bhatt","CA","SRI International","Standard Grant","Eva E. Zanzerkia","08/31/2017","$517,718.00","Russell Cosgrove","asti.bhatt@sri.com","333 RAVENSWOOD AVE","Menlo Park","CA","940253493","6508592651","GEO","8074","7433","$0.00","The habitability of planet Earth depends on a complex interaction between interior regions, solid surface, oceans, atmosphere, near-earth space environment, and Sun. Yet, study of this Sun-Earth system is traditionally broken up into separate geoscience disciplines, so that progress can be made by scientists working in reasonably-sized communities that share a common language and base of knowledge. To broach the bigger question of the interaction of the subsystems studied by the separate communities, it is necessary to overcome the barriers of communication posed by different observational instruments, software tools for interpreting data, and modeling methods. In answer to this challenge, the Integrated Geoscience Observatory is a pilot project that creates an online platform for integrating data and associated software tools contributed by separate geoscience research communities, into a unified toolset that brings them together. The vision is to expand the individual domains of geoscience research toward study of the whole Sun-Earth system, and in so doing to uncover the system level effects critical to the habitability of planet Earth.<br/><br/>EarthCube aims to develop a framework for assisting researchers in understanding the Earth system. This systems science challenge is recognized in the Decadal Survey in Solar and Space Physics [2012], with the conclusion ""Data from diverse space- and ground-based instruments need to be routinely combined in order to maximize their multi-scale potential."" The Integrated Geoscience Observatory is a pilot project that explores realization of this vision by focusing on the limited context of geospace research. The observatory creates an integrated package of software tools contributed by researchers with specific capabilities, and designed to enable integration of diverse observational data. Features of the toolkit include: (A) linking diverse data sets from multiple data repositories and automatically mapping them to a common user-specified coordinate grid; (B) implementing the well-known Assimilative Mapping of Ionospheric Electrodynamics (AMIE) procedure for assimilation of this data to yield a global picture; and (C) utilization of the EarthCube building blocks GeoSoft, for communicating ontology, and GeoDataspace, for attributing credit to contributors through publication of processed data. The toolset can be accessed and used either through a web-based computing environment, or through download packages for local installation, with a nearly seamless transition between the two."
"1540901","EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory","ICER","EarthCube","09/01/2015","07/28/2015","Tanu Malik","IL","University of Chicago","Standard Grant","Eva E. Zanzerkia","08/31/2017","$89,990.00","","tanu@cdm.depaul.edu","5801 South Ellis Avenue","Chicago","IL","606375418","7737028669","GEO","8074","7433","$0.00","The habitability of planet Earth depends on a complex interaction between interior regions, solid surface, oceans, atmosphere, near-earth space environment, and Sun. Yet, study of this Sun-Earth system is traditionally broken up into separate geoscience disciplines, so that progress can be made by scientists working in reasonably-sized communities that share a common language and base of knowledge. To broach the bigger question of the interaction of the subsystems studied by the separate communities, it is necessary to overcome the barriers of communication posed by different observational instruments, software tools for interpreting data, and modeling methods. In answer to this challenge, the Integrated Geoscience Observatory is a pilot project that creates an online platform for integrating data and associated software tools contributed by separate geoscience research communities, into a unified toolset that brings them together. The vision is to expand the individual domains of geoscience research toward study of the whole Sun-Earth system, and in so doing to uncover the system level effects critical to the habitability of planet Earth.<br/><br/>EarthCube aims to develop a framework for assisting researchers in understanding the Earth system. This systems science challenge is recognized in the Decadal Survey in Solar and Space Physics [2012], with the conclusion ""Data from diverse space- and ground-based instruments need to be routinely combined in order to maximize their multi-scale potential."" The Integrated Geoscience Observatory is a pilot project that explores realization of this vision by focusing on the limited context of geospace research. The observatory creates an integrated package of software tools contributed by researchers with specific capabilities, and designed to enable integration of diverse observational data. Features of the toolkit include: (A) linking diverse data sets from multiple data repositories and automatically mapping them to a common user-specified coordinate grid; (B) implementing the well-known Assimilative Mapping of Ionospheric Electrodynamics (AMIE) procedure for assimilation of this data to yield a global picture; and (C) utilization of the EarthCube building blocks GeoSoft, for communicating ontology, and GeoDataspace, for attributing credit to contributors through publication of processed data. The toolset can be accessed and used either through a web-based computing environment, or through download packages for local installation, with a nearly seamless transition between the two."
"1541010","EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory","ICER","EarthCube","09/01/2015","07/28/2015","Tomoko Matsuo","CO","University of Colorado at Boulder","Standard Grant","Eva E. Zanzerkia","08/31/2017","$100,000.00","","tomoko.matsuo@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","GEO","8074","7433","$0.00","The habitability of planet Earth depends on a complex interaction between interior regions, solid surface, oceans, atmosphere, near-earth space environment, and Sun. Yet, study of this Sun-Earth system is traditionally broken up into separate geoscience disciplines, so that progress can be made by scientists working in reasonably-sized communities that share a common language and base of knowledge. To broach the bigger question of the interaction of the subsystems studied by the separate communities, it is necessary to overcome the barriers of communication posed by different observational instruments, software tools for interpreting data, and modeling methods. In answer to this challenge, the Integrated Geoscience Observatory is a pilot project that creates an online platform for integrating data and associated software tools contributed by separate geoscience research communities, into a unified toolset that brings them together. The vision is to expand the individual domains of geoscience research toward study of the whole Sun-Earth system, and in so doing to uncover the system level effects critical to the habitability of planet Earth.<br/><br/>EarthCube aims to develop a framework for assisting researchers in understanding the Earth system. This systems science challenge is recognized in the Decadal Survey in Solar and Space Physics [2012], with the conclusion ""Data from diverse space- and ground-based instruments need to be routinely combined in order to maximize their multi-scale potential."" The Integrated Geoscience Observatory is a pilot project that explores realization of this vision by focusing on the limited context of geospace research. The observatory creates an integrated package of software tools contributed by researchers with specific capabilities, and designed to enable integration of diverse observational data. Features of the toolkit include: (A) linking diverse data sets from multiple data repositories and automatically mapping them to a common user-specified coordinate grid; (B) implementing the well-known Assimilative Mapping of Ionospheric Electrodynamics (AMIE) procedure for assimilation of this data to yield a global picture; and (C) utilization of the EarthCube building blocks GeoSoft, for communicating ontology, and GeoDataspace, for attributing credit to contributors through publication of processed data. The toolset can be accessed and used either through a web-based computing environment, or through download packages for local installation, with a nearly seamless transition between the two."
"1346690","EarthCube Domain End-User Workshop: Community-Based Cyberinfrastructure for Polar Science Instrumentation, Technology, and Environmental Monitors","PLR","POLAR CYBERINFRASTRUCTURE, EarthCube","10/01/2013","03/27/2015","Alberto Behar","AZ","Arizona State University","Standard Grant","Renee D. Crain","03/31/2015","$35,233.00","","alberto.behar@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","GEO","5407, 8074","1079, 7433","$0.00","The project consists in the organization of a workshop aiming at bringing together scientists from the polar science domain<br/>and cyberinfrastructure specialists. The goal is to gather requirements and develop a vision for an advanced<br/>information and knowledge management system that will transform the way instrumentation, technology,<br/>sensors and environmental monitors are used in polar regions in the conduct of science.<br/>The workshop will provide community feedback to the EarthCube<br/>initiative and the Polar Cyberinfrastructure program to design and develop the architecture of an Earth<br/>Science cyberinfrastructure that is aligned with the end-users' needs for new systems aimed<br/>data acquisition, field storage, transmission, security, redundancy and the deployment infrastructure<br/>techniques and material for these systems. The format will be the same as previous Earthcube sponsored workshop. <br/>The workshop will target requirements on science-drivers on the latest<br/>needs in instrumentation/sensing systems, field computing, power: generation, handling, distribution<br/>& storage, data: storage, reliability and transmission, environmental enclosures, field deployment<br/>techniques and other needs to design strategies for funding opportunities that will support<br/>scientists and engineers to perform outstanding and ground-breaking research in the polar<br/>regions. The workshop will target a broad spectrum of<br/>polar scientists, with the goal that a significant contingent of early career scientists will<br/>participate."
"1338760","Collaborative Research: EarthCube End-User Workshop: Deep Seafloor Processes and Dynamics","OCE","EarthCube","04/15/2013","04/05/2013","Vicki Ferrini","NY","Columbia University","Standard Grant","Eva E. Zanzerkia","03/31/2014","$9,564.00","","ferrini@ldeo.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","GEO","8074","0000, 7433, OTHR","$0.00","The seafloor serves and the primary conduit for mass and heat transfer between the sub-seafloor and the overlying ocean water column, with both operating on vastly different time and mass scales. Dynamics at this interface drive global biogeochemical and geochemical elemental cycles, control global ocean chemistry, and shape the atmosphere and climate systems. Deep sea ecosystems also host some of the most diverse and extreme ecosystems including those inhabiting hydrothermal vents, cold seeps, mid-ocean ridges, ridge flanks, and plate margins. Without data from a wide variety of disciplines, such as geology, petrology, geophysics, hydrogeology, and micro/macro/evolutionary biology, it is not possible to realistically model these important systems and understand the complex interactions between their various physical, chemical, and biological components. Instrumental to understanding processes and dynamics of the deep sea requires integration of the disparate datasets and models that represent and predict the behavior of the components of this complex, important system. The goal of this workshop is to surface requirements in the field of deep sea processes for a major new NSF data and knowledge management initiative (i.e., EarthCube) that is dedicated to revolutionizing geoscience by providing easy access to, discovery of, and visualization of data from across the geo- and environmental sciences. This workshop will bring together ~55 oceanographers from across the relevant disciplines. It will also include cyber/computer science experts. Together workshop participants will collectively define future science goals in this important scientific area and focus on identifying the most critical, widespread cyberinfrastructure and data management issues and problems presently holding back scientific advances in deep sea science in order to guide the development of NSF EarthCube cyberinfrastructure. The workshop will also focus on strategies that help scientists and data that they need to cross sub-discipline barriers to enable more interdisciplinary research to take place. Workshop participants will address topics such as science drivers in deep sea process research in the next 15 years, data and data management needs and problems, and software and visualization needs to help model and understand data. Broader impacts of the work include support of an organization in an EPSCoR state, support of two PIs whose gender is under-represented in the sciences and engineering, and engagement of early career scientists. A virtual component of the workshop will be held to help broaden participation beyond those present on-site."
"1417948","EarthCube Domain Workshop: Data Facilities","ICER","EarthCube","01/15/2014","01/16/2014","M. Lee Allison","AZ","Arizona Geological Survey","Standard Grant","Eva E. Zanzerkia","12/31/2015","$93,147.00","Jennifer Arrigo, Cynthia Chandler, Kerstin Lehnert","lee.allison@azgs.az.gov","416 W. Congress St, #100","Tucson","AZ","857011381","5207703500","GEO","8074","7433","$0.00","Data facilities provide a key resource in the pursuit of innovative scientific research by<br/>aggregating, preserving, and disseminating large quantities of data sets, including highly<br/>complex petabyte scale data to more simple metadata catalogs. The proposed workshop provides<br/>a forum for leaders from these facilities, regardless of scale, type or format of data, to<br/>gather and discuss commonalities and collaborative solutions to the increasing challenges<br/>associated with providing data access for researchers. In addition, this workshop will act<br/>as a key end-user Assembly Group during the EarthCube Test Enterprise Governance process to<br/>identify decision making processes and governance models that are most applicable to the geoscience<br/>data facilities.<br/><br/>A steering committee of experts from across the Geosciences, including Atmosphere, Oceans,<br/>and Earth Sciences will act to identify key participants and create a quality agenda. Social<br/>scientists will be utilized to ensure developmental evaluation and learning loops are incorporated<br/>into the agenda; this includes the construction of key scenarios and exercises for discussion<br/>and breakout groups.<br/><br/>Results of the meeting will include a set of common and unique requirements and challenges<br/>associated with the communication, collaboration, interoperability, and governance structures<br/>required to ensure that the capabilities and opportunities of existing and emerging NSF/GEO<br/>facilities are incorporated into the EarthCube concept."
"1338705","Collaborative Research: EarthCube End-User Workshop: Deep Seafloor Processes and Dynamics","OCE","EarthCube","04/15/2013","04/05/2013","Karyn Rogers","DC","Carnegie Institution of Washington","Standard Grant","Eva E. Zanzerkia","03/31/2014","$12,874.00","","rogerk5@rpi.edu","1530 P ST NW","WASHINGTON","DC","200051910","2023876400","GEO","8074","0000, 7433, OTHR","$0.00","The seafloor serves and the primary conduit for mass and heat transfer between the sub-seafloor and the overlying ocean water column, with both operating on vastly different time and mass scales. Dynamics at this interface drive global biogeochemical and geochemical elemental cycles, control global ocean chemistry, and shape the atmosphere and climate systems. Deep sea ecosystems also host some of the most diverse and extreme ecosystems including those inhabiting hydrothermal vents, cold seeps, mid-ocean ridges, ridge flanks, and plate margins. Without data from a wide variety of disciplines, such as geology, petrology, geophysics, hydrogeology, and micro/macro/evolutionary biology, it is not possible to realistically model these important systems and understand the complex interactions between their various physical, chemical, and biological components. Instrumental to understanding processes and dynamics of the deep sea requires integration of the disparate datasets and models that represent and predict the behavior of the components of this complex, important system. The goal of this workshop is to surface requirements in the field of deep sea processes for a major new NSF data and knowledge management initiative (i.e., EarthCube) that is dedicated to revolutionizing geoscience by providing easy access to, discovery of, and visualization of data from across the geo- and environmental sciences. This workshop will bring together ~55 oceanographers from across the relevant disciplines. It will also include cyber/computer science experts. Together workshop participants will collectively define future science goals in this important scientific area and focus on identifying the most critical, widespread cyberinfrastructure and data management issues and problems presently holding back scientific advances in deep sea science in order to guide the development of NSF EarthCube cyberinfrastructure. The workshop will also focus on strategies that help scientists and data that they need to cross sub-discipline barriers to enable more interdisciplinary research to take place. Workshop participants will address topics such as science drivers in deep sea process research in the next 15 years, data and data management needs and problems, and software and visualization needs to help model and understand data. Broader impacts of the work include support of an organization in an EPSCoR state, support of two PIs whose gender is under-represented in the sciences and engineering, and engagement of early career scientists. A virtual component of the workshop will be held to help broaden participation beyond those present on-site."
"1238438","Collaborative workshop proposal: Drawing the roadmap for the semantic/ontology based infrastructure for Geosciences","EAR","EarthCube","04/01/2012","03/27/2012","Akhaury Sinha","VA","Virginia Polytechnic Institute and State University","Standard Grant","Barbara L. Ransom","03/31/2014","$89,924.00","","pitlab@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","GEO","8074","7433","$0.00","EarthCube is focused on community-driven development of an integrated, and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive, process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems. This award funds a series of broad community interactions to gather adequate information and requirements to create a roadmap for a critical cyberinfrastructure capability (semantics and ontologies) in the development of EarthCube. In the context of cyberinfrastructure, semantics and ontologies are what allows heterogeneous and distributed data systems to become interoperable. They enable scientists to register, discover, access, and integrate data irrespective of its structural heterogeneity. This work convenes public, online/virtual meetings and seeks broad community input in the development of a process to have the geoscience and cyberinfrastructure communities converge on a way forward in the realm of semantics and ontologies for data, with the end product being a capability implementation roadmap. Also involved in the process is the identification of appropriate community agreed upon use cases. Broader impacts of the work include development of approaches, protocols, and standards that may be applicable across the sciences and the fostering of close interaction between communities that do not commonly interact, to a great extent, with one another moving them toward a common goal of the creation of a new paradigm in data and knowledge management in the geosciences."
"1541088","EarthCube IA: Digital Rocks Portal: a Sustainable Platform for Sharing, Translation, and Analysis of Volumetric Data of Porous Media","ICER","EarthCube","09/01/2015","08/25/2015","Masa Prodanovic","TX","University of Texas at Austin","Standard Grant","Eva E. Zanzerkia","08/31/2017","$629,065.00","Richard Ketcham, Maria Esteva","masha@utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","GEO","8074","7433","$0.00","Recent advances in high-resolution imaging techniques have provided a wealth of 3D datasets that reveal the microstructure of rocks and soil. It is now possible to conduct numerical experiments and construct detailed models to simulate phenomena such as fluid flow or mechanical deformation in the pore spaces of these materials. Popularly called digital rock physics, this research framework can inform important decisions in environmental, civil and petroleum engineering, as well as address key geological questions. Examples include: containing the spread of toxins or harmful bacteria in watersheds; designing safe dams; improving recovery of hydrocarbons, and understanding the history of rock formation. Researchers, however, have trouble storing and sharing these datasets due to their large sizes and the lack of standards to characterize image types and associated information about them. This impedes scientific cross-validation of the simulation approaches, and limits the development of studies that span length scales from a micrometer (a millionth of a meter, the size of individual pores and grains making up a rock) to a kilometer (the level of a geological basin or aquifer). Studies spanning length scales are important to characterize rock and flow properties at the kilometer scale that often depend on complex processes on the micrometer scale.<br/><br/>This project will continue the development of a sustainable, open and easy-to-use repository called the Digital Rocks Portal (https://pep.tacc.utexas.edu/). The portal will: a) organize the images and related experimental measurements of diverse porous materials; b) improve access to porous media analysis results for a wider community of geoscience and engineering researchers not necessarily trained in computer science or data analysis; and c) enhance productivity, scientific inquiry, and engineering decisions founded on a data-driven basis. The portal will incorporate software tools and pipelines that make it easier for researchers from EarthCube and beyond to organize, publish and reuse data, and for educators to quickly visualize and illustrate concepts for a wide audience. For data sustainability and continuous access, the portal is implemented within the reliable High Performance Computing Infrastructure deployed and maintained at the Texas Advanced Computing Center (TACC) at The University of Texas at Austin, which is supported by The University of Texas System Research Cyberinfrastructure (UTRC) initiative. We will coordinate development and data integration with the High-Resolution X-ray Computed Tomography Facility at The University of Texas at Austin (UTCT), one of the largest academic imaging facilities in the nation. Finally, an important contribution will be the development of a business model for sustaining long-term preservation of important datasets obtained from research investments."
"1632211","EarthCube RCN IS-GEO: Intelligent Systems Research to Support Geosciences","ICER","ROBUST INTELLIGENCE, EarthCube","08/15/2016","08/23/2016","Suzanne Pierce","TX","University of Texas at Austin","Standard Grant","Eva E. Zanzerkia","07/31/2018","$299,998.00","","spierce@tacc.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","GEO","7495, 8074","7433","$0.00","This project will foster collaborations between computer scientists and geoscientists that will advance research in both areas. Geoscience problems are complex and often involve data that changes across space and time. Frequently geoscience knowledge and understanding provides valuable information and insight for problems related to energy, water, climate, agriculture, mineral resources, and our understanding of how the Earth evolves through time. Simultaneously, many grand challenges in the geosciences cannot be addressed without the aid of computational support and innovations. Intelligent and Information Systems (IS) research in computer science includes a broad range of topics and computational methods such as knowledge representation, information integration, machine learning, robotics, adaptive sensors, and intelligent interfaces. IS research has an important role to play in accelerating the speed of scientific discovery in geosciences and thus in solving challenges that cannot be addressed by other means. Similarly, many aspects of Geosciences (GEO) research pose novel large-scale problems for IS researchers to improve and validate their methods. Intelligent Systems for Geosciences (IS-GEO) represent an emerging community of interdisciplinary researchers producing fundamental new capabilities for understanding Earth systems and how the application of IS technologies can cultivate key new developments in both fields.<br/><br/>The EarthCube Research Coordination Network for Intelligent Systems for Geosciences (IS-GEO RCN) will catalyze collaborations to enable advances in our understanding of Earth systems through innovative applications of intelligent and information systems to fundamental geosciences problems. The goal of the IS-GEO RCN is to leverage expertise and generate interactions between both the geosciences and computing sciences communities to provide advanced scientific capabilities. To enable the network, the IS-GEO RCN will host meetings and other activities that: (1) foster an active and broad-based community across GEO and IIS areas; (2) identify barriers to research, such as terminology differences among the disciplines involved and highlight knowledge gaps that hinder collaboration across the disciplines; (3) establish and enhance communication channels between GEO and IS researchers; (4) defining grand challenges in geosciences that are well suited to IS techniques; and (5) encourage robust, long-term collaborations. Furthermore, the educational component aims to identify new approaches to teaching students in this new interdisciplinary area, seeking to raise a new generation of scientists that are better able to apply IS methods and tools to geoscience challenges of the future. By providing avenues for IS and GEO researchers to work together the IS-GEO RCN will serve as both a point of contact, as well as an avenue for educational outreach across the disciplines for the nascent community of research and practice.<br/><br/>The initial efforts are focused on connecting the communities in ways that help researchers understand opportunities and challenges that can benefit from IS-GEO collaborations. The uncertain, heterogeneous and disparate nature of geoscience data paired with recent IS advances and increases in observational data offer unique opportunities for new approaches and discoveries through joint efforts. The IS-GEO RCN will jumpstart interdisciplinary research collaborations in this emerging new area so that progress across both disciplines can be accelerated."
"1541008","EarthCube IA: Collaborative Proposal: Cross-Domain Observational Metadata Environmental Sensing Network (X-DOMES)","ICER","EarthCube","09/01/2015","08/18/2015","Janet Fredericks","MA","Woods Hole Oceanographic Institution","Standard Grant","Eva E. Zanzerkia","08/31/2017","$677,919.00","Michael Botts, Carlos Rueda, Felimon Gayanilo","jfredericks@whoi.edu","183 OYSTER POND ROAD","WOODS HOLE","MA","025431041","5082893542","GEO","8074","7433","$0.00","Across-domains, agencies and political boundaries, our environment is being continuously observed and studied. The researchers in this project are looking for short-term, near-term and long-term changes while researching new and evolving methods to observe properties and to process the collected observations. Emerging technologies enable us to provide and discover the data openly and freely. But, if we do not understand the newly discovered data, with its inherent limitations and biases, it cannot be responsibly utilized for new or collaborative research efforts. Working with environmental sensor manufacturers and researchers, the X-DOMES project will develop tools and social and technical infrastructure to facilitate the creation of data about data (metadata). Metadata describes not only who, when and where the observations were made, but also it must document how an observation came to be (provenance). By taking this knowledge out of manuals and human-readable documents, the X-DOMES model creates metadata that can be treated like data ? discoverable and searchable, making it ready to be incorporated into automated archival and processing for quality assurance and validation methods. <br/><br/>Leveraging existing relationships with large NSF-funded data management programs, EarthCube building blocks and working groups, and environmental sensor manufacturers and consortia, we will establish a community of sensor manufacturers and other stakeholders to provide a unifying approach to describing sensors and observations across geo-science domains. Built on an existing sensor metadata model that references registered, standards-based vocabularies, the X-DOMES pilot project will provide a suite of tools, built upon community-adopted standards of the Open Geospatial Consortium (OGC) and World Wide Web Consortium (W3C) to demonstrate and facilitate the generation of documents that are discoverable and accessible on-line and/or directly from onboard sensor descriptions. The project will also demonstrate mechanisms to associate the data with the metadata through standards-based web services. With vendor-ready tools implemented throughout a broad-based community, the X-DOMES Network will lay the foundation for the development of and adoption of interoperable access to much needed content-rich sensor metadata."
"1239065","Service Based Integration Platform for EarthCube (SBIP-E)","EAR","EarthCube","04/01/2012","03/22/2012","Timothy Ahern","DC","Incorporated Research Institutions for Seismology","Standard Grant","Barbara L. Ransom","03/31/2013","$200,953.00","","tim@iris.washington.edu","1200 New York Avenue, NW","Washington","DC","200056142","2026822220","GEO","8074","7433, 7916","$0.00","This EAGER award focuses on exploring the feasibility of the implementation of a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube. Led by a team of experts in geoscience data management, this project focuses on developing a loosely coupled web service approach to allow geoscience data repositories to more effectively make their data holdings discoverable and available to the public. One project goal will be to test the utility of the RESTful (representative state transfer) approach. Its target will be more to link together of disparate geoscience data types from widely distributed data repositories so new types of data-enabled science can be realized. The project engages data management groups from most of the major NSF-funded geoscience data facilities as well as those from a variety of major European geoscience data holdings. This interaction will not only allow broader testing of developed web services, but will also provide a much needed forum to exchange ideas and approaches allowing a better return on investment. One key aspect of this project is the development of URL builders to help users formulate web service requests. Broader impacts of the work include the development of new infrastructure for science and engineering and the likelihood that what results from this project will be applicable to fields outside of the geosciences. An additional broader impact is an international component that engages Italian and other European scientists and data networks as collaborators in the activity."
"1343811","EarthCube Building Blocks: Earth System Bridge: Spanning Scientific Communities with Interoperable Modeling Frameworks","ICER","EarthCube","09/15/2013","03/09/2015","Scott Peckham","CO","University of Colorado at Boulder","Standard Grant","Eva E. Zanzerkia","08/31/2017","$1,699,997.00","David Gochis, Cecelia Deluca, Jennifer Arrigo, Richard Hooper, Anna Kelbert, Gary Egbert","Scott.Peckham@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","GEO","8074","7433","$0.00","This EarthCube project possesses deep, disciplinary and interdisciplinary expertise in the development, implementation and support of geoscientific modeling architectures and in the promotion and utilization of community standards in model development and in data management. Combined, this team will integrate existing model architectures, model coupling standards and data standards into a set of open source Earth System Bridge building blocks that will transform the process of Earth system model coupling and bridge the present technological gap. In collaboration with the community of framework developers, the team will create a Framework Definition Language (FDL) which characterizes Earth system coupling technologies in terms of their metadata usage, architecture, protocols for interaction, and implementation, and use this as a basis for understanding potential framework inter-connections. They will use the FDL to develop a set of ?bridges? that connect leading software frameworks from the federal modeling enterprise and from the academic geoscientific modeling enterprise, for the sake of creating seamless environmental and impacts prediction tools, and develop new services to improve the integration of inter-agency, four-dimensional databases with more heterogeneous academic databases for use in earth system models and by modeling groups. Demonstration of the new modeling and data integration architecture will be in two case studies: the first, prediction of the local impacts of the Hurricane Sandy landfall; and the second, the integration of deep Earth process with surface dynamics. These problems span disciplines, agencies, and research and operational communities, and require addressing scientific, technical, and cultural issues.<br/><br/>The overarching goal is to bridge this present technological gap in Earth System modeling, thereby illustrating how a common cyberinfrastructure can be used in different Earth science disciplines and communities, and how improved cyberinfrastructure can directly address pressing cross-disciplinary science questions.<br/><br/>The tools developed by the Earth System Bridge have the potential to serve many different disciplinary communities. A more interconnected and capable modeling community will significantly increase the speed at which knowledge is currently transferred between the research and operational communities, Connecting the academic and operational infrastructure will reduce inefficiencies and gaps that exists in the system today. The technology developed will place increased capabilities in the hands of a broader set of geoscientists, lowering the barriers to more scientists participating in multi-disciplinary research that is needed to address today?s policy issues and increase our national resilience to a wide variety of natural hazards."
"1440342","Earthcube RCN: Coral REef Science & CYberinfrastructure NeTwork (CReSCyNT)","ICER","EarthCube","09/01/2014","08/21/2014","Ruth Gates","HI","University of Hawaii","Standard Grant","Eva E. Zanzerkia","08/31/2017","$299,845.00","Megan Donahue, Gwen Jacobs, Judith Lemus, Erik Franklin","rgates@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","GEO","8074","7433, 9150","$0.00","This project develops the the Coral Reef Science & Cyberinfrastructure Network (CReSCyNT). As ecosystem engineers, corals provide the nutritional, economic, and structural basis of ecosystems worth billions of dollars annually. The broader impacts that CReSCyNT encompasses include: (i) integration and exchange with professional societies, (ii) development of visualization products in collaboration with educators and resource managers, (iii) connecting place-based collaborative networks, (iv) building a collaborative community in the coral reef discipline, (v) training of two graduate students, (vi) broad transfer of disciplinary expertise among geoscientists, cybertechnologists, medical scientists and graphic artists (media), (vii) raises visibility and awareness of coral reef data in the geosciences, and (viii) user-friendly web-based visualization tools accessible to the public that serve to showcase the value of coral reef science and the innovative approaches employed by the EarthCube program<br/><br/>The coral reef community has exceptionally diverse data structures and analysis requirements necessary to forward integrative science. It is therefore an exemplar for cyberinfrastructure-enabled advances to other geosciences communities. CReSCyNT will grow a multi-tiered and multidisciplinary network of coral reef researchers, cyberinfrastructure specialists, and computer scientists with the end goal of facilitating integrative and interactive research. This network will match the data sources, data structures, and analysis needs of the coral reef community with the current advances in data management, visualization, and image processing from ocean sciences, biomedical research, and graphic arts to advance coral reef research and meet the increasing challenges of coastal conservation. The network will assemble and communicate to coordinate, plan, and prioritize cyberinfrastructure needs within the coral reef community and with the broader geosciences. Our objectives are to collectively identify needs, best practices, bottlenecks, and avenues or approaches to advance the design and ultimately the development of data management, visualization, and image processing capacity for the coral reef domain that is directly and immediately translatable to the broader geoscience community.The five-member CReSCyNT Facilitating Committee will shepherd the growth of a network around 12 coral reef disciplinary nodes and 5 technology nodes, where each node represents a sub field or discipline of coral reef science (or computer science) that is led by a recognized member of that sub discipline in advocating sharing, transparency, open dialog, creativity, and the integration of data across the geosciences. Facilitated by CReSCyNT meetings, social media, and a presence at professional society conferences, the leader of each node will invite broad participation in CReSCyNT activities from members of their sub discipline. These nodes will be allowed to expand, coalesce, or divide to meet the needs and interests of the subdisciplinary communities, while maintaining a connection to CReSCyNT through the node coordinators and ongoing network activities."
"1354693","EAGER: Collaborative Research: EarthCube Building Blocks, Leveraging Semantics and Linked Data for Geoscience Data Sharing and Dis covery","ICER","EarthCube","09/15/2013","05/12/2014","Thomas Narock","MD","University of Maryland Baltimore County","Standard Grant","Barbara L. Ransom","08/31/2015","$74,984.00","Timothy Finin","thomas.w.narock@nasa.gov","1000 Hilltop Circle","Baltimore","MD","212500002","4104553140","GEO","8074","7433, 7916, 0000, OTHR","$0.00","This innovative project carries out exploratory research applying semantic technologies to support data representation, discovery, sharing, and integration between disparate geoscience data types and structures. It is a risky, high pay-off activity that, if successful, has the potential to transform our ability to discover, access, and use geoscience data in ways not possible at present. The goal of this research is to develop a prototype involving the data collections of some major NSF-funded Data Management Centers: IEDA and R2R at the Lamont Doherty Earth Observatory at Columbia University and BCO-DMO at the Woods Hole Oceanographic Institution. The effort is focused on making NSF-collected data for the ocean sciences and other associated datasets more easily and widely accessible and available to researchers and the public. Linked Open Data methodologies will be employed. Essential elements of this approach include the use of unique data identifiers to mark, link-to, and dereference specific data and details. Once the intial relationships are aligned, the new system can automatically infer new relationships between data and data locations. Goals will be to semantically integrate the data already available from the initially targeted data reposotiries in such a way that the approach can be scaled up to the whole of EarthCube, a new NSF initiative to develop a geoscience knowledge and data mangement system for the 21st Century. This project is a collaboration between ocean science resaerchers, computer scientists, and ocean data management centers from Maryland, Ohio, New York, and Massachusetts. Braoder impacts of the work include building infrastructure for science and improving public accessiblity to NSF-funded data collections."
"1540849","EarthCube IA: Collaborative Proposal: Cross-Domain Observational Metadata Environmental Sensing Network (X-DOMES)","ICER","EarthCube","09/01/2015","08/18/2015","Krzysztof Janowicz","CA","University of California-Santa Barbara","Standard Grant","Eva E. Zanzerkia","08/31/2017","$55,288.00","","jano@geog.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","GEO","8074","7433","$0.00","Across-domains, agencies and political boundaries, our environment is being continuously observed and studied. The researchers in this project are looking for short-term, near-term and long-term changes while researching new and evolving methods to observe properties and to process the collected observations. Emerging technologies enable us to provide and discover the data openly and freely. But, if we do not understand the newly discovered data, with its inherent limitations and biases, it cannot be responsibly utilized for new or collaborative research efforts. Working with environmental sensor manufacturers and researchers, the X-DOMES project will develop tools and social and technical infrastructure to facilitate the creation of data about data (metadata). Metadata describes not only who, when and where the observations were made, but also it must document how an observation came to be (provenance). By taking this knowledge out of manuals and human-readable documents, the X-DOMES model creates metadata that can be treated like data ? discoverable and searchable, making it ready to be incorporated into automated archival and processing for quality assurance and validation methods. <br/><br/>Leveraging existing relationships with large NSF-funded data management programs, EarthCube building blocks and working groups, and environmental sensor manufacturers and consortia, we will establish a community of sensor manufacturers and other stakeholders to provide a unifying approach to describing sensors and observations across geo-science domains. Built on an existing sensor metadata model that references registered, standards-based vocabularies, the X-DOMES pilot project will provide a suite of tools, built upon community-adopted standards of the Open Geospatial Consortium (OGC) and World Wide Web Consortium (W3C) to demonstrate and facilitate the generation of documents that are discoverable and accessible on-line and/or directly from onboard sensor descriptions. The project will also demonstrate mechanisms to associate the data with the metadata through standards-based web services. With vendor-ready tools implemented throughout a broad-based community, the X-DOMES Network will lay the foundation for the development of and adoption of interoperable access to much needed content-rich sensor metadata."
"1238409","Collaborative workshop proposal: Drawing the roadmap for the semantic/ontology based infrastructure for Geosciences","EAR","EarthCube","04/01/2012","03/27/2012","Hassan Babaie","GA","Georgia State University Research Foundation, Inc.","Standard Grant","Barbara L. Ransom","08/31/2013","$9,940.00","","hbabaie@gsu.edu","G76Dahlberg Hall 30 Courtland St","Atlanta","GA","303023999","4044133500","GEO","8074","7433","$0.00","EarthCube is focused on community-driven development of an integrated, and interoperable knowledge management system for data in the geo- and environmental sciences. By utilizing a cooperative, as opposed to competitive, process like that which created the Internet and Open Source software, EarthCube will attack the recalcitrant and persistent problems that so far have prevented adequate access to and the analysis, visualization, and interoperability of the vast storehouses of disparate geoscience data and data types residing in distributed and diverse data systems. This award funds a series of broad community interactions to gather adequate information and requirements to create a roadmap for a critical cyberinfrastructure capability (semantics and ontologies) in the development of EarthCube. In the context of cyberinfrastructure, semantics and ontologies are what allows heterogeneous and distributed data systems to become interoperable. They enable scientists to register, discover, access, and integrate data irrespective of its structural heterogeneity. This work convenes public, online/virtual meetings and seeks broad community input in the development of a process to have the geoscience and cyberinfrastructure communities converge on a way forward in the realm of semantics and ontologies for data, with the end product being a capability implementation roadmap. Also involved in the process is the identification of appropriate community agreed upon use cases. Broader impacts of the work include development of approaches, protocols, and standards that may be applicable across the sciences and the fostering of close interaction between communities that do not commonly interact, to a great extent, with one another moving them toward a common goal of the creation of a new paradigm in data and knowledge management in the geosciences."
"1321723","EarthCube Domain End-User Workshop: Community-Based Cyberinfrastructure for Petrology and Geochemistry","EAR","EarthCube","02/15/2013","02/11/2013","Kerstin Lehnert","NY","Columbia University","Standard Grant","Jennifer Wade","01/31/2016","$99,975.00","","lehnert@ldeo.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","GEO","8074","","$0.00","This workshop will bring together scientists from the petrology and geochemistry domains, data managers, sample curators, and cyberinfrastructure specialists to gather requirements and develop a vision for an advanced information and knowledge management system that will transform the way petrological and geochemical data and samples are acquired, analyzed, published, and re-used across the geosciences in the conduct of science. The outcomes of this workshop will provide guidance to the EarthCube initiative from the petrology-geochemistry community to design and develop the architecture of an Earth Science cyberinfrastructure that is aligned with the end-users' needs for data and sample access, software tools for data and metadata acquisition, workflow support, data analysis, data visualization, and modeling, computing capabilities, interoperability with data from other domains, as well as policies and procedures that address the scientists' concerns regarding, for example, data sharing, data citation, intellectual property, sample curation, and career advancement. The workshop report will be made widely accessible on the web."
"1533930","Workshop on Intelligent Systems Research to Support Geosciences and EarthCube Mission","IIS","INFO INTEGRATION & INFORMATICS, ROBUST INTELLIGENCE, EarthCube","03/01/2015","03/23/2015","Yolanda Gil","CA","University of Southern California","Standard Grant","Hector Munoz-Avila","02/29/2016","$99,999.00","","gil@isi.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","7364, 7495, 8074","7364, 7433, 7495, 7556","$0.00","This workshop will serve as a conduit for jump-starting synergistic research advancing our understanding of the Earth system through innovative cyber-infrastructure that pushes the envelope on information systems research. The workshop will help synthesize a vision and needs for intelligent systems research that will provide new capabilities envisioned by EarthCube to advance geosciences. The workshop will catalyze a community and research agenda in the emerging area of Discovery Informatics grounded on geoscience requirements. <br/><br/>Participants will discuss how to tackle problems in heterogeneous data integration and visualization (e.g., hand-made sketches, aerial imagery, field-data repositories, stakeholder interviews), ontological reasoning with scientific metadata and mathematical models (e.g., representing uncertainty, simulation predictions, evolving theories). The salient themes arising from discussions at the workshop will be articulated in detail in a final workshop report, which will be made available for the broad research community."
"1354990","EAGER: Collaborative Research: EarthCube Building Blocks, Leveraging | Semantics and Linked Data for Geoscience Data Sharing and Discovery","ICER","EarthCube","09/15/2013","08/12/2013","Robert Arko","NY","Columbia University","Standard Grant","Barbara L. Ransom","08/31/2015","$74,936.00","Suzanne Carbotte","arko@ldeo.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","GEO","8074","7433, 7916, 0000, OTHR","$0.00","This innovative project carries out exploratory research applying semantic technologies to support data representation, discovery, sharing, and integration between disparate geoscience data types and structures. It is a risky, high pay-off activity that, if successful, has the potential to transform our ability to discover, access, and use geoscience data in ways not possible at present. The goal of this research is to develop a prototype involving the data collections of some major NSF-funded Data Management Centers: IEDA and R2R at the Lamont Doherty Earth Observatory at Columbia University and BCO-DMO at the Woods Hole Oceanographic Institution. The effort is focused on making NSF-collected data for the ocean sciences and other associated datasets more easily and widely accessible and available to researchers and the public. Linked Open Data methodologies will be employed. Essential elements of this approach include the use of unique data identifiers to mark, link-to, and dereference specific data and details. Once the intial relationships are aligned, the new system can automatically infer new relationships between data and data locations. Goals will be to semantically integrate the data already available from the initially targeted data reposotiries in such a way that the approach can be scaled up to the whole of EarthCube, a new NSF initiative to develop a geoscience knowledge and data mangement system for the 21st Century. This project is a collaboration between ocean science resaerchers, computer scientists, and ocean data management centers from Maryland, Ohio, New York, and Massachusetts. Braoder impacts of the work include building infrastructure for science and improving public accessiblity to NSF-funded data collections."
"1354107","EAGER: Collaborative Research: EarthCube Building Blocks, Leveraging Semantics and Linked Data for Geoscience Data Sharing and Discovery","ICER","EarthCube","09/15/2013","08/12/2013","Cynthia Chandler","MA","Woods Hole Oceanographic Institution","Standard Grant","Barbara L. Ransom","08/31/2015","$74,993.00","","cchandler@whoi.edu","183 OYSTER POND ROAD","WOODS HOLE","MA","025431041","5082893542","GEO","8074","7916, 0000, OTHR","$0.00","This innovative project carries out exploratory research applying semantic technologies to support data representation, discovery, sharing, and integration between disparate geoscience data types and structures. It is a risky, high pay-off activity that, if successful, has the potential to transform our ability to discover, access, and use geoscience data in ways not possible at present. The goal of this research is to develop a prototype involving the data collections of some major NSF-funded Data Management Centers: IEDA and R2R at the Lamont Doherty Earth Observatory at Columbia University and BCO-DMO at the Woods Hole Oceanographic Institution. The effort is focused on making NSF-collected data for the ocean sciences and other associated datasets more easily and widely accessible and available to researchers and the public. Linked Open Data methodologies will be employed. Essential elements of this approach include the use of unique data identifiers to mark, link-to, and dereference specific data and details. Once the intial relationships are aligned, the new system can automatically infer new relationships between data and data locations. Goals will be to semantically integrate the data already available from the initially targeted data reposotiries in such a way that the approach can be scaled up to the whole of EarthCube, a new NSF initiative to develop a geoscience knowledge and data mangement system for the 21st Century. This project is a collaboration between ocean science resaerchers, computer scientists, and ocean data management centers from Maryland, Ohio, New York, and Massachusetts. Braoder impacts of the work include building infrastructure for science and improving public accessiblity to NSF-funded data collections."
"1354778","EAGER: Collaborative Research: EarthCube Building Blocks, Leveraging Semantics and Linked Data for Geoscience Data Sharing and Discovery","ICER","EarthCube","09/15/2013","08/12/2013","Pascal Hitzler","OH","Wright State University","Standard Grant","Barbara L. Ransom","08/31/2014","$74,999.00","","pascal.hitzler@wright.edu","3640 Colonel Glenn Highway","Dayton","OH","454350001","9377752425","GEO","8074","7433, 7916, 0000, OTHR","$0.00","This innovative project carries out exploratory research applying semantic technologies to support data representation, discovery, sharing, and integration between disparate geoscience data types and structures. It is a risky, high pay-off activity that, if successful, has the potential to transform our ability to discover, access, and use geoscience data in ways not possible at present. The goal of this research is to develop a prototype involving the data collections of some major NSF-funded Data Management Centers: IEDA and R2R at the Lamont Doherty Earth Observatory at Columbia University and BCO-DMO at the Woods Hole Oceanographic Institution. The effort is focused on making NSF-collected data for the ocean sciences and other associated datasets more easily and widely accessible and available to researchers and the public. Linked Open Data methodologies will be employed. Essential elements of this approach include the use of unique data identifiers to mark, link-to, and dereference specific data and details. Once the intial relationships are aligned, the new system can automatically infer new relationships between data and data locations. Goals will be to semantically integrate the data already available from the initially targeted data reposotiries in such a way that the approach can be scaled up to the whole of EarthCube, a new NSF initiative to develop a geoscience knowledge and data mangement system for the 21st Century. This project is a collaboration between ocean science resaerchers, computer scientists, and ocean data management centers from Maryland, Ohio, New York, and Massachusetts. Braoder impacts of the work include building infrastructure for science and improving public accessiblity to NSF-funded data collections."
"1238420","EAGER: Readiness of Disciplinary Data Systems for Cross-Domain Interoperability within a Standards-Based EarthCube Reference Framework","EAR","Software Institutes, EarthCube","04/01/2012","03/22/2012","Ilya Zaslavsky","CA","University of California-San Diego","Standard Grant","Barbara L. Ransom","03/31/2014","$217,932.00","","zaslavsk@sdsc.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","GEO","8004, 8074","7433, 7916","$0.00","This EAGER award promotes a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube. Led by a team of experts from across the fields of geoscience, cyberinfrastructure, engineering, and computer science this project focuses on using a collaborative, as opposed to competitive, method to create community consensus on the most appropriate means to realize interoperability of databases containing disparate data types that are widely distributed among many large and small data repositories. To achieve this goal, the project will create registries of interoperable infrastructure components for information-sharing of geoscience data; define user requirements for such a system; and carry out proof-of-concept, cross-domain interoperability workflows using federated catalogs, cross-linked vocabularies, common data services, and shared model semantics. One of the unique aspects of this project is that the approach employed utilizes an inclusive, community-driven, collaborative approach. It also engages individuals from most of the major NSF-funded geoscience data facilities, creating a much needed forum to exchange tools, services, and best practices allowing for a better return on research money investment. Broader impacts of the project include a focus on engaging students and young researchers in cross-domain data-intensive research, the likelihood that impacts of the project will crossover to other science domains, and the fact that some core project members were from under-represented groups in science and engineering. An additional broader impact is an international component that engages UK scientists as members of the core project team."
"1256100","The Role of Software and Software Institutes in Computational Science Over Time","ACI","CI-TEAM, Software Institutes","10/01/2012","09/04/2012","Ewa Deelman","CA","University of Southern California","Standard Grant","Daniel Katz","09/30/2014","$74,430.00","Miron Livny","deelman@isi.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","7477, 8004","8005, 8009, 7477","$0.00","The workshop will bring together Principle Investigators of the leading software cyberinfrastructure projects and discuss issues relevant to the community as we move into the future. In 2011 and 2012 the OCI Software Infrastructure for Sustained Innovation (SI2) program funded software efforts in small development efforts that can provide software pieces that can be integrated into the larger cyberinfrastructure, and larger collaborations that were delivering significant community software. In addition, new SI2 awards aimed at conceptualizing large-scale software institutes, aimed at providing a fabric for the software needed by domain scientists to achieve breakthroughs in their intra and inter-disciplinary efforts, will be awarded. New NSF initiatives such as EarthCube are defining roadmaps for cyberinfrastructure development in Earth sciences. This workshop will bring together the Principle Investigators of the recent SI2 awards to discuss potential synergies and collaborations, define challenges ahead, discuss the relationship of the SI2 efforts to the planned Software Institutes, and explore the relationship of the OCI-funded software in the context of the broad NSF initiatives such as EarthCube, DataWay, and other planned community-focused efforts.<br/><br/>To achieve its goals, the workshop will focus on these main themes: (i) Discussing SI2 projects within the context of SI2 Institutes and NSF-wide initiative such as EarthCube, DataWay, and others; (ii) sharing experiences in building quality software and services; (iii) fostering collaboration and providing incentives for collaboration and cyberinfrastructure development as a career; and (iv) sustaining the software capabilities in the long term, defining software value.<br/><br/>The workshop will solicit participation from major science and engineering projects that rely on the national cyberinfrastructure for their computations and data management needs. Their participation will help ensure that the cyberinfrastructure software developed as part of SI2 projects will be relevant and broadly applicable to a number of science and engineering domains. The results of this workshop will then potentially guide cyberinfrastructure development and testing in the future."
"1541031","EarthCube IA: Advancing netCDF-CF for the Geoscience Community","ICER","EarthCube","09/01/2015","08/27/2015","Ethan Davis","CO","University Corporation For Atmospheric Res","Standard Grant","Eva E. Zanzerkia","08/31/2017","$1,091,266.00","Charles Zender, Aleksandar Jelenak, David Arctur, Nicholas Bond","edavis@ucar.edu","3090 Center Green Drive","Boulder","CO","803012252","3034971000","GEO","8074","7433","$0.00","For a collection of scientific data to be useful to multiple independent research groups, the collection must contain auxiliary information that describes where and how the data were collected, the units of measurement used, and other similar details. This auxiliary information, known as ""metadata,"" is crucial to allowing scientists to understand the physical and derived quantities captured by the data. The Climate and Forecast (CF) metadata conventions for netCDF (netCDF-CF) are currently used widely by weather forecasters, climate scientists, and remote-sensing researchers to include metadata along with scientific data, and numerous open source and commercial software tools have been developed to explore and analyze data sets that use the conventions. This project will work to extend the existing metadata conventions in ways that will broaden the range of earth science domains whose data can be represented. By broadening the applicability of an established convention, this effort seeks to extend its benefits to related earth science domains and reduce the amount of effort scientists must expend decoding and reformatting datasets created by other research groups. This, in turn, will leave researchers more time for analysis, leading to a better understanding of the physical processes the data describe.<br/><br/>NetCDF-CF is a community-developed standard first released in 2003. Originally designed to represent climate and forecast model output encoded in the netCDF binary format, with the specific goal of facilitating comparison of output from different models, the standard is now widely accepted in the climate, weather, and remote-sensing research communities, but less so in other earth science domains. This project will extend the standard to better represent a data set's spatial extents, and to encompass earth science data sets not currently covered by the conventions, including radar and more complex satellite data. Additionally, the project will work to make netCDF-CF compatible with data stored in modern data structures developed since the original creation of the conventions. Since netCDF-CF is a community-based standard, the approach will be to bring stakeholders from the existing CF community together with experts from domains into which CF can logically be extended so they can work together to design and prototype a series of enhancements, which will be submitted to the larger community for consideration. The envisioned improvements will help diverse research groups use the conventions to faithfully represent their data in formats accessible using standard, widely-available software tools. This type of cross-domain data interoperability has the potential to give rise to more effective, integrated decisionmaking tools for a wide range of communities."
"1541029","EarthCube IA: Collaborative Proposal: LinkedEarth: Crowdsourcing Data Curation & Standards Development in Paleoclimatology","ICER","EarthCube","09/01/2015","07/28/2015","Julien Emile-Geay","CA","University of Southern California","Standard Grant","Eva E. Zanzerkia","08/31/2017","$684,779.00","Yolanda Gil","julieneg@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","GEO","8074","7433","$0.00","Natural climate variability signficantly modulates anthropogenic global warming, and only paleoclimate observations can adequately constrain it. Moreover, such observations are most powerful when many records are brought together to provide a spatial understanding of past variability. However, there is currently no universal way to share paleoclimate data between users or machines, hindering integration and synthesis. Large-scale, international, paleoclimate data syntheses have a long and successful history, but have been needlessly labor-intensive. Recognizing that (1) paleoclimate data curation requires expert knowledge; (2) top-down data management approaches are ineffectual; (3) existing infrastructure does not foster standardization; there emerges a critical need for a flexible platform enabling crowdsourced data curation and standards development.The platform will be combined with editorial and community-driven processes which will result in a system that has the potential to engage a broad user base in geoscientific data curation. The proposed framework will lower barriers to participation in the geosciences, enabling more ""dark data"" to join the public domain using community-sanctioned protocols. The pilot project will facilitate the work of hundreds of paleoclimate scientists, accelerating scientific discovery and the dissemination of its results to society.<br/><br/>Semantic wikis provide a simple, intuitive interface to semantic languages and infrastructure that build on open Web architecture. Like traditional wikis, they enable the collaborative authoring of content. Secure access and time-stamped content also enable the tracking of changes and the accountability of users, as well as moderation capabilities by community members of recognized expertise. In contrast to traditional wikis, semantic wikis allow contributors to assign meaning to their content, specifying relationships between the objects they describe. This enables artificial intelligence reasoners to parse, process and translate these data into more useful forms. The technology is well-proven, scalable, and completely transparent to the user, requiring no computer science knowledge or more sophisticated technology than a web browser. The LinkedEarth Wiki will automatically translate this information into Linked Open Data, a universal format to share data across the Web. To demonstrate this concept?s broad applicability across paleoclimate science, the project?s target community is the PAGES2k consortium, an international collaboration dedicated to the climate of the Common Era. Social technologies will be developed to power collective curation, standards development and quality control by the community itself. The project will demonstrate applicability to other paleogeosciences, serving as a potential template for other geoscientific disciplines."
"1639554","EarthCube Building Blocks: Collaborative Proposal: An Expanded Implementation of Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS)","ICER","EarthCube","09/01/2016","09/01/2016","Dorothy Stamps","VA","Virginia Polytechnic Institute and State University","Standard Grant","Eva E. Zanzerkia","08/31/2019","$87,811.00","","dstamps@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","GEO","8074","7433","$0.00","While advances in sensing, hardware and wireless communications are permitting for previously unmeasured phenomena to be observed across unprecedented scales, it is the ability to act on these data that promises to transform modern geoscientific experimentation. The importance of real-time scientific data (data that are used as soon as they are collected) is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Many of the phenomenon occurring within the geosciences can benefit from better coverage of real-time data. Geosciences phenomenon range from hurricanes and severe weather, to earthquakes, volcano eruptions and floods and real-time data are essential to understand these phenomena and predict their impacts. The National Science Foundation funds many small teams of researchers that reside at Universities whose measurements can be of benefit to a better understanding of these phenomenon in order to ultimately improve forecasts and predictions. This is where Cloud-Hosted Real-time Data Services for the Geosciences, or CHORDS, fits in.<br/><br/>CHORDS makes it simple for small research teams to make their real-time data available to the research community in standard formats. By following a few simple steps, a CHORDS ?portal? can be created for a research team and their data can be streamed into it very easily. CHORDS can also be used to access data from large NSF research platforms like radars, aircraft, ships and operational networks of sophisticated instrumentation. Once these data are ingested by a CHORDS portal, they are exposed in standard formats and are available to complex scientific tools such as prediction models and other analysis or decision-support systems. Since the CHORDS concept will be exposed to small research teams at Universities, this will allow college students to learn about the importance of real-time data and how to incorporate these data into their analysis. By having more and higher quality measurements available thorough CHORDS, models and other tools can make more accurate forecasts and provide better-informed decisions to mitigate the impacts and improve the understanding of these phenomenon."
"1639549","EarthCube Data Infrastructure: Collaborative Proposal: Development of an Integrated Data System for the Geological Field Sciences","ICER","EarthCube","09/01/2016","09/16/2016","Basil Tikoff","WI","University of Wisconsin-Madison","Standard Grant","Eva E. Zanzerkia","08/31/2019","$134,249.00","","basil@geology.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","GEO","8074","7433","$0.00","Geological field observations help us understand Earth history and are essential for developing hydrocarbon, groundwater, and mineral resources and for improving models of natural hazards like floods, earthquakes, and volcanoes. When geologists look at rocks or structures (like faults) in the field they collect a large variety of information. The traditional method for the collection of these data (still taught to students and practiced by geologists) is the writing of notes in a field notebook and the drawing of lines and symbols on maps or diagrams. Geologists all understand how to do this, but sharing the information with others is not easy or flexible ? most of the time these data are summarized in a report, table, or diagram leaving out the complete details of their discoveries. This project develops ays to easily gather, record and communicate information collected in the field. The main approach is to use handheld devices such as tablets or smart phones to collect information, mimicking closely the procedures used by field scientists, and then store the data in a format accessible to other scientists or the interested public. The system will also support those wanting to use traditional methods (notes in a field notebook) but then convert their data to digital format when they return. They aim to develop this data-collection and -sharing system, along with common definitions for technical terms, and distribute it broadly among the geoscience community. The project will last three years, and the efforts will be focused on both sedimentary rocks (the type formed by the action of wind or water) and igneous/metamorphic rocks (the types derived from molten rock or by the addition of heat and pressure on existing rocks). By the end of the project, geologists will be using the software and methodologies we develop to both collect and disseminate data from the field. The work and approach will be applicable to a broad spectrum of the field sciences including such areas as biology and ecology.<br/><br/>The project will develop a Data System for parts of the Geological Field Sciences that closely follows the existing workflows and vocabulary of the field geologist. The Data System will seamlessly incorporate the data from different sub-disciplines. The starting point will be an application and approach called Strabo, developed for this purpose by the Structural Geology and Tectonics community. The researchers intend to engage the Sedimentary Geology and Petrology communities and use the Strabo approach to establish data standards, data collection, and community buy-in. They will modify the existing Strabo platform to incorporate data types for Sedimentary Geology and Petrology, and build on the field-based application (StraboMobile) to fit the appropriate workflows. The project will 1) Hold community-wide town-hall meetings; 2) Engage expert panels to review workflows and vocabularies of the field scientists; and 3) Offer trips for junior to senior faculty to gather feedback about operation of the appropriate new field applications cloned from Strabo. This project will: 1) Provide digital databases for the geological field sciences that promote widespread and timely data-sharing; 2) Establish pathways for different sub-disciplines to interact and share data with each other and facilitate interdisciplinary integration of field data broadly across geosciences; and 3) Ensure public access to data from NSF-funded projects. At present, many communities are excluded from easy data communication because no common digital archives or even data reporting exists. The work will extensively engage post-doctoral fellows, graduate students, and junior faculty members to help train the next generation of geoscientists."
"1639722","EarthCube Building Blocks: Collaborative Proposal: That dot is a world! Drilling down from a statistics scatterplot to pre-populated case Notebooks.","ICER","EarthCube","09/01/2016","09/13/2016","Brian Mapes","FL","University of Miami Rosenstiel School of Marine&Atmospheric Sci","Standard Grant","Eva E. Zanzerkia","08/31/2019","$808,231.00","Mohamed Iskandarani","bmapes@rsmas.miami.edu","4600 RICKENBACKER CSWY","KEY BISCAYNE","FL","331491031","3054214089","GEO","8074","7433","$0.00","This project will develop and utilize capabilities for its scientists to ""drill down"" into abstract statistics about the flows of the atmosphere and ocean, to build a library of Notebooks with clear views of the actual weather systems (in the atmospheric part of the work) or Gulf of Mexico ocean eddies (in the ocean part of the work). The researchers will build this software, DRILSDOWN, using popular and powerful open-source software components that already exist, so it should be very generally applicable and have a long future. The power at the heart of the DRILSDOWN software will be the Integrated Data Viewer. The front end will consist of Jupyter Notebooks, a very popular new approach for literate computing and reproducibility of science. Literate computing allows a human-readable, meaningful, openly published document to have embedded computer-executable codes that can be repeated by anyone to replicate the results. The code can be adjusted if a user wants to see how analysis choices translate into outcomes. The involvement of scientists and a postdoc and and students will ensure the product development is useful to real research activities, while the collaboration with professional software developers (and the use of popular existing components) will ensure that it is robust and flexible enough to serve other use cases, including researchers in other areas of geoscience.<br/><br/>The project will develop and utilize new software called DRILSDOWN to facilitate the linking of statistics to instances, a key step in the science of complex systems. In order to guide and stress test the software development, the team will perform novel atmospheric and oceanic science newly enabled by DRILSDOWN. In the atmosphere, they will study some distinct but related published measures of high-impact flow events variously classified as Rossby wave breaking (or potential vorticity filamentation) in the upper troposphere, or as poleward water vapor transports in the lower troposphere. Three-dimensional case studies will show the relationship between these low- and high-altitude descriptions, based on statistics of each measure which will allow us to select cases with high-low, low-high, and high-high measures. How do these different measures perform at characterizing these high impact events, and how might they be reconciled and perhaps optimized? In the ocean, similar activity will be to examine statistical characterizations of eddy shedding from the Loop Current in the Gulf of Mexico, an important current system for oil spills, hurricanes, fisheries, and other hazards and interests. Full-detail case studies of marginal cases (shedding/ non-shedding) will inform fundamental science understanding of the shedding process, as well as helping to improve the algorithms for objectively measuring it, so that large ensembles of possible ocean flow scenarios can be more effectively and rapidly screened, with realistic uncertainty quantification, for instance in the event of an incident requiring ocean forecasts."
"1440323","EarthCube Building Blocks: Collaborative Proposal: GeoSoft: Collaborative Open Source Software Sharing for Geosciences","ICER","EarthCube","09/01/2014","08/14/2014","Yolanda Gil","CA","University of Southern California","Standard Grant","Eva E. Zanzerkia","08/31/2017","$1,048,000.00","Chris Mattmann","gil@isi.edu","University Park","Los Angeles","CA","900890001","2137407762","GEO","8074","7433","$0.00","Geosciences software embodies crucial scientific knowledge, and as such it should be explicitly captured, curated, managed, and disseminated. The goal of this project is to create a system for software stewardship in geosciences that will empower scientists to manage their software as valuable scientific assets. Scientific software stewardship requires a combination of cyberinfrastructure, social infrastructure, and professional development infrastructure. The framework will result in an open transparent and broader access to scientific software to other scientists, software professionals, students, and decision makers. It will significantly improve the adoption of open data and open software initiatives, improve reproducibility, and advance scientific scholarship.<br/><br/>The proposed research will advance knowledge and understanding of scientific software as a valuable community asset that is worth sharing, curating, cataloging, validating, reusing, and maintaining.<br/> 1) Facilitating software publication through TurboSoft, a personal assistant (analogous to TurboTax) that guides a user through best practices. Users will choose the degree of investment they are willing to make in componentizing, describing, licensing, and maintaining their software. The system will encourage open source publication, the formation of communities around the software, and set up mechanisms for software citation and credit. <br/>2) Enabling broad software dissemination through GeoSoft, a ""software commons"" for geosciences that will support software contributions (prepared through TurboSoft or otherwise), software discovery through multi-faceted search, and foster social interactions through dynamic formation of communities of interest. GeoSoft will interoperate with existing software repositories and modeling frameworks in geosciences. <br/>3) Providing just-in-time training materials through GeoCamp, an annotated collection of educational units ranging from basic education to professional training on all aspects of software stewardship. GeoCamp will be seamlessly integrated with TurboSoft and GeoSoft, and present a wide range of options for learning in the context of a user?s context of interaction with the framework or independently."
"1639694","EarthCube Building Blocks: Collaborative Proposal: The Power of Many: Ensemble Toolkit for Earth Sciences","ICER","EarthCube","09/01/2016","09/08/2016","Shantenu Jha","NJ","Rutgers University New Brunswick","Standard Grant","Eva E. Zanzerkia","08/31/2019","$509,643.00","","shantenu.jha@rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","GEO","8074","7433","$0.00","The study of hazards and renewable energy are paramount for the development and sustainability of society. Similarly, the emergence of new climatic patterns pose new challenges for future societal planning. Geospatial data are being generated at unprecedented rate exceeding our analysis capabilities and leading towards a data-rich but knowledge-poor environment. The use of advanced computing tools and techniques are playing an increasingly important role in contributing to solutions to problems of societal importance. This project will create specialized computational tools that will enhance the ability of scientists to effectively and efficiently study natural hazards and renewable energy. The use of these tools will support novel methods and the use of powerful computing resources in ways that are not currently possible.<br/><br/>Many scientific applications in the geosciences are increasingly reliant on ""ensemble-based"" methods to make scientific progress. This is true for applications that are both net producers of data, as well as aggregate consumers of data. In response to the growing importance and pervasiveness of ensemble-based applications and analysis, and to address the challenges of scale, simplicity and flexibility, the research team will develop the Ensemble Toolkit for Earth Sciences. The Ensemble Toolkit will provide an important addition to the set of capabilities and tools that will enable the geosciences community to use high-performance computing resources more efficiently, effectively and in an extensible fashion. This project represents the co-design of Ensemble Toolkit for Earth Sciences and is a collective effort of an interdisciplinary team of cyberinfrastructure and domain scientists. It will also support the integration of the Ensemble Toolkit with a range of science applications, as well as its use in solving scientific problems of significant societal impact that are currently unable to utilize the collective capacity of supercomputers, campus clusters and clouds"
"1540996","EarthCube IA: Collaborative Proposal: LinkedEarth: Crowdsourcing Data Curation & Standards Development in Paleoclimatology","ICER","EarthCube","09/01/2015","07/28/2015","Nicholas McKay","AZ","Northern Arizona University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$113,015.00","","Nicholas.McKay@nau.edu","ARD Building #56, Suite 240","Flagstaff","AZ","860110001","9285230886","GEO","8074","7433","$0.00","Natural climate variability signficantly modulates anthropogenic global warming, and only paleoclimate observations can adequately constrain it. Moreover, such observations are most powerful when many records are brought together to provide a spatial understanding of past variability. However, there is currently no universal way to share paleoclimate data between users or machines, hindering integration and synthesis. Large-scale, international, paleoclimate data syntheses have a long and successful history, but have been needlessly labor-intensive. Recognizing that (1) paleoclimate data curation requires expert knowledge; (2) top-down data management approaches are ineffectual; (3) existing infrastructure does not foster standardization; there emerges a critical need for a flexible platform enabling crowdsourced data curation and standards development.The platform will be combined with editorial and community-driven processes which will result in a system that has the potential to engage a broad user base in geoscientific data curation. The proposed framework will lower barriers to participation in the geosciences, enabling more ""dark data"" to join the public domain using community-sanctioned protocols. The pilot project will facilitate the work of hundreds of paleoclimate scientists, accelerating scientific discovery and the dissemination of its results to society.<br/><br/>Semantic wikis provide a simple, intuitive interface to semantic languages and infrastructure that build on open Web architecture. Like traditional wikis, they enable the collaborative authoring of content. Secure access and time-stamped content also enable the tracking of changes and the accountability of users, as well as moderation capabilities by community members of recognized expertise. In contrast to traditional wikis, semantic wikis allow contributors to assign meaning to their content, specifying relationships between the objects they describe. This enables artificial intelligence reasoners to parse, process and translate these data into more useful forms. The technology is well-proven, scalable, and completely transparent to the user, requiring no computer science knowledge or more sophisticated technology than a web browser. The LinkedEarth Wiki will automatically translate this information into Linked Open Data, a universal format to share data across the Web. To demonstrate this concept?s broad applicability across paleoclimate science, the project?s target community is the PAGES2k consortium, an international collaboration dedicated to the climate of the Common Era. Social technologies will be developed to power collective curation, standards development and quality control by the community itself. The project will demonstrate applicability to other paleogeosciences, serving as a potential template for other geoscientific disciplines."
"1440312","EarthCube Building Blocks: Collaborative Proposal: Digital Crust - A 4D Exploratory Environment for Earth Science Research and Learning","ICER","EarthCube","09/01/2014","08/08/2014","Shanan Peters","WI","University of Wisconsin-Madison","Standard Grant","Eva E. Zanzerkia","08/31/2017","$246,997.00","","peters@geology.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","GEO","8074","7433","$0.00","This project develops the Digital Crust, an online workspace where the geosciences community can contribute data and knowledge, visualize, explore, synthesize and test multiple hypotheses across space-time and themes, and derive 4D data product from multiple data.The platform can serve as a resource to bring together geoscientists working on separate aspects of the Earth system, by bringing their data/ideas together and by providing an environment to view the Earth from different perspectives. It will also be a ""one-stop shop"" for Earth science educators to expose the growing minds to the multi-faceted nature of Earth science problems and to see data and knowledge gaps which are powerful motivators for the young (not all problems have been solved ? there is a place for me to contribute). <br/><br/>The Digital Crust platform prototype will demonstrate technology that has the potential to transform the way geoscientists conduct research and learning, by (1) linking existing data repositories on all aspects of the Earth?s crust created by all disciplines of geosciences, communities as well as individuals, (2) creating a multi-context environment (e.g., tectonics, structural geology, stratigraphy, sedimentology, geomorphology, paleontology, archeology, mineralogy, geochemistry, soil science, hydrology, terrestrial ecology) at any given space (xyz) and time (t) for synthesis-type explorations, hypothesis-testing or learning, (3) allowing for multi-scale (e.g., outcrop to continent) data extractions and downloads for all research and learning applications, and (4) exposing data-knowledge gaps to identify the most rewarding future investments. Hosting multiple data types and sometimes conflicting interpretations and hypotheses of Earth processes will promote community discussion and debate on Earth processes that will foster interaction, collaboration, and data/idea sharing among scientists who might otherwise never have met. From the CI perspective, Digital Crust leverages and links with existing Building Blocks, explores the application of ""loose-schema"", noSQL databases to allow the flexibility necessary in a geoscience research database, and utilizes a modular software design to facilitate long-term maintenance and evolution of the platform."
"1542052","EarthCube RCN: Collaborative Research: Research Coordination Network for High-Performance Distributed Computing in the Polar Sciences","ICER","EarthCube","09/01/2015","08/04/2015","Jaroslaw Nabrzyski","IN","University of Notre Dame","Standard Grant","Eva E. Zanzerkia","08/31/2017","$27,300.00","","naber@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","GEO","8074","7433","$0.00","One of the major current challenges with polar cyberinfrastructure is managing and fully exploiting the<br/>volume of high-resolution commercial imagery now being collected over the polar regions. This data can be used to understand the changes in polar regions due to climate change and other processes. The potential of global socio-economic costs of these impacts make it an urgent priority to better understand polar systems. Understanding the mechanisms that underlie polar climate change and the links between polar and global climate systems requires a combination of field data, high-resolution observations from satellites, airborne imagery, and computer model outputs. Computational approaches have the potential to support faster and more fine-grained integration and analysis of these and other data types, thus increasing the efficiency of analyzing and understanding the complex processes. This project will support advances in computing tools and techniques that will enable the Polar Sciences Community to address significant challenges, both in the short and long-term.<br/><br/>The impact of this project will be in the improvements in the ability to utilize advanced cyberinfrastructure and high-performance distributed computing to fundamentally alter the scale, sophistication and scope of polar science problems that will be addressed. This project will not implement those changes but will identify and lay the groundwork for such impact across the Polar Sciences. The Project personnel will identify primary barriers to the uptake of high-performance and distributed computing and will help alleviate them through a combination of community based solutions and training. The project will also produce a roadmap detailing a credible and effective way to meet the long-term computing challenges faced by the Polar Science community and possible plans to effectively address them. This project will establish mechanisms for community engagement which include, gathering technical requirements for polar cyberinfrastructure and supporting and training early career scientists and graduate students."
"1440301","EarthCube Building Blocks Collaborative Proposal: Digital Crust ? An Exploratory Environment for Earth Science Research and Learning","ICER","EarthCube","09/01/2014","09/29/2014","Ilya Zaslavsky","CA","University of California-San Diego","Standard Grant","Eva E. Zanzerkia","08/31/2017","$502,497.00","Charles Kennel","zaslavsk@sdsc.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","GEO","8074","7433","$0.00","This project develops the Digital Crust, an online workspace where the geosciences community can contribute data and knowledge, visualize, explore, synthesize and test multiple hypotheses across space-time and themes, and derive 4D data product from multiple data.The platform can serve as a resource to bring together geoscientists working on separate aspects of the Earth system, by bringing their data/ideas together and by providing an environment to view the Earth from different perspectives. It will also be a ""one-stop shop"" for Earth science educators to expose the growing minds to the multi-faceted nature of Earth science problems and to see data and knowledge gaps which are powerful motivators for the young (not all problems have been solved ? there is a place for me to contribute). <br/><br/>The Digital Crust platform prototype will demonstrate technology that has the potential to transform the way geoscientists conduct research and learning, by (1) linking existing data repositories on all aspects of the Earth?s crust created by all disciplines of geosciences, communities as well as individuals, (2) creating a multi-context environment (e.g., tectonics, structural geology, stratigraphy, sedimentology, geomorphology, paleontology, archeology, mineralogy, geochemistry, soil science, hydrology, terrestrial ecology) at any given space (xyz) and time (t) for synthesis-type explorations, hypothesis-testing or learning, (3) allowing for multi-scale (e.g., outcrop to continent) data extractions and downloads for all research and learning applications, and (4) exposing data-knowledge gaps to identify the most rewarding future investments. Hosting multiple data types and sometimes conflicting interpretations and hypotheses of Earth processes will promote community discussion and debate on Earth processes that will foster interaction, collaboration, and data/idea sharing among scientists who might otherwise never have met. From the CI perspective, Digital Crust leverages and links with existing Building Blocks, explores the application of ""loose-schema"", noSQL databases to allow the flexibility necessary in a geoscience research database, and utilizes a modular software design to facilitate long-term maintenance and evolution of the platform."
"1440315","EarthCube Building Blocks: Collaborative Proposal: A Geo-Semantic Framework for Integrating Long-Tail Data and Models","ICER","EarthCube","09/01/2014","08/13/2014","Praveen Kumar","IL","University of Illinois at Urbana-Champaign","Standard Grant","Eva E. Zanzerkia","08/31/2017","$647,149.00","Mostafa Elag, Luigi Marini","kumar1@uiuc.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","GEO","8074","7433","$0.00","The project offers a unique and transformative approach to integrate existing and emerging long-tail model and data resources. Many challenges hinder the seamless integration of models with data. These challenges compel scientists to perform the integration process manually. The primary challenges are a consequence of the knowledge latency between model and data resources and others are derived from inadequate adoption and exploitation of information technologies. Knowledge latency challenges increase exponentially when a user aims to integrate long-tail data (data collected by individual researchers or small research groups) and long-tail models (models developed by individuals or small modeling communities).The goal of this research is to develop a framework rooted in semantic techniques and approaches to support ?long-tail? models and data integration. The vision is to develop a decentralized knowledge-based platform that can be easily adopted across geoscience communities comprising of individual and small group researchers. <br/><br/>This project offers a unique and transformative approach to integrate existing and emerging long-tail model and data resources. The project will develop a knowledge framework to close the loop from models? queries back to data sources by first investigating the required concepts architecture for integrating two leading examples of long-tail resources in geoscience: Community Surface Dynamic Modeling System (CSDMS) and Sustainable Environment Actionable Data (SEAD). The project will also develop a context-based data model that provides an explicit interpretation of a metadata attribute. The researchers will capture the metadata concepts and semantic from various geo-informatics systems and provide tools for ensuring conceptual integration between the resources. Next, the project will develop a knowledge discovery tool that allows automated coupling of a model and data coming from different contributors. Finally, the project will provide a prototype physical implementation of the knowledge framework in CSDMS modeling framework to demonstrate how it can advance the seamless discovery, selection, and integration between models and data, and how to achieve dynamic reusability of resources across multiple Earth Science long-tail resources."
"1440213","EarthCube Building Blocks: Collaborative Proposal: Enabling Scientific Collaboration and Discovery through Semantic Connections","ICER","EarthCube","09/01/2014","08/04/2014","Linda Rowan","CO","UNAVCO, Inc.","Standard Grant","Eva E. Zanzerkia","08/31/2017","$386,875.00","","rowan@unavco.org","6350 Nautilus Dr.","Boulder","CO","803015394","3033817636","GEO","8074","7433","$0.00","Data, information, ideas, and technologies diffuse through social and organizational networks, if the impediments to their adoption are low and the benefits of new approaches are clear. This project brings together the National Center for Atmospheric Research (NCAR), UNAVCO, and Cornell University to understand how to improve the processes of collaboration and resource sharing in the geosciences by demonstrating and encouraging the adoption of structured information systems rooted in common standards. Using two large geoscience research programs as case studies, this effort will demonstrate how semantic web and linked data technology can play an essential role in the coordination and organization of scientific virtual organizations and their products, thereby accelerating the pace of scientific discovery and innovation. <br/><br/><br/>The researchers will use a well-developed open source web application as an integrating data layer to expose the informational relationships and organizational collaborations within the case studies. This project will be an exemplar of using linked data to support virtual organizations in the geosciences. These efforts will feed into new tools that leverage linked data to support information and data exchange, and will produce recommendations on engaging user communities in linked data projects. This project will provide insight into how the geosciences can leverage linked data to produce more coherent methods of information and data discovery for large multi-disciplinary projects and virtual organizations. They will use the open source VIVO software application to illustrate how linked data can transform scientific project communication and dissemination via front end discovery based on rich networked metadata. The VIVO platform provides new capabilities for researchers and educators to use structured, interpretable data, permitting direct interlinking of information and data across platforms and projects. The project will structure data into an ontology-based, standard data format (RDF) for re-use, leveraging web identifier and vocabulary structures that have been well developed and widely adopted in the geoscience and cyberinfrastructure communities."
"1639720","EarthCube Building Blocks: Collaborative Proposal: An Expanded Implementation of CloudHosted Real-time Data Services for the Geosciences (CHORDS)","ICER","EarthCube","09/01/2016","09/01/2016","Sara Graves","AL","University of Alabama in Huntsville","Standard Grant","Eva E. Zanzerkia","08/31/2019","$145,911.00","","sgraves@itsc.uah.edu","301 Sparkman Drive","Huntsville","AL","358051911","2568246120","GEO","8074","7433, 9150","$0.00","While advances in sensing, hardware and wireless communications are permitting for previously unmeasured phenomena to be observed across unprecedented scales, it is the ability to act on these data that promises to transform modern geoscientific experimentation. The importance of real-time scientific data (data that are used as soon as they are collected) is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Many of the phenomenon occurring within the geosciences can benefit from better coverage of real-time data. Geosciences phenomenon range from hurricanes and severe weather, to earthquakes, volcano eruptions and floods and real-time data are essential to understand these phenomena and predict their impacts. The National Science Foundation funds many small teams of researchers that reside at Universities whose measurements can be of benefit to a better understanding of these phenomenon in order to ultimately improve forecasts and predictions. This is where Cloud-Hosted Real-time Data Services for the Geosciences, or CHORDS, fits in.<br/><br/>CHORDS makes it simple for small research teams to make their real-time data available to the research community in standard formats. By following a few simple steps, a CHORDS ?portal? can be created for a research team and their data can be streamed into it very easily. CHORDS can also be used to access data from large NSF research platforms like radars, aircraft, ships and operational networks of sophisticated instrumentation. Once these data are ingested by a CHORDS portal, they are exposed in standard formats and are available to complex scientific tools such as prediction models and other analysis or decision-support systems. Since the CHORDS concept will be exposed to small research teams at Universities, this will allow college students to learn about the importance of real-time data and how to incorporate these data into their analysis. By having more and higher quality measurements available thorough CHORDS, models and other tools can make more accurate forecasts and provide better-informed decisions to mitigate the impacts and improve the understanding of these phenomenon."
"1639640","EarthCube Building Blocks: Collaborative Proposal: An Expanded Implementation of Cloud-Hosted Real-Time Data Services for the Geosciences (CHORDS)","ICER","EarthCube","09/01/2016","09/01/2016","Branko Kerkez","MI","University of Michigan Ann Arbor","Standard Grant","Eva E. Zanzerkia","08/31/2019","$227,999.00","","bkerkez@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","GEO","8074","7433","$0.00","While advances in sensing, hardware and wireless communications are permitting for previously unmeasured phenomena to be observed across unprecedented scales, it is the ability to act on these data that promises to transform modern geoscientific experimentation. The importance of real-time scientific data (data that are used as soon as they are collected) is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Many of the phenomenon occurring within the geosciences can benefit from better coverage of real-time data. Geosciences phenomenon range from hurricanes and severe weather, to earthquakes, volcano eruptions and floods and real-time data are essential to understand these phenomena and predict their impacts. The National Science Foundation funds many small teams of researchers that reside at Universities whose measurements can be of benefit to a better understanding of these phenomenon in order to ultimately improve forecasts and predictions. This is where Cloud-Hosted Real-time Data Services for the Geosciences, or CHORDS, fits in.<br/><br/>CHORDS makes it simple for small research teams to make their real-time data available to the research community in standard formats. By following a few simple steps, a CHORDS ?portal? can be created for a research team and their data can be streamed into it very easily. CHORDS can also be used to access data from large NSF research platforms like radars, aircraft, ships and operational networks of sophisticated instrumentation. Once these data are ingested by a CHORDS portal, they are exposed in standard formats and are available to complex scientific tools such as prediction models and other analysis or decision-support systems. Since the CHORDS concept will be exposed to small research teams at Universities, this will allow college students to learn about the importance of real-time data and how to incorporate these data into their analysis. By having more and higher quality measurements available thorough CHORDS, models and other tools can make more accurate forecasts and provide better-informed decisions to mitigate the impacts and improve the understanding of these phenomenon."
"1639570","EarthCube Building Blocks: Collaborative Proposal: An Expanded Implementation of Cloud-Hosted Real-Time Data Services for the Geosciences (CHORDS)","ICER","EarthCube","09/01/2016","09/01/2016","V. Chandrasekar","CO","Colorado State University","Standard Grant","Eva E. Zanzerkia","08/31/2019","$228,600.00","","chandra@engr.colostate.edu","601 S Howes St","Fort Collins","CO","805232002","9704916355","GEO","8074","7433","$0.00","While advances in sensing, hardware and wireless communications are permitting for previously unmeasured phenomena to be observed across unprecedented scales, it is the ability to act on these data that promises to transform modern geoscientific experimentation. The importance of real-time scientific data (data that are used as soon as they are collected) is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Many of the phenomenon occurring within the geosciences can benefit from better coverage of real-time data. Geosciences phenomenon range from hurricanes and severe weather, to earthquakes, volcano eruptions and floods and real-time data are essential to understand these phenomena and predict their impacts. The National Science Foundation funds many small teams of researchers that reside at Universities whose measurements can be of benefit to a better understanding of these phenomenon in order to ultimately improve forecasts and predictions. This is where Cloud-Hosted Real-time Data Services for the Geosciences, or CHORDS, fits in.<br/><br/>CHORDS makes it simple for small research teams to make their real-time data available to the research community in standard formats. By following a few simple steps, a CHORDS ?portal? can be created for a research team and their data can be streamed into it very easily. CHORDS can also be used to access data from large NSF research platforms like radars, aircraft, ships and operational networks of sophisticated instrumentation. Once these data are ingested by a CHORDS portal, they are exposed in standard formats and are available to complex scientific tools such as prediction models and other analysis or decision-support systems. Since the CHORDS concept will be exposed to small research teams at Universities, this will allow college students to learn about the importance of real-time data and how to incorporate these data into their analysis. By having more and higher quality measurements available thorough CHORDS, models and other tools can make more accurate forecasts and provide better-informed decisions to mitigate the impacts and improve the understanding of these phenomenon."
"1540700","EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API","ICER","EarthCube","09/01/2015","07/30/2015","Roy Nelson","FL","Florida State University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$154,360.00","","gnelson@bio.fsu.edu","874 Traditions Way, 3rd Floor","TALLAHASSEE","FL","323064166","8506445260","GEO","8074","7433","$0.00","Understanding future environmental change requires researchers to access and integrate data from the geological and biological sciences, in order to answer questions about how environmental change will affect life on Earth. In many cases the data needed to answer these questions already exists but, unfortunately, technology has not kept pace with research needs. This places increasing demands on researchers, who have to search for and download data from multiple separate online databases; compile published information from many different literature sources; and track down specimens housed in museum and other collections scattered around the world. The time needed to search and retrieve this information is enormous and, once found, the data often have to be standardized before they can be used. This project will tackle this problem by developing software tools to connect three established, well-supported, and critically important data sources: the Paleobiology Database (PBDB, paleontological, literature based), iDigPaleo (paleontological, specimen based) and iDigBio (neontological, specimen based). This project will allow users of any one of these databases to access and query the others at the same time, returning a much richer, combined set of data to the user. Connecting these resources will open up a whole host of research questions that are currently difficult to answer, even by multiple researchers working as a team. The development of this system will allow scientists to ask and answer new research questions affecting fields as diverse as biogeographic/niche modeling, systematics, functional morphology, evolutionary biology, ecology, climatology, conservation biology, oceanography, and petroleum geology. This project will fundamentally change the nature of the research questions that can be addressed by the scientific community.<br/><br/>The connectivity between modern and fossil, and specimen and literature-based resources does not currently exist. The digital infrastructure provided by the composite ePANDDA application programming interfaces (APIs) will streamline and normalize data acquisition, including retrieval from disparate data sources, and will facilitate coordination with future data initiatives. Rather than creating another portal for the aggregation of data, ePANDDA will unify results that normally would have required multiple searches on numerous platforms. For the researcher, this eliminates a significant barrier to data collection and processing. Researchers will now have the ability to collaborate across disciplinary boundaries to study earth system processes and the nature of biotic response to environmental change across both space and time. Linking publications to specimens will enrich the potential of museum collections and augment their value for both research and education. The ePANDDA project also provides an opportunity to build collaborative programs that leverage existing education and outreach activities in addition to the primary research goals."
"1541002","EarthCube IA: Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics","ICER","EarthCube","09/01/2015","07/30/2015","John Williams","WI","University of Wisconsin-Madison","Standard Grant","Eva E. Zanzerkia","08/31/2017","$228,770.00","Simon Goring, Shanan Peters","jww@geography.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","GEO","8074","7433","$0.00","Paleontologists provide data about the past distribution and diversity of life. These data are useful both to geologists, because they can help determine the age of rocks, reconstruct past environments, and constrain models of the Earth system; and to biologists interested in the evolutionary history of organisms and the behavior of ecological systems during past global changes. Currently, data about fossils are dispersed across thousands of scientific publications, and dozens of small to large databases, only some of which are publicly available via the Internet. Even publicly available databases can be difficult to access because each stores different kinds of data with different conventions, requiring researchers to individually harmonize searches and their outputs. This project brings together six paleobiological databases so that they share a single set of Internet-based commands by which researchers and the public can easily access fossil records from all of Earth history. By coordinating with other emerging efforts in geological and biological data sharing, best practices, and protocols, we ensure that data will be freely available to all, enabling new scientific syntheses and discovery, more powerful educational opportunities, and general exploration of the history of life on Earth.<br/><br/>The paleobiological sciences sit at the nexus between geosciences and the biosciences, with close interdependencies in both domains. Within the geosciences, information about the past spatiotemporal distribution of organisms, species, and assemblages of species is essential to a wide array of allied disciplines: to sedimentologists and economic geologists studying facies relationships and employing biostratigraphic controls for correlating rock strata, to structural geologists and geophysicists seeking biogeographic constraints on reconstructions of former tectonic plate positions, to paleoclimatologists extracting paleoclimatic signals from paleoecological data, and to earth system modelers seeking to understand how biospheric dynamics have shaped, and continue to shape, the history of the Earth-Life system. Within the biosciences, the fossil record is essential for understanding how contemporary ecological systems are shaped by historical legacies of slow-acting processes, for testing climate-driven models of species distribution and diversity that are being used to project the impacts of 21st century climate change, for constraining phylogenetic models of species divergence and rates of evolution, and for understanding the fundamental drivers of biodiversity (i.e. species extinctions and originations). In an era of global change, when stewarding biodiversity is an urgent societal concern, conservation biologists, global change ecologists, and earth system scientists are all looking to the past to study the behavior of the Earth-Life system during rapid transitions. Paleobiological data are currently served by a wide array of databases that vary in structure, composition, temporal scales, types of data and metadata. To conduct ?global? or holistic analyses of the paleobiological record it is necessary to retrieve data from a variety of these databases - requiring queries of each database to retrieve the types of data needed. The purpose of this project is to make six different paleobiological databases interoperable so that they can be accessed via a common Application Programming Interface (API) to query the data from these and other databases. Towards that end, five key records of North American Pleistocene lakes will be uploaded and become available through this integrative project. This project also will increase the interoperability between these paleobiological resources and contemporary databases of species distributions and diversity, enabling continuous time-series analyses (e.g., of biodiversity) from the beginning of life on earth to today. Integration of the paleobiological databases with databases of the stratigraphic record (Macrostrat) will enhance the value of both types of data. New R packages will facilitate retrieval and analysis of data from all of the databases. Finally, this proposal establishes a Paleobiological Data Consortium, consisting of leaders of cyberinfrastructure resources in the paleobiosciences and allied disciplines, with the goal of sharing best practices and protocols among the geoinformatic and bioinformatic communities."
"1540902","EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API","ICER","EarthCube","09/01/2015","07/30/2015","Jocelyn Sessa","NY","American Museum Natural History","Standard Grant","Eva E. Zanzerkia","08/31/2017","$172,303.00","Neil Landman","jsessa@amnh.org","Central Park West at 79th St","New York","NY","100245192","2127695975","GEO","8074","7433","$0.00","Understanding future environmental change requires researchers to access and integrate data from the geological and biological sciences, in order to answer questions about how environmental change will affect life on Earth. In many cases the data needed to answer these questions already exists but, unfortunately, technology has not kept pace with research needs. This places increasing demands on researchers, who have to search for and download data from multiple separate online databases; compile published information from many different literature sources; and track down specimens housed in museum and other collections scattered around the world. The time needed to search and retrieve this information is enormous and, once found, the data often have to be standardized before they can be used. This project will tackle this problem by developing software tools to connect three established, well-supported, and critically important data sources: the Paleobiology Database (PBDB, paleontological, literature based), iDigPaleo (paleontological, specimen based) and iDigBio (neontological, specimen based). This project will allow users of any one of these databases to access and query the others at the same time, returning a much richer, combined set of data to the user. Connecting these resources will open up a whole host of research questions that are currently difficult to answer, even by multiple researchers working as a team. The development of this system will allow scientists to ask and answer new research questions affecting fields as diverse as biogeographic/niche modeling, systematics, functional morphology, evolutionary biology, ecology, climatology, conservation biology, oceanography, and petroleum geology. This project will fundamentally change the nature of the research questions that can be addressed by the scientific community.<br/><br/>The connectivity between modern and fossil, and specimen and literature-based resources does not currently exist. The digital infrastructure provided by the composite ePANDDA application programming interfaces (APIs) will streamline and normalize data acquisition, including retrieval from disparate data sources, and will facilitate coordination with future data initiatives. Rather than creating another portal for the aggregation of data, ePANDDA will unify results that normally would have required multiple searches on numerous platforms. For the researcher, this eliminates a significant barrier to data collection and processing. Researchers will now have the ability to collaborate across disciplinary boundaries to study earth system processes and the nature of biotic response to environmental change across both space and time. Linking publications to specimens will enrich the potential of museum collections and augment their value for both research and education. The ePANDDA project also provides an opportunity to build collaborative programs that leverage existing education and outreach activities in addition to the primary research goals."
"1440327","EarthCube Building Block: GeoDataspace: Simplifying Data Management for Geoscience Models","ICER","EarthCube","09/01/2014","08/08/2014","Tanu Malik","IL","University of Chicago","Standard Grant","Eva E. Zanzerkia","08/31/2017","$519,440.00","Ian Foster","tanu@cdm.depaul.edu","5801 South Ellis Avenue","Chicago","IL","606375418","7737028669","GEO","8074","7433","$0.00","A big obstacle to such sharing is the inordinate amount of time and effort that must be spent in creating, communicating, receiving, and interpreting specifications of data, models, and associated knowledge. This inability to quickly and conveniently share is particularly a problem in computational geoscience, wherein scientists spend significant portions of their time managing the many input and output files that are typically associated with a model. When developing, testing, validating, and comparing models, particularly coupled models, the number of such data elements and the complexity associated with their management soon outgrows human memory capacity. The unfortunate consequence is that researchers often narrow the scope of a model analysis, compromise research quality, or conduct analysis within restricted teams. This pilot project will demonstrate a mechanism to overcome this challenge in the scientific community.<br/><br/>The GeoDataspace pilot will develop a new data-centric approach to describing models and associated data resources for computational geoscience. This new approach will both simplify model use and enhance the shareability, reusability, and reproducibility of models, data, and computations?properties widely sought by computational geoscientists. Specifically, the project will develop methods for defining, sharing, and accessing geounits, collections of descriptive metadata that define a m the entire collection of files needed to run a computational model, including details about the model run. In the case of files, processing and manipulation scripts, manifests, spreadsheets, or one-off databases, the encapsulation may consist simplify of the elements location and specification of each element. The GeoDataspace team includes (a) experts in cyberinfrastructure, data management systems, and SaaS at UChicago; (b) experienced and leading geoscientists in four domains of solid earth, climate, hydrology, and space science, and a leading expert, as well as, geoscientist on model coupling frameworks. Together the team has identified a cross-cutting data management barrier that must be critically addressed in a domain-independent manner so as to extend capabilities to a broader set of geoscientists.All participating geoscientists are initiators, leaders, working-group chairs, and/or representatives of the five modeling communities we represent, including Computational Infrastructure for Geodynamics (CIG), Community Earth System Models (CESM), Consortium of Universities for the Advancement of Hydrological Science, Inc. (CUAHSI), and Community Coordinated Modeling Center (CCMC) at NASA, and finally Earth Systems Bridge (ESB), a community invested in developing model coupling frameworks. In total, the number of geoscientists either directly or indirectly involved in GeoDataspace is in the hundreds, if not thousands."
"1541028","EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API","ICER","EarthCube","09/01/2015","06/21/2016","Dena Smith","CO","Geological Society of America Today","Standard Grant","Eva E. Zanzerkia","08/31/2017","$82,734.00","","dena@colorado.edu","3300 PENROSE PL","Boulder","CO","803011806","3033571000","GEO","8074","7433","$0.00","Understanding future environmental change requires researchers to access and integrate data from the geological and biological sciences, in order to answer questions about how environmental change will affect life on Earth. In many cases the data needed to answer these questions already exists but, unfortunately, technology has not kept pace with research needs. This places increasing demands on researchers, who have to search for and download data from multiple separate online databases; compile published information from many different literature sources; and track down specimens housed in museum and other collections scattered around the world. The time needed to search and retrieve this information is enormous and, once found, the data often have to be standardized before they can be used. This project will tackle this problem by developing software tools to connect three established, well-supported, and critically important data sources: the Paleobiology Database (PBDB, paleontological, literature based), iDigPaleo (paleontological, specimen based) and iDigBio (neontological, specimen based). This project will allow users of any one of these databases to access and query the others at the same time, returning a much richer, combined set of data to the user. Connecting these resources will open up a whole host of research questions that are currently difficult to answer, even by multiple researchers working as a team. The development of this system will allow scientists to ask and answer new research questions affecting fields as diverse as biogeographic/niche modeling, systematics, functional morphology, evolutionary biology, ecology, climatology, conservation biology, oceanography, and petroleum geology. This project will fundamentally change the nature of the research questions that can be addressed by the scientific community.<br/><br/>The connectivity between modern and fossil, and specimen and literature-based resources does not currently exist. The digital infrastructure provided by the composite ePANDDA application programming interfaces (APIs) will streamline and normalize data acquisition, including retrieval from disparate data sources, and will facilitate coordination with future data initiatives. Rather than creating another portal for the aggregation of data, ePANDDA will unify results that normally would have required multiple searches on numerous platforms. For the researcher, this eliminates a significant barrier to data collection and processing. Researchers will now have the ability to collaborate across disciplinary boundaries to study earth system processes and the nature of biotic response to environmental change across both space and time. Linking publications to specimens will enrich the potential of museum collections and augment their value for both research and education. The ePANDDA project also provides an opportunity to build collaborative programs that leverage existing education and outreach activities in addition to the primary research goals."
"1540977","EarthCube IA: Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics","ICER","EarthCube","09/01/2015","07/30/2015","Jessica Blois","CA","University of California - Merced","Standard Grant","Eva E. Zanzerkia","08/31/2017","$68,118.00","","jblois@ucmerced.edu","5200 North Lake Road","Merced","CA","953435001","2097566405","GEO","8074","7433","$0.00","Paleontologists provide data about the past distribution and diversity of life. These data are useful both to geologists, because they can help determine the age of rocks, reconstruct past environments, and constrain models of the Earth system; and to biologists interested in the evolutionary history of organisms and the behavior of ecological systems during past global changes. Currently, data about fossils are dispersed across thousands of scientific publications, and dozens of small to large databases, only some of which are publicly available via the Internet. Even publicly available databases can be difficult to access because each stores different kinds of data with different conventions, requiring researchers to individually harmonize searches and their outputs. This project brings together six paleobiological databases so that they share a single set of Internet-based commands by which researchers and the public can easily access fossil records from all of Earth history. By coordinating with other emerging efforts in geological and biological data sharing, best practices, and protocols, we ensure that data will be freely available to all, enabling new scientific syntheses and discovery, more powerful educational opportunities, and general exploration of the history of life on Earth.<br/><br/>The paleobiological sciences sit at the nexus between geosciences and the biosciences, with close interdependencies in both domains. Within the geosciences, information about the past spatiotemporal distribution of organisms, species, and assemblages of species is essential to a wide array of allied disciplines: to sedimentologists and economic geologists studying facies relationships and employing biostratigraphic controls for correlating rock strata, to structural geologists and geophysicists seeking biogeographic constraints on reconstructions of former tectonic plate positions, to paleoclimatologists extracting paleoclimatic signals from paleoecological data, and to earth system modelers seeking to understand how biospheric dynamics have shaped, and continue to shape, the history of the Earth-Life system. Within the biosciences, the fossil record is essential for understanding how contemporary ecological systems are shaped by historical legacies of slow-acting processes, for testing climate-driven models of species distribution and diversity that are being used to project the impacts of 21st century climate change, for constraining phylogenetic models of species divergence and rates of evolution, and for understanding the fundamental drivers of biodiversity (i.e. species extinctions and originations). In an era of global change, when stewarding biodiversity is an urgent societal concern, conservation biologists, global change ecologists, and earth system scientists are all looking to the past to study the behavior of the Earth-Life system during rapid transitions. Paleobiological data are currently served by a wide array of databases that vary in structure, composition, temporal scales, types of data and metadata. To conduct ?global? or holistic analyses of the paleobiological record it is necessary to retrieve data from a variety of these databases - requiring queries of each database to retrieve the types of data needed. The purpose of this project is to make six different paleobiological databases interoperable so that they can be accessed via a common Application Programming Interface (API) to query the data from these and other databases. Towards that end, five key records of North American Pleistocene lakes will be uploaded and become available through this integrative project. This project also will increase the interoperability between these paleobiological resources and contemporary databases of species distributions and diversity, enabling continuous time-series analyses (e.g., of biodiversity) from the beginning of life on earth to today. Integration of the paleobiological databases with databases of the stratigraphic record (Macrostrat) will enhance the value of both types of data. New R packages will facilitate retrieval and analysis of data from all of the databases. Finally, this proposal establishes a Paleobiological Data Consortium, consisting of leaders of cyberinfrastructure resources in the paleobiosciences and allied disciplines, with the goal of sharing best practices and protocols among the geoinformatic and bioinformatic communities."
"1639724","EarthCube Data Infrastructure: Collaborative Proposal: Development of an Integrated Data System for the Geological Field Sciences","ICER","EarthCube","09/01/2016","09/16/2016","Allen Glazner","NC","University of North Carolina at Chapel Hill","Standard Grant","Eva E. Zanzerkia","08/31/2019","$151,236.00","","afg@unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","GEO","8074","7433","$0.00","Geological field observations help us understand Earth history and are essential for developing hydrocarbon, groundwater, and mineral resources and for improving models of natural hazards like floods, earthquakes, and volcanoes. When geologists look at rocks or structures (like faults) in the field they collect a large variety of information. The traditional method for the collection of these data (still taught to students and practiced by geologists) is the writing of notes in a field notebook and the drawing of lines and symbols on maps or diagrams. Geologists all understand how to do this, but sharing the information with others is not easy or flexible ? most of the time these data are summarized in a report, table, or diagram leaving out the complete details of their discoveries. This project develops ays to easily gather, record and communicate information collected in the field. The main approach is to use handheld devices such as tablets or smart phones to collect information, mimicking closely the procedures used by field scientists, and then store the data in a format accessible to other scientists or the interested public. The system will also support those wanting to use traditional methods (notes in a field notebook) but then convert their data to digital format when they return. They aim to develop this data-collection and -sharing system, along with common definitions for technical terms, and distribute it broadly among the geoscience community. The project will last three years, and the efforts will be focused on both sedimentary rocks (the type formed by the action of wind or water) and igneous/metamorphic rocks (the types derived from molten rock or by the addition of heat and pressure on existing rocks). By the end of the project, geologists will be using the software and methodologies we develop to both collect and disseminate data from the field. The work and approach will be applicable to a broad spectrum of the field sciences including such areas as biology and ecology.<br/><br/>The project will develop a Data System for parts of the Geological Field Sciences that closely follows the existing workflows and vocabulary of the field geologist. The Data System will seamlessly incorporate the data from different sub-disciplines. The starting point will be an application and approach called Strabo, developed for this purpose by the Structural Geology and Tectonics community. The researchers intend to engage the Sedimentary Geology and Petrology communities and use the Strabo approach to establish data standards, data collection, and community buy-in. They will modify the existing Strabo platform to incorporate data types for Sedimentary Geology and Petrology, and build on the field-based application (StraboMobile) to fit the appropriate workflows. The project will 1) Hold community-wide town-hall meetings; 2) Engage expert panels to review workflows and vocabularies of the field scientists; and 3) Offer trips for junior to senior faculty to gather feedback about operation of the appropriate new field applications cloned from Strabo. This project will: 1) Provide digital databases for the geological field sciences that promote widespread and timely data-sharing; 2) Establish pathways for different sub-disciplines to interact and share data with each other and facilitate interdisciplinary integration of field data broadly across geosciences; and 3) Ensure public access to data from NSF-funded projects. At present, many communities are excluded from easy data communication because no common digital archives or even data reporting exists. The work will extensively engage post-doctoral fellows, graduate students, and junior faculty members to help train the next generation of geoscientists."
"1639686","EarthCube Data Infrastructure: Collaborative Proposal: Development of an Integrated Data System for the Geological Field Sciences","ICER","EarthCube","09/01/2016","09/16/2016","Frank Spear","NY","Rensselaer Polytechnic Institute","Standard Grant","Eva E. Zanzerkia","08/31/2019","$138,165.00","","spearf@rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","GEO","8074","7433","$0.00","Geological field observations help us understand Earth history and are essential for developing hydrocarbon, groundwater, and mineral resources and for improving models of natural hazards like floods, earthquakes, and volcanoes. When geologists look at rocks or structures (like faults) in the field they collect a large variety of information. The traditional method for the collection of these data (still taught to students and practiced by geologists) is the writing of notes in a field notebook and the drawing of lines and symbols on maps or diagrams. Geologists all understand how to do this, but sharing the information with others is not easy or flexible ? most of the time these data are summarized in a report, table, or diagram leaving out the complete details of their discoveries. This project develops ays to easily gather, record and communicate information collected in the field. The main approach is to use handheld devices such as tablets or smart phones to collect information, mimicking closely the procedures used by field scientists, and then store the data in a format accessible to other scientists or the interested public. The system will also support those wanting to use traditional methods (notes in a field notebook) but then convert their data to digital format when they return. They aim to develop this data-collection and -sharing system, along with common definitions for technical terms, and distribute it broadly among the geoscience community. The project will last three years, and the efforts will be focused on both sedimentary rocks (the type formed by the action of wind or water) and igneous/metamorphic rocks (the types derived from molten rock or by the addition of heat and pressure on existing rocks). By the end of the project, geologists will be using the software and methodologies we develop to both collect and disseminate data from the field. The work and approach will be applicable to a broad spectrum of the field sciences including such areas as biology and ecology.<br/><br/>The project will develop a Data System for parts of the Geological Field Sciences that closely follows the existing workflows and vocabulary of the field geologist. The Data System will seamlessly incorporate the data from different sub-disciplines. The starting point will be an application and approach called Strabo, developed for this purpose by the Structural Geology and Tectonics community. The researchers intend to engage the Sedimentary Geology and Petrology communities and use the Strabo approach to establish data standards, data collection, and community buy-in. They will modify the existing Strabo platform to incorporate data types for Sedimentary Geology and Petrology, and build on the field-based application (StraboMobile) to fit the appropriate workflows. The project will 1) Hold community-wide town-hall meetings; 2) Engage expert panels to review workflows and vocabularies of the field scientists; and 3) Offer trips for junior to senior faculty to gather feedback about operation of the appropriate new field applications cloned from Strabo. This project will: 1) Provide digital databases for the geological field sciences that promote widespread and timely data-sharing; 2) Establish pathways for different sub-disciplines to interact and share data with each other and facilitate interdisciplinary integration of field data broadly across geosciences; and 3) Ensure public access to data from NSF-funded projects. At present, many communities are excluded from easy data communication because no common digital archives or even data reporting exists. The work will extensively engage post-doctoral fellows, graduate students, and junior faculty members to help train the next generation of geoscientists."
"1440333","EarthCube Building Blocks: Collaborative Proposal: A Geo-Semantic Framework for Integrating Long-Tail Data and Models","ICER","EarthCube","09/01/2014","08/13/2014","Scott Peckham","CO","University of Colorado at Boulder","Standard Grant","Eva E. Zanzerkia","08/31/2017","$262,299.00","","Scott.Peckham@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","GEO","8074","7433","$0.00","The project offers a unique and transformative approach to integrate existing and emerging long-tail model and data resources. Many challenges hinder the seamless integration of models with data. These challenges compel scientists to perform the integration process manually. The primary challenges are a consequence of the knowledge latency between model and data resources and others are derived from inadequate adoption and exploitation of information technologies. Knowledge latency challenges increase exponentially when a user aims to integrate long-tail data (data collected by individual researchers or small research groups) and long-tail models (models developed by individuals or small modeling communities).The goal of this research is to develop a framework rooted in semantic techniques and approaches to support ?long-tail? models and data integration. The vision is to develop a decentralized knowledge-based platform that can be easily adopted across geoscience communities comprising of individual and small group researchers. <br/><br/>This project offers a unique and transformative approach to integrate existing and emerging long-tail model and data resources. The project will develop a knowledge framework to close the loop from models? queries back to data sources by first investigating the required concepts architecture for integrating two leading examples of long-tail resources in geoscience: Community Surface Dynamic Modeling System (CSDMS) and Sustainable Environment Actionable Data (SEAD). The project will also develop a context-based data model that provides an explicit interpretation of a metadata attribute. The researchers will capture the metadata concepts and semantic from various geo-informatics systems and provide tools for ensuring conceptual integration between the resources. Next, the project will develop a knowledge discovery tool that allows automated coupling of a model and data coming from different contributors. Finally, the project will provide a prototype physical implementation of the knowledge framework in CSDMS modeling framework to demonstrate how it can advance the seamless discovery, selection, and integration between models and data, and how to achieve dynamic reusability of resources across multiple Earth Science long-tail resources."
"1639682","EarthCube Data Infrastructure: Collaborative Proposal: Development of an Integrated Data System for the Geological Field Sciences","ICER","EarthCube","09/01/2016","09/16/2016","Marjorie Chan","UT","University of Utah","Standard Grant","Eva E. Zanzerkia","08/31/2019","$226,000.00","","marjorie.chan@utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","GEO","8074","7433, 9150","$0.00","Geological field observations help us understand Earth history and are essential for developing hydrocarbon, groundwater, and mineral resources and for improving models of natural hazards like floods, earthquakes, and volcanoes. When geologists look at rocks or structures (like faults) in the field they collect a large variety of information. The traditional method for the collection of these data (still taught to students and practiced by geologists) is the writing of notes in a field notebook and the drawing of lines and symbols on maps or diagrams. Geologists all understand how to do this, but sharing the information with others is not easy or flexible ? most of the time these data are summarized in a report, table, or diagram leaving out the complete details of their discoveries. This project develops ays to easily gather, record and communicate information collected in the field. The main approach is to use handheld devices such as tablets or smart phones to collect information, mimicking closely the procedures used by field scientists, and then store the data in a format accessible to other scientists or the interested public. The system will also support those wanting to use traditional methods (notes in a field notebook) but then convert their data to digital format when they return. They aim to develop this data-collection and -sharing system, along with common definitions for technical terms, and distribute it broadly among the geoscience community. The project will last three years, and the efforts will be focused on both sedimentary rocks (the type formed by the action of wind or water) and igneous/metamorphic rocks (the types derived from molten rock or by the addition of heat and pressure on existing rocks). By the end of the project, geologists will be using the software and methodologies we develop to both collect and disseminate data from the field. The work and approach will be applicable to a broad spectrum of the field sciences including such areas as biology and ecology.<br/><br/>The project will develop a Data System for parts of the Geological Field Sciences that closely follows the existing workflows and vocabulary of the field geologist. The Data System will seamlessly incorporate the data from different sub-disciplines. The starting point will be an application and approach called Strabo, developed for this purpose by the Structural Geology and Tectonics community. The researchers intend to engage the Sedimentary Geology and Petrology communities and use the Strabo approach to establish data standards, data collection, and community buy-in. They will modify the existing Strabo platform to incorporate data types for Sedimentary Geology and Petrology, and build on the field-based application (StraboMobile) to fit the appropriate workflows. The project will 1) Hold community-wide town-hall meetings; 2) Engage expert panels to review workflows and vocabularies of the field scientists; and 3) Offer trips for junior to senior faculty to gather feedback about operation of the appropriate new field applications cloned from Strabo. This project will: 1) Provide digital databases for the geological field sciences that promote widespread and timely data-sharing; 2) Establish pathways for different sub-disciplines to interact and share data with each other and facilitate interdisciplinary integration of field data broadly across geosciences; and 3) Ensure public access to data from NSF-funded projects. At present, many communities are excluded from easy data communication because no common digital archives or even data reporting exists. The work will extensively engage post-doctoral fellows, graduate students, and junior faculty members to help train the next generation of geoscientists."
"1440332","EarthCube Building Blocks: Collaborative Proposal: GeoSoft: Collaborative Open Source Software Sharing for Geosciences","ICER","EarthCube","09/01/2014","08/14/2014","Scott Peckham","CO","University of Colorado at Boulder","Standard Grant","Eva E. Zanzerkia","08/31/2017","$330,000.00","","Scott.Peckham@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","GEO","8074","7433","$0.00","Geosciences software embodies crucial scientific knowledge, and as such it should be explicitly captured, curated, managed, and disseminated. The goal of this project is to create a system for software stewardship in geosciences that will empower scientists to manage their software as valuable scientific assets. Scientific software stewardship requires a combination of cyberinfrastructure, social infrastructure, and professional development infrastructure. The framework will result in an open transparent and broader access to scientific software to other scientists, software professionals, students, and decision makers. It will significantly improve the adoption of open data and open software initiatives, improve reproducibility, and advance scientific scholarship.<br/><br/>The proposed research will advance knowledge and understanding of scientific software as a valuable community asset that is worth sharing, curating, cataloging, validating, reusing, and maintaining.<br/> 1) Facilitating software publication through TurboSoft, a personal assistant (analogous to TurboTax) that guides a user through best practices. Users will choose the degree of investment they are willing to make in componentizing, describing, licensing, and maintaining their software. The system will encourage open source publication, the formation of communities around the software, and set up mechanisms for software citation and credit. <br/>2) Enabling broad software dissemination through GeoSoft, a ""software commons"" for geosciences that will support software contributions (prepared through TurboSoft or otherwise), software discovery through multi-faceted search, and foster social interactions through dynamic formation of communities of interest. GeoSoft will interoperate with existing software repositories and modeling frameworks in geosciences. <br/>3) Providing just-in-time training materials through GeoCamp, an annotated collection of educational units ranging from basic education to professional training on all aspects of software stewardship. GeoCamp will be seamlessly integrated with TurboSoft and GeoSoft, and present a wide range of options for learning in the context of a user?s context of interaction with the framework or independently."
"1440291","EarthCube Building Blocks: Collaborative Proposal: GeoSoft: Collaborative Open Source Software Sharing for Geosciences","ICER","EarthCube","09/01/2014","08/14/2014","Christopher Duffy","PA","Pennsylvania State Univ University Park","Standard Grant","Eva E. Zanzerkia","08/31/2016","$147,000.00","","cxd11@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","GEO","8074","7433","$0.00","Geosciences software embodies crucial scientific knowledge, and as such it should be explicitly captured, curated, managed, and disseminated. The goal of this project is to create a system for software stewardship in geosciences that will empower scientists to manage their software as valuable scientific assets. Scientific software stewardship requires a combination of cyberinfrastructure, social infrastructure, and professional development infrastructure. The framework will result in an open transparent and broader access to scientific software to other scientists, software professionals, students, and decision makers. It will significantly improve the adoption of open data and open software initiatives, improve reproducibility, and advance scientific scholarship.<br/><br/>The proposed research will advance knowledge and understanding of scientific software as a valuable community asset that is worth sharing, curating, cataloging, validating, reusing, and maintaining.<br/> 1) Facilitating software publication through TurboSoft, a personal assistant (analogous to TurboTax) that guides a user through best practices. Users will choose the degree of investment they are willing to make in componentizing, describing, licensing, and maintaining their software. The system will encourage open source publication, the formation of communities around the software, and set up mechanisms for software citation and credit. <br/>2) Enabling broad software dissemination through GeoSoft, a ""software commons"" for geosciences that will support software contributions (prepared through TurboSoft or otherwise), software discovery through multi-faceted search, and foster social interactions through dynamic formation of communities of interest. GeoSoft will interoperate with existing software repositories and modeling frameworks in geosciences. <br/>3) Providing just-in-time training materials through GeoCamp, an annotated collection of educational units ranging from basic education to professional training on all aspects of software stewardship. GeoCamp will be seamlessly integrated with TurboSoft and GeoSoft, and present a wide range of options for learning in the context of a user?s context of interaction with the framework or independently."
"1639707","EarthCube Building Blocks: Collaborative Proposal: The Power of Many: Ensemble Toolkit for Earth Sciences","ICER","EarthCube","09/01/2016","09/08/2016","Guido Cervone","PA","Pennsylvania State Univ University Park","Standard Grant","Eva E. Zanzerkia","08/31/2019","$391,000.00","Michael Mann","guc18@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","GEO","8074","026Z, 7433","$0.00","The study of hazards and renewable energy are paramount for the development and sustainability of society. Similarly, the emergence of new climatic patterns pose new challenges for future societal planning. Geospatial data are being generated at unprecedented rate exceeding our analysis capabilities and leading towards a data-rich but knowledge-poor environment. The use of advanced computing tools and techniques are playing an increasingly important role in contributing to solutions to problems of societal importance. This project will create specialized computational tools that will enhance the ability of scientists to effectively and efficiently study natural hazards and renewable energy. The use of these tools will support novel methods and the use of powerful computing resources in ways that are not currently possible.<br/><br/>Many scientific applications in the geosciences are increasingly reliant on ""ensemble-based"" methods to make scientific progress. This is true for applications that are both net producers of data, as well as aggregate consumers of data. In response to the growing importance and pervasiveness of ensemble-based applications and analysis, and to address the challenges of scale, simplicity and flexibility, the research team will develop the Ensemble Toolkit for Earth Sciences. The Ensemble Toolkit will provide an important addition to the set of capabilities and tools that will enable the geosciences community to use high-performance computing resources more efficiently, effectively and in an extensible fashion. This project represents the co-design of Ensemble Toolkit for Earth Sciences and is a collective effort of an interdisciplinary team of cyberinfrastructure and domain scientists. It will also support the integration of the Ensemble Toolkit with a range of science applications, as well as its use in solving scientific problems of significant societal impact that are currently unable to utilize the collective capacity of supercomputers, campus clusters and clouds"
"1639698","EarthCube Building Blocks: Collaborative Proposal: The Power of Many: Ensemble Toolkit for Earth Sciences","ICER","EarthCube","09/01/2016","09/08/2016","Jeroen Tromp","NJ","Princeton University","Standard Grant","Eva E. Zanzerkia","08/31/2019","$339,754.00","Matthieu Lefebvre","jtromp@princeton.edu","Off. of Research & Proj. Admin.","Princeton","NJ","085442020","6092583090","GEO","8074","7433","$0.00","The study of hazards and renewable energy are paramount for the development and sustainability of society. Similarly, the emergence of new climatic patterns pose new challenges for future societal planning. Geospatial data are being generated at unprecedented rate exceeding our analysis capabilities and leading towards a data-rich but knowledge-poor environment. The use of advanced computing tools and techniques are playing an increasingly important role in contributing to solutions to problems of societal importance. This project will create specialized computational tools that will enhance the ability of scientists to effectively and efficiently study natural hazards and renewable energy. The use of these tools will support novel methods and the use of powerful computing resources in ways that are not currently possible.<br/><br/>Many scientific applications in the geosciences are increasingly reliant on ""ensemble-based"" methods to make scientific progress. This is true for applications that are both net producers of data, as well as aggregate consumers of data. In response to the growing importance and pervasiveness of ensemble-based applications and analysis, and to address the challenges of scale, simplicity and flexibility, the research team will develop the Ensemble Toolkit for Earth Sciences. The Ensemble Toolkit will provide an important addition to the set of capabilities and tools that will enable the geosciences community to use high-performance computing resources more efficiently, effectively and in an extensible fashion. This project represents the co-design of Ensemble Toolkit for Earth Sciences and is a collective effort of an interdisciplinary team of cyberinfrastructure and domain scientists. It will also support the integration of the Ensemble Toolkit with a range of science applications, as well as its use in solving scientific problems of significant societal impact that are currently unable to utilize the collective capacity of supercomputers, campus clusters and clouds"
"1440288","EarthCube Building Blocks Collaborative Proposal: Digital Crust ? An Exploratory Environment for Earth Science Research and Learning","ICER","EarthCube","09/01/2014","08/08/2014","Ying Fan Reinfelder","NJ","Rutgers University New Brunswick","Standard Grant","Eva E. Zanzerkia","08/31/2017","$249,570.00","","yingfan@eps.rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","GEO","8074","7433","$0.00","This project develops the Digital Crust, an online workspace where the geosciences community can contribute data and knowledge, visualize, explore, synthesize and test multiple hypotheses across space-time and themes, and derive 4D data product from multiple data.The platform can serve as a resource to bring together geoscientists working on separate aspects of the Earth system, by bringing their data/ideas together and by providing an environment to view the Earth from different perspectives. It will also be a ""one-stop shop"" for Earth science educators to expose the growing minds to the multi-faceted nature of Earth science problems and to see data and knowledge gaps which are powerful motivators for the young (not all problems have been solved ? there is a place for me to contribute). <br/><br/>The Digital Crust platform prototype will demonstrate technology that has the potential to transform the way geoscientists conduct research and learning, by (1) linking existing data repositories on all aspects of the Earth?s crust created by all disciplines of geosciences, communities as well as individuals, (2) creating a multi-context environment (e.g., tectonics, structural geology, stratigraphy, sedimentology, geomorphology, paleontology, archeology, mineralogy, geochemistry, soil science, hydrology, terrestrial ecology) at any given space (xyz) and time (t) for synthesis-type explorations, hypothesis-testing or learning, (3) allowing for multi-scale (e.g., outcrop to continent) data extractions and downloads for all research and learning applications, and (4) exposing data-knowledge gaps to identify the most rewarding future investments. Hosting multiple data types and sometimes conflicting interpretations and hypotheses of Earth processes will promote community discussion and debate on Earth processes that will foster interaction, collaboration, and data/idea sharing among scientists who might otherwise never have met. From the CI perspective, Digital Crust leverages and links with existing Building Blocks, explores the application of ""loose-schema"", noSQL databases to allow the flexibility necessary in a geoscience research database, and utilizes a modular software design to facilitate long-term maintenance and evolution of the platform."
"1542058","EarthCube RCN: Collaborative Research: Research Coordination Network for High-Performance Distributed Computing in the Polar Sciences","ICER","EarthCube","09/01/2015","08/04/2015","Heather Lynch","NY","SUNY at Stony Brook","Standard Grant","Eva E. Zanzerkia","08/31/2017","$27,326.00","","heather.lynch@stonybrook.edu","WEST 5510 FRK MEL LIB","Stony Brook","NY","117940001","6316329949","GEO","8074","7433","$0.00","One of the major current challenges with polar cyberinfrastructure is managing and fully exploiting the<br/>volume of high-resolution commercial imagery now being collected over the polar regions. This data can be used to understand the changes in polar regions due to climate change and other processes. The potential of global socio-economic costs of these impacts make it an urgent priority to better understand polar systems. Understanding the mechanisms that underlie polar climate change and the links between polar and global climate systems requires a combination of field data, high-resolution observations from satellites, airborne imagery, and computer model outputs. Computational approaches have the potential to support faster and more fine-grained integration and analysis of these and other data types, thus increasing the efficiency of analyzing and understanding the complex processes. This project will support advances in computing tools and techniques that will enable the Polar Sciences Community to address significant challenges, both in the short and long-term.<br/><br/>The impact of this project will be in the improvements in the ability to utilize advanced cyberinfrastructure and high-performance distributed computing to fundamentally alter the scale, sophistication and scope of polar science problems that will be addressed. This project will not implement those changes but will identify and lay the groundwork for such impact across the Polar Sciences. The Project personnel will identify primary barriers to the uptake of high-performance and distributed computing and will help alleviate them through a combination of community based solutions and training. The project will also produce a roadmap detailing a credible and effective way to meet the long-term computing challenges faced by the Polar Science community and possible plans to effectively address them. This project will establish mechanisms for community engagement which include, gathering technical requirements for polar cyberinfrastructure and supporting and training early career scientists and graduate students."
"1542110","EarthCube RCN: Collaborative Research: Research Coordination Network for High-Performance Distributed Computing in the Polar Sciences","ICER","EarthCube","09/01/2015","08/04/2015","Shantenu Jha","NJ","Rutgers University New Brunswick","Standard Grant","Eva E. Zanzerkia","08/31/2017","$200,879.00","","shantenu.jha@rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","GEO","8074","7433","$0.00","One of the major current challenges with polar cyberinfrastructure is managing and fully exploiting the<br/>volume of high-resolution commercial imagery now being collected over the polar regions. This data can be used to understand the changes in polar regions due to climate change and other processes. The potential of global socio-economic costs of these impacts make it an urgent priority to better understand polar systems. Understanding the mechanisms that underlie polar climate change and the links between polar and global climate systems requires a combination of field data, high-resolution observations from satellites, airborne imagery, and computer model outputs. Computational approaches have the potential to support faster and more fine-grained integration and analysis of these and other data types, thus increasing the efficiency of analyzing and understanding the complex processes. This project will support advances in computing tools and techniques that will enable the Polar Sciences Community to address significant challenges, both in the short and long-term.<br/><br/>The impact of this project will be in the improvements in the ability to utilize advanced cyberinfrastructure and high-performance distributed computing to fundamentally alter the scale, sophistication and scope of polar science problems that will be addressed. This project will not implement those changes but will identify and lay the groundwork for such impact across the Polar Sciences. The Project personnel will identify primary barriers to the uptake of high-performance and distributed computing and will help alleviate them through a combination of community based solutions and training. The project will also produce a roadmap detailing a credible and effective way to meet the long-term computing challenges faced by the Polar Science community and possible plans to effectively address them. This project will establish mechanisms for community engagement which include, gathering technical requirements for polar cyberinfrastructure and supporting and training early career scientists and graduate students."
"1440229","EarthCube Building Blocks: Collaborative Proposal: A Geo-Semantic Framework for Integrating Long-Tail Data and Models","ICER","EarthCube","09/01/2014","06/28/2016","Leslie Hsu","NY","Columbia University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$87,673.00","","hsu.leslie@gmail.com","2960 Broadway","NEW YORK","NY","100276902","2128546851","GEO","8074","7433","$0.00","The project offers a unique and transformative approach to integrate existing and emerging long-tail model and data resources. Many challenges hinder the seamless integration of models with data. These challenges compel scientists to perform the integration process manually. The primary challenges are a consequence of the knowledge latency between model and data resources and others are derived from inadequate adoption and exploitation of information technologies. Knowledge latency challenges increase exponentially when a user aims to integrate long-tail data (data collected by individual researchers or small research groups) and long-tail models (models developed by individuals or small modeling communities).The goal of this research is to develop a framework rooted in semantic techniques and approaches to support ?long-tail? models and data integration. The vision is to develop a decentralized knowledge-based platform that can be easily adopted across geoscience communities comprising of individual and small group researchers. <br/><br/>This project offers a unique and transformative approach to integrate existing and emerging long-tail model and data resources. The project will develop a knowledge framework to close the loop from models? queries back to data sources by first investigating the required concepts architecture for integrating two leading examples of long-tail resources in geoscience: Community Surface Dynamic Modeling System (CSDMS) and Sustainable Environment Actionable Data (SEAD). The project will also develop a context-based data model that provides an explicit interpretation of a metadata attribute. The researchers will capture the metadata concepts and semantic from various geo-informatics systems and provide tools for ensuring conceptual integration between the resources. Next, the project will develop a knowledge discovery tool that allows automated coupling of a model and data coming from different contributors. Finally, the project will provide a prototype physical implementation of the knowledge framework in CSDMS modeling framework to demonstrate how it can advance the seamless discovery, selection, and integration between models and data, and how to achieve dynamic reusability of resources across multiple Earth Science long-tail resources."
"1541620","EarthCube RCN: Collaborative Research: Research Coordination Network for High-Performance Distributed Computing in the Polar Sciences","ICER","EarthCube","09/01/2015","05/25/2016","Allen Pope","CO","University of Colorado at Boulder","Standard Grant","Eva E. Zanzerkia","08/31/2017","$44,472.00","","allen.pope@nsidc.org","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","GEO","8074","7433","$0.00","One of the major current challenges with polar cyberinfrastructure is managing and fully exploiting the<br/>volume of high-resolution commercial imagery now being collected over the polar regions. This data can be used to understand the changes in polar regions due to climate change and other processes. The potential of global socio-economic costs of these impacts make it an urgent priority to better understand polar systems. Understanding the mechanisms that underlie polar climate change and the links between polar and global climate systems requires a combination of field data, high-resolution observations from satellites, airborne imagery, and computer model outputs. Computational approaches have the potential to support faster and more fine-grained integration and analysis of these and other data types, thus increasing the efficiency of analyzing and understanding the complex processes. This project will support advances in computing tools and techniques that will enable the Polar Sciences Community to address significant challenges, both in the short and long-term.<br/><br/>The impact of this project will be in the improvements in the ability to utilize advanced cyberinfrastructure and high-performance distributed computing to fundamentally alter the scale, sophistication and scope of polar science problems that will be addressed. This project will not implement those changes but will identify and lay the groundwork for such impact across the Polar Sciences. The Project personnel will identify primary barriers to the uptake of high-performance and distributed computing and will help alleviate them through a combination of community based solutions and training. The project will also produce a roadmap detailing a credible and effective way to meet the long-term computing challenges faced by the Polar Science community and possible plans to effectively address them. This project will establish mechanisms for community engagement which include, gathering technical requirements for polar cyberinfrastructure and supporting and training early career scientists and graduate students."
"1541015","EarthCube IA: Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics","ICER","EarthCube","09/01/2015","07/30/2015","Edward Davis","OR","University of Oregon Eugene","Standard Grant","Eva E. Zanzerkia","08/31/2017","$70,088.00","","edavis@uoregon.edu","5219 UNIVERSITY OF OREGON","Eugene","OR","974035219","5413465131","GEO","8074","7433","$0.00","Paleontologists provide data about the past distribution and diversity of life. These data are useful both to geologists, because they can help determine the age of rocks, reconstruct past environments, and constrain models of the Earth system; and to biologists interested in the evolutionary history of organisms and the behavior of ecological systems during past global changes. Currently, data about fossils are dispersed across thousands of scientific publications, and dozens of small to large databases, only some of which are publicly available via the Internet. Even publicly available databases can be difficult to access because each stores different kinds of data with different conventions, requiring researchers to individually harmonize searches and their outputs. This project brings together six paleobiological databases so that they share a single set of Internet-based commands by which researchers and the public can easily access fossil records from all of Earth history. By coordinating with other emerging efforts in geological and biological data sharing, best practices, and protocols, we ensure that data will be freely available to all, enabling new scientific syntheses and discovery, more powerful educational opportunities, and general exploration of the history of life on Earth.<br/><br/>The paleobiological sciences sit at the nexus between geosciences and the biosciences, with close interdependencies in both domains. Within the geosciences, information about the past spatiotemporal distribution of organisms, species, and assemblages of species is essential to a wide array of allied disciplines: to sedimentologists and economic geologists studying facies relationships and employing biostratigraphic controls for correlating rock strata, to structural geologists and geophysicists seeking biogeographic constraints on reconstructions of former tectonic plate positions, to paleoclimatologists extracting paleoclimatic signals from paleoecological data, and to earth system modelers seeking to understand how biospheric dynamics have shaped, and continue to shape, the history of the Earth-Life system. Within the biosciences, the fossil record is essential for understanding how contemporary ecological systems are shaped by historical legacies of slow-acting processes, for testing climate-driven models of species distribution and diversity that are being used to project the impacts of 21st century climate change, for constraining phylogenetic models of species divergence and rates of evolution, and for understanding the fundamental drivers of biodiversity (i.e. species extinctions and originations). In an era of global change, when stewarding biodiversity is an urgent societal concern, conservation biologists, global change ecologists, and earth system scientists are all looking to the past to study the behavior of the Earth-Life system during rapid transitions. Paleobiological data are currently served by a wide array of databases that vary in structure, composition, temporal scales, types of data and metadata. To conduct ?global? or holistic analyses of the paleobiological record it is necessary to retrieve data from a variety of these databases - requiring queries of each database to retrieve the types of data needed. The purpose of this project is to make six different paleobiological databases interoperable so that they can be accessed via a common Application Programming Interface (API) to query the data from these and other databases. Towards that end, five key records of North American Pleistocene lakes will be uploaded and become available through this integrative project. This project also will increase the interoperability between these paleobiological resources and contemporary databases of species distributions and diversity, enabling continuous time-series analyses (e.g., of biodiversity) from the beginning of life on earth to today. Integration of the paleobiological databases with databases of the stratigraphic record (Macrostrat) will enhance the value of both types of data. New R packages will facilitate retrieval and analysis of data from all of the databases. Finally, this proposal establishes a Paleobiological Data Consortium, consisting of leaders of cyberinfrastructure resources in the paleobiosciences and allied disciplines, with the goal of sharing best practices and protocols among the geoinformatic and bioinformatic communities."
"1541564","EarthCube RCN: Collaborative Research: Engaging the Greenland Ice Sheet Ocean (GRISO) Science Network","ICER","EarthCube","08/01/2016","08/04/2016","Fiammetta Straneo","MA","Woods Hole Oceanographic Institution","Standard Grant","Eva E. Zanzerkia","07/31/2018","$259,385.00","","fstraneo@ucsd.edu","183 OYSTER POND ROAD","WOODS HOLE","MA","025431041","5082893542","GEO","8074","7433","$0.00","Greenland ice loss quadrupled over the last two decades and presently accounts for one quarter of global sea level rise. The ice loss is due to changes in surface mass balance and ice sheet dynamics associated with rising air and ocean temperatures. The associated increasing freshwater discharge is impacting the regional ocean, including its ecosystems, and has the potential to impact the large-scale North Atlantic circulation. Thus, Greenland's changes are having far-reaching consequences for global societies, yet the mechanisms responsible for these changes are not well understood. Dynamic ice loss, in particular, was likely triggered by changes at the margins of marine-terminating glaciers, through ice/ocean/atmosphere processes that are either absent or poorly represented in climate, ice sheet and ocean models. The interaction of the ocean, the glaciers and atmosphere at Greenland?s margins is a new research frontier. The complex processes involved include the coupling of multiple components of the Earth system, the challenges of obtaining and integrating diverse data from this region, and of modeling such a complex system. These challenges make this a problem that can only be addressed by bringing together multiple disciplines, including data management, collaboratively exploring diverse approaches and working across national borders. This project establishes a network to help scientists working in this area to share their data and work collaboratively.<br/><br/>The goal of this project is to substantially enhance multi-disciplinary activities and collaboration through the establishment of the GRISO (Greenland Ice Sheet Ocean) Science Network - an international, multidisciplinary, open network of scientists and cyberinfrastructure experts. Participants have a shared interested in advancing collective understanding of problems related to Greenland Ice Sheet change and its impact on regional and global climate. GRISO RCN activities will bring together scientists focused on all aspects of ice/ocean/atmosphere/climate data in Greenland and provide a framework for productive collaborative interaction. Specific objectives include two workshops, and a series of synthesis efforts. Additionally, a virtual data portal, leveraging existing infrastructure, will make interdisciplinary data submission and data availability easier and promote uniform and appropriate data management practices. The RCN builds on activities initiated by the former GRISO US CLIVAR Working Group and explicitly addresses priorities identified in a report from an international workshop held in 2013."
"1541390","EarthCube RCN: Collaborative Research: Engaging the Greenland Ice Sheet Ocean (GRISO) Science Network","ICER","EarthCube","08/01/2016","08/04/2016","David Sutherland","OR","University of Oregon Eugene","Standard Grant","Eva E. Zanzerkia","07/31/2018","$43,424.00","Twila Moon","dsuth@uoregon.edu","5219 UNIVERSITY OF OREGON","Eugene","OR","974035219","5413465131","GEO","8074","7433","$0.00","Greenland ice loss quadrupled over the last two decades and presently accounts for one quarter of global sea level rise. The ice loss is due to changes in surface mass balance and ice sheet dynamics associated with rising air and ocean temperatures. The associated increasing freshwater discharge is impacting the regional ocean, including its ecosystems, and has the potential to impact the large-scale North Atlantic circulation. Thus, Greenland's changes are having far-reaching consequences for global societies, yet the mechanisms responsible for these changes are not well understood. Dynamic ice loss, in particular, was likely triggered by changes at the margins of marine-terminating glaciers, through ice/ocean/atmosphere processes that are either absent or poorly represented in climate, ice sheet and ocean models. The interaction of the ocean, the glaciers and atmosphere at Greenland?s margins is a new research frontier. The complex processes involved include the coupling of multiple components of the Earth system, the challenges of obtaining and integrating diverse data from this region, and of modeling such a complex system. These challenges make this a problem that can only be addressed by bringing together multiple disciplines, including data management, collaboratively exploring diverse approaches and working across national borders. This project establishes a network to help scientists working in this area to share their data and work collaboratively.<br/><br/>The goal of this project is to substantially enhance multi-disciplinary activities and collaboration through the establishment of the GRISO (Greenland Ice Sheet Ocean) Science Network - an international, multidisciplinary, open network of scientists and cyberinfrastructure experts. Participants have a shared interested in advancing collective understanding of problems related to Greenland Ice Sheet change and its impact on regional and global climate. GRISO RCN activities will bring together scientists focused on all aspects of ice/ocean/atmosphere/climate data in Greenland and provide a framework for productive collaborative interaction. Specific objectives include two workshops, and a series of synthesis efforts. Additionally, a virtual data portal, leveraging existing infrastructure, will make interdisciplinary data submission and data availability easier and promote uniform and appropriate data management practices. The RCN builds on activities initiated by the former GRISO US CLIVAR Working Group and explicitly addresses priorities identified in a report from an international workshop held in 2013."
"1343800","EarthCube Building Blocks: Software Stewardship for the Geosciences","ICER","EarthCube","09/15/2013","08/26/2015","Yolanda Gil","CA","University of Southern California","Standard Grant","Barbara L. Ransom","02/29/2016","$315,000.00","Chris Mattmann, Scott Peckham, Erin Robinson, Christopher Duffy","gil@isi.edu","University Park","Los Angeles","CA","900890001","2137407762","GEO","8074","7433, 0000, OTHR","$0.00","Geoscience and environmental science software is crucial for data analysis and generating new knowledge and understanding about the Earth. Because reproducibility of operations, calculations, and predictions done with this software is important for science, commercial, and regulatory applications, it is important that the software generated by geoscientists and their colleagues be captured, curated, managed, and made available to all interested parties upon request. This project initiates that process by building partnerships between computer scientist, software developers, and scientists across all geoscience domains with the goal or creating a software ecosystem and a culture of software stewardship that will empower geoscientists and others to make their software accessible and manage it as a valuable scientific asset. This work will examine the possibility of creating effective on-line tools that will guide users through best practices in software use and development, including componentizing codes, describing and documenting their codes, licensing their programs, and maintaining reusable code. It will also explore the best and most effective means for training geoscientists and providing appropriate educational/training materials to dramatically improve the ability of geoscientists to more effectively develop and curate software generated by themselves, their students, and others. Broader impacts of the work include building infrastructure for science, engagement of early career professionals in both computer and geoscience, and increasing cyber sophistication of geoscience practitioners. The project supports a core team that is geographically distributed (California, Pennsylvania, and Colorado) and partners with a nation-wide consortium of academic organizations dedicated to advancing geoscience geospatial needs."
"1343785","Title: EarthCube Building Blocks: Integrating Discrete and Continuous Data","ICER","EarthCube","09/15/2013","09/10/2013","David Maidment","TX","University of Texas at Austin","Standard Grant","Eva E. Zanzerkia","08/31/2016","$899,999.00","Ethan Davis, Alva Couch, Daniel Ames","maidment@mail.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","GEO","8074","7433","$0.00","Geoscience information is defined on both discrete and continuous spatial domains. Discrete<br/>spatial domains include point locations of observations at measurement sites and GIS coverages<br/>of point, line and area features used for observation and data interpretation. Continuous<br/>spatial domains are used in geophysical fluid sciences such as for the atmosphere, oceans,<br/>and land subsurface to describe arrays of measured or modeled variables defined on a mesh<br/>of uniformly spaced points. Data defined on either discrete or continuous spatial domains<br/>may also vary discretely or continuously in time, ranging from one-time samples, to samples<br/>at random points of time, to samples at regularly spaced intervals of time. This project<br/>builds upon previous work called ""Crossing the Digital Divide"" focused on integrated discovery<br/>of common information themes including precipitation in discrete data from the CUAHSI hydrologic<br/>information system and continuous data from the Unidata THREDDS data server. This project<br/>will advance that work by investigating in the first year creating new technologies for publishing<br/>and discovery of information through the Global Earth Observation System of Systems (GEOSS)<br/>Common Infrastructure, the definition of a Common Information Model for discrete and continuous<br/>data, development of shard software tools for using this Common Information Model, and extension<br/>of the concepts to similar information in the Polar, Ocean and Solid Earth Sciences.<br/><br/>This work builds on existing NSF data infrastructures and extends them in a reasonable way between two domains, Hydrology and Atmospheric Sciences, which are closely related intellectually, but have very different data environments. Some<br/>further extension into the Polar, Ocean and Solid Earth Sciences is also attainable. The project include the engagement of an international spectrum of collaborators<br/>through the Global Earth Observing System of Systems."
"1242909","EAGER Collaborative Research: Bringing Together Computational and Linguistic Methods to Extract 'Dark' Geosciences Data for the EarthCube Framework","EAR","EarthCube","07/15/2012","07/03/2012","Christopher Jenkins","CO","University of Colorado at Boulder","Standard Grant","Barbara L. Ransom","06/30/2013","$69,452.00","","chris.jenkins@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","GEO","8074","7433, 0000, 7916, OTHR","$0.00","A large percentage of vaulable geoscience data is based on the analysis of discrete samples and is collected manually (e.g., paleontological collections, structural/tectonic data, petrographic/mineralogic data, economic data, geochemical measurements, rock mechanics, etc.) Often, these data are reported only in tables in the published literature or in .pdf or spreadsheets on individual investigator websites. Commonly these data are not registerd on or entered into standardized, publicly accessible databases. As a result, for this data to be discovered and used/reused, researchers or other interested parties must manually comb through the text, figures, and appendices of journal articles or websites of individual investigators, sometimes having to sift through raw experimental data. This process is extremely time intensive and slows down the time needed to make scientific discoveries or allow verification of research results. As a result the vast amount of surface earth geoscience data is currently inaccessible. This inaccessible data is termed ""Dark Data"". This EAGER combines the expertise of top-notch computer scientists and geoscientists whose goal is to create a search algorithm to bring this dark data to light in a way that will enable the next generation of integrative geoscience research. The approach will involved development of an innovative search engine ""crawler"" that will comb the geoscience literature and bring dark data to light from the text and figures in this corpus. The cyberinfrastructure tool being developed will be able to interpret the semantics of English text and the concepts of geoscience. The tool will be piloted by examining entries on the Macrostrat database, a structured spatial database of lithologic and geochronologic information, and then employing a geoscience ontology by means of the Hazy framework for information extraction. Questions to be addressed will be to find out to what extent dark data is presently accessible and if it can be extracted and placed into an accessible format and repository where it can be discovered by web services or other search engines. Broader impacts of the work include training of graduate students and increasing the infrastructure for science through the development of a new and much needed data search tool."
"1242902","EAGER Collaborative: Bringing Together Computational and Linguistic Methods to Extract 'Dark' Geosciences Data for the EarthCube Framework","EAR","EarthCube","07/15/2012","07/03/2012","Christopher Re","WI","University of Wisconsin-Madison","Standard Grant","Barbara L. Ransom","06/30/2013","$129,380.00","Shanan Peters, Miron Livny","chrismre@cs.stanford.edu","21 North Park Street","MADISON","WI","537151218","6082623822","GEO","8074","7433, 0000, 7916, OTHR","$0.00","A large percentage of vaulable geoscience data is based on the analysis of discrete samples and is collected manually (e.g., paleontological collections, structural/tectonic data, petrographic/mineralogic data, economic data, geochemical measurements, rock mechanics, etc.) Often, these data are reported only in tables in the published literature or in .pdf or spreadsheets on individual investigator websites. Commonly these data are not registerd on or entered into standardized, publicly accessible databases. As a result, for this data to be discovered and used/reused, researchers or other interested parties must manually comb through the text, figures, and appendices of journal articles or websites of individual investigators, sometimes having to sift through raw experimental data. This process is extremely time intensive and slows down the time needed to make scientific discoveries or allow verification of research results. As a result the vast amount of surface earth geoscience data is currently inaccessible. This inaccessible data is termed ""Dark Data"". This EAGER combines the expertise of top-notch computer scientists and geoscientists whose goal is to create a search algorithm to bring this dark data to light in a way that will enable the next generation of integrative geoscience research. The approach will involved development of an innovative search engine ""crawler"" that will comb the geoscience literature and bring dark data to light from the text and figures in this corpus. The cyberinfrastructure tool being developed will be able to interpret the semantics of English text and the concepts of geoscience. The tool will be piloted by examining entries on the Macrostrat database, a structured spatial database of lithologic and geochronologic information, and then employing a geoscience ontology by means of the Hazy framework for information extraction. Questions to be addressed will be to find out to what extent dark data is presently accessible and if it can be extracted and placed into an accessible format and repository where it can be discovered by web services or other search engines. Broader impacts of the work include training of graduate students and increasing the infrastructure for science through the development of a new and much needed data search tool."
"1540979","EarthCube IA: Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics","ICER","EarthCube","09/01/2015","07/30/2015","Russell Graham","PA","Pennsylvania State Univ University Park","Standard Grant","Eva E. Zanzerkia","08/31/2017","$199,895.00","Brian Bills","rwg12@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","GEO","8074","7433","$0.00","Paleontologists provide data about the past distribution and diversity of life. These data are useful both to geologists, because they can help determine the age of rocks, reconstruct past environments, and constrain models of the Earth system; and to biologists interested in the evolutionary history of organisms and the behavior of ecological systems during past global changes. Currently, data about fossils are dispersed across thousands of scientific publications, and dozens of small to large databases, only some of which are publicly available via the Internet. Even publicly available databases can be difficult to access because each stores different kinds of data with different conventions, requiring researchers to individually harmonize searches and their outputs. This project brings together six paleobiological databases so that they share a single set of Internet-based commands by which researchers and the public can easily access fossil records from all of Earth history. By coordinating with other emerging efforts in geological and biological data sharing, best practices, and protocols, we ensure that data will be freely available to all, enabling new scientific syntheses and discovery, more powerful educational opportunities, and general exploration of the history of life on Earth.<br/><br/>The paleobiological sciences sit at the nexus between geosciences and the biosciences, with close interdependencies in both domains. Within the geosciences, information about the past spatiotemporal distribution of organisms, species, and assemblages of species is essential to a wide array of allied disciplines: to sedimentologists and economic geologists studying facies relationships and employing biostratigraphic controls for correlating rock strata, to structural geologists and geophysicists seeking biogeographic constraints on reconstructions of former tectonic plate positions, to paleoclimatologists extracting paleoclimatic signals from paleoecological data, and to earth system modelers seeking to understand how biospheric dynamics have shaped, and continue to shape, the history of the Earth-Life system. Within the biosciences, the fossil record is essential for understanding how contemporary ecological systems are shaped by historical legacies of slow-acting processes, for testing climate-driven models of species distribution and diversity that are being used to project the impacts of 21st century climate change, for constraining phylogenetic models of species divergence and rates of evolution, and for understanding the fundamental drivers of biodiversity (i.e. species extinctions and originations). In an era of global change, when stewarding biodiversity is an urgent societal concern, conservation biologists, global change ecologists, and earth system scientists are all looking to the past to study the behavior of the Earth-Life system during rapid transitions. Paleobiological data are currently served by a wide array of databases that vary in structure, composition, temporal scales, types of data and metadata. To conduct ?global? or holistic analyses of the paleobiological record it is necessary to retrieve data from a variety of these databases - requiring queries of each database to retrieve the types of data needed. The purpose of this project is to make six different paleobiological databases interoperable so that they can be accessed via a common Application Programming Interface (API) to query the data from these and other databases. Towards that end, five key records of North American Pleistocene lakes will be uploaded and become available through this integrative project. This project also will increase the interoperability between these paleobiological resources and contemporary databases of species distributions and diversity, enabling continuous time-series analyses (e.g., of biodiversity) from the beginning of life on earth to today. Integration of the paleobiological databases with databases of the stratigraphic record (Macrostrat) will enhance the value of both types of data. New R packages will facilitate retrieval and analysis of data from all of the databases. Finally, this proposal establishes a Paleobiological Data Consortium, consisting of leaders of cyberinfrastructure resources in the paleobiosciences and allied disciplines, with the goal of sharing best practices and protocols among the geoinformatic and bioinformatic communities."
"1639734","EarthCube Data Infrastructure: Collaborative Proposal: Development of an Integrated Data System for the Geological Field Sciences","ICER","EarthCube","09/01/2016","09/16/2016","J. Douglas Walker","KS","University of Kansas Center for Research Inc","Standard Grant","Eva E. Zanzerkia","08/31/2019","$740,338.00","Warren Alexander, Diane Kamola","jdwalker@ku.edu","2385 IRVING HILL RD","LAWRENCE","KS","660457568","7858643441","GEO","8074","7433, 9150","$0.00","Geological field observations help us understand Earth history and are essential for developing hydrocarbon, groundwater, and mineral resources and for improving models of natural hazards like floods, earthquakes, and volcanoes. When geologists look at rocks or structures (like faults) in the field they collect a large variety of information. The traditional method for the collection of these data (still taught to students and practiced by geologists) is the writing of notes in a field notebook and the drawing of lines and symbols on maps or diagrams. Geologists all understand how to do this, but sharing the information with others is not easy or flexible ? most of the time these data are summarized in a report, table, or diagram leaving out the complete details of their discoveries. This project develops ays to easily gather, record and communicate information collected in the field. The main approach is to use handheld devices such as tablets or smart phones to collect information, mimicking closely the procedures used by field scientists, and then store the data in a format accessible to other scientists or the interested public. The system will also support those wanting to use traditional methods (notes in a field notebook) but then convert their data to digital format when they return. They aim to develop this data-collection and -sharing system, along with common definitions for technical terms, and distribute it broadly among the geoscience community. The project will last three years, and the efforts will be focused on both sedimentary rocks (the type formed by the action of wind or water) and igneous/metamorphic rocks (the types derived from molten rock or by the addition of heat and pressure on existing rocks). By the end of the project, geologists will be using the software and methodologies we develop to both collect and disseminate data from the field. The work and approach will be applicable to a broad spectrum of the field sciences including such areas as biology and ecology.<br/><br/>The project will develop a Data System for parts of the Geological Field Sciences that closely follows the existing workflows and vocabulary of the field geologist. The Data System will seamlessly incorporate the data from different sub-disciplines. The starting point will be an application and approach called Strabo, developed for this purpose by the Structural Geology and Tectonics community. The researchers intend to engage the Sedimentary Geology and Petrology communities and use the Strabo approach to establish data standards, data collection, and community buy-in. They will modify the existing Strabo platform to incorporate data types for Sedimentary Geology and Petrology, and build on the field-based application (StraboMobile) to fit the appropriate workflows. The project will 1) Hold community-wide town-hall meetings; 2) Engage expert panels to review workflows and vocabularies of the field scientists; and 3) Offer trips for junior to senior faculty to gather feedback about operation of the appropriate new field applications cloned from Strabo. This project will: 1) Provide digital databases for the geological field sciences that promote widespread and timely data-sharing; 2) Establish pathways for different sub-disciplines to interact and share data with each other and facilitate interdisciplinary integration of field data broadly across geosciences; and 3) Ensure public access to data from NSF-funded projects. At present, many communities are excluded from easy data communication because no common digital archives or even data reporting exists. The work will extensively engage post-doctoral fellows, graduate students, and junior faculty members to help train the next generation of geoscientists."
"1639648","EarthCube Building Blocks: Collaborative Proposal: That dot is a world! Drilling down from a statistics scatterplot to pre-populated case Notebooks","ICER","EarthCube","09/01/2016","09/13/2016","Yuan Ho","CO","University Corporation For Atmospheric Res","Standard Grant","Eva E. Zanzerkia","08/31/2019","$545,496.00","","yuanho@ucar.edu","3090 Center Green Drive","Boulder","CO","803012252","3034971000","GEO","8074","7433","$0.00","This project will develop and utilize capabilities for its scientists to ""drill down"" into abstract statistics about the flows of the atmosphere and ocean, to build a library of Notebooks with clear views of the actual weather systems (in the atmospheric part of the work) or Gulf of Mexico ocean eddies (in the ocean part of the work). The researchers will build this software, DRILSDOWN, using popular and powerful open-source software components that already exist, so it should be very generally applicable and have a long future. The power at the heart of the DRILSDOWN software will be the Integrated Data Viewer. The front end will consist of Jupyter Notebooks, a very popular new approach for literate computing and reproducibility of science. Literate computing allows a human-readable, meaningful, openly published document to have embedded computer-executable codes that can be repeated by anyone to replicate the results. The code can be adjusted if a user wants to see how analysis choices translate into outcomes. The involvement of scientists and a postdoc and and students will ensure the product development is useful to real research activities, while the collaboration with professional software developers (and the use of popular existing components) will ensure that it is robust and flexible enough to serve other ?use cases?, including researchers in other areas of geoscience.<br/><br/>The project will develop and utilize new software called DRILSDOWN to facilitate the linking of statistics to instances, a key step in the science of complex systems. In order to guide and stress test the software development, the team will perform novel atmospheric and oceanic science newly enabled by DRILSDOWN. In the atmosphere, they will study some distinct but related published measures of high-impact flow events variously classified as Rossby wave breaking (or potential vorticity filamentation) in the upper troposphere, or as poleward water vapor transports in the lower troposphere. Three-dimensional case studies will show the relationship between these low- and high-altitude descriptions, based on statistics of each measure which will allow us to select cases with high-low, low-high, and high-high measures. How do these different measures perform at characterizing these high impact events, and how might they be reconciled and perhaps optimized? In the ocean, similar activity will be to examine statistical characterizations of eddy shedding from the Loop Current in the Gulf of Mexico, an important current system for oil spills, hurricanes, fisheries, and other hazards and interests. Full-detail case studies of marginal cases (shedding/ non-shedding) will inform fundamental science understanding of the shedding process, as well as helping to improve the algorithms for objectively measuring it, so that large ensembles of possible ocean flow scenarios can be more effectively and rapidly screened, with realistic uncertainty quantification, for instance in the event of an incident requiring ocean forecasts."
"1541043","EarthCube IA: Collaborative Proposal: Optimal Data Layout for Scalable Geophysical Analysis in a Data-intensive Environment","ICER","EarthCube","09/01/2015","09/08/2015","Hongfeng Yu","NE","University of Nebraska-Lincoln","Standard Grant","Eva E. Zanzerkia","08/31/2017","$332,941.00","","yu@cse.unl.edu","2200 Vine St, 151 Whittier","Lincoln","NE","685031435","4024723171","GEO","8074","7433, 9150","$0.00","Steady advance in remote sensing, satellite imaging, and computing technology has enabled scientists to study geophysical phenomena of unprecedented resolutions and complexity. Earth observation data generated from space-based satellites or ground-based radar and radiometer facilities are typically time-varying, and multivariate, and can take tera- or even peta-bytes of space to preserve and process. The common practice is to choose and transfer subsets of data from multiple data archive servers to local machines and then conduct data analysis tasks. However, this approach becomes increasingly unsustainable with an exponential growth of observation data size. It becomes an increasing severe problem that scientists can gain detailed observation data but lack suitable and scalable analysis capabilities to study the full extent of data. The team will work closely to develop, evaluate,and deploy the computer infrastructure to improve the performance and scalability of geophysical analysis for scientific discovery and education. By making the system available to other researchers, it will facilitate the development of new scalable solutions.Interactive geosciences applications will be used as an effective means to promote students interest in science and engineering studies, and to attract and retain students for geosciences community growth.<br/><br/>This research develops new techniques in support of scalable geophysical analysis in a data-intensive environment. The innovation and the basis of our technique approach are to develop an optimal data layout algorithm for indexing and placing massive heterogeneous observation data across distributed devices of a cluster. The new data layout is tailored to the spatial-temporal characteristics of Earth observation data, and can directly account for advanced compute techniques, including non-volatile storage resources and GPU- and Manycore-based computing nodes, and support high-throughput and high-resolution exploration of large-scale data. The long-term goal is to study theory and technology that enable scalable data management and analysis for the geosciences community."
"1540542","EarthCube IA: Collaborative Proposal: Optimal Data Layout for Scalable Geophysical Analysis in a Data-intensive Environment","ICER","EarthCube","09/01/2015","09/08/2015","Kwo-Sen Kuo","MD","University of Maryland College Park","Standard Grant","Eva E. Zanzerkia","08/31/2017","$242,906.00","","kkuo@umd.edu","3112 LEE BLDG 7809 Regents Drive","COLLEGE PARK","MD","207425141","3014056269","GEO","8074","7433, 9150","$0.00","Steady advance in remote sensing, satellite imaging, and computing technology has enabled scientists to study geophysical phenomena of unprecedented resolutions and complexity. Earth observation data generated from space-based satellites or ground-based radar and radiometer facilities are typically time-varying, and multivariate, and can take tera- or even peta-bytes of space to preserve and process. The common practice is to choose and transfer subsets of data from multiple data archive servers to local machines and then conduct data analysis tasks. However, this approach becomes increasingly unsustainable with an exponential growth of observation data size. It becomes an increasing severe problem that scientists can gain detailed observation data but lack suitable and scalable analysis capabilities to study the full extent of data. The team will work closely to develop, evaluate,and deploy the computer infrastructure to improve the performance and scalability of geophysical analysis for scientific discovery and education. By making the system available to other researchers, it will facilitate the development of new scalable solutions.Interactive geosciences applications will be used as an effective means to promote students interest in science and engineering studies, and to attract and retain students for geosciences community growth.<br/><br/>This research develops new techniques in support of scalable geophysical analysis in a data-intensive environment. The innovation and the basis of our technique approach are to develop an optimal data layout algorithm for indexing and placing massive heterogeneous observation data across distributed devices of a cluster. The new data layout is tailored to the spatial-temporal characteristics of Earth observation data, and can directly account for advanced compute techniques, including non-volatile storage resources and GPU- and Manycore-based computing nodes, and support high-throughput and high-resolution exploration of large-scale data. The long-term goal is to study theory and technology that enable scalable data management and analysis for the geosciences community."
"1440081","Earth Cube Building Blocks Collaborative Proposal: Cloud-Hosted Real-Time Data Services for the Geosciences (CHORDS)","ICER","EarthCube","09/01/2014","08/06/2014","Sara Graves","AL","University of Alabama in Huntsville","Standard Grant","Eva E. Zanzerkia","08/31/2016","$120,000.00","","sgraves@itsc.uah.edu","301 Sparkman Drive","Huntsville","AL","358051911","2568246120","GEO","8074","7433, 9150","$0.00","The importance of real-time scientific data is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Furthermore, advances in the distribution of real-time data are leading many new transient phenomena in space-time to be observed. Presently however, realtime decision-making is infeasible in many cases that require streaming scientific data to be coupled with complex models. While EarthCube will provide an unprecedented framework for disseminating data sources, the use of real-time data raises an additional set of complex challenges that must be considered. This project is a pilot to demonstrate the importance of coodinating the geosciences around their real-time data gathering and use. The work will demonstrate a Cloud-Hosted Real-time Data Services for the Geosciences (CHORDS)<br/><br/>The vision behind CHORDS is to provide a real-time data management infrastructure that will: a)Provide a system to archive, navigate and distribute real-time data streams via the Internet; b)Be easily deployed and configured; c)Run on cloud infrastructure; d)Use transactions built on RESTful protocols (i.e. via URLs); e)Employ data and metadata formats that adhere to standards, which simplify the user experience; f)Be free and open source.Science derived from observing platform data is the result of years of planning before a deployment, for example, and millions of dollars are spent on the deployment itself in hopes of obtaining the desired dataset. Many geo-scientific experiments are often resource constrained. In such cases it is vital to guarantee the optimal allocation of resources to ensure that important events do not go unobserved. In geo-scientific domains it is not uncommon to analyze data after a field campaigns, only to detect sensor faults, calibration offsets or anomalous behaviors when it is already too late. Real-time data will enable the optimal allocation of constrained experimental resources by automating the detection of faults and anomalies. CHORDS will provide a framework to enable adaptive sampling, discovery and fusion of various real-time geoscientific data sources, thus facilitating a new means by which geoscience experiments are carried out. The use cases will illustrate this by showing traditional experiments would have missed events of interest due to lack of access to real-time data. Focus on the initial work of defining requirements, design and specifications. Begin to ingest a small subset of geosciences data streams into a prototype CHORDS structure built in the cloud. Participate in activities that strengthen the integration of real-time data being ingested via CHORDS into other EarthCube Building Block systems that are under development. They will focus on some initial test cases, in hydrology sensor data, radar data streams, the NCAR Lower Atmosphere Observing Facilities, and outreach to earth and oceans communities."
"1440181","EarthCube Building Blocks: Collaborative Proposal: Enabling Scientific Collaboration and Discovery through Semantic Connections","ICER","EarthCube","09/01/2014","08/04/2014","Dean Krafft","NY","Cornell University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$404,884.00","","dean.krafft@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","GEO","8074","7433","$0.00","Data, information, ideas, and technologies diffuse through social and organizational networks, if the impediments to their adoption are low and the benefits of new approaches are clear. This project brings together the National Center for Atmospheric Research (NCAR), UNAVCO, and Cornell University to understand how to improve the processes of collaboration and resource sharing in the geosciences by demonstrating and encouraging the adoption of structured information systems rooted in common standards. Using two large geoscience research programs as case studies, this effort will demonstrate how semantic web and linked data technology can play an essential role in the coordination and organization of scientific virtual organizations and their products, thereby accelerating the pace of scientific discovery and innovation. <br/><br/><br/>The researchers will use a well-developed open source web application as an integrating data layer to expose the informational relationships and organizational collaborations within the case studies. This project will be an exemplar of using linked data to support virtual organizations in the geosciences. These efforts will feed into new tools that leverage linked data to support information and data exchange, and will produce recommendations on engaging user communities in linked data projects. This project will provide insight into how the geosciences can leverage linked data to produce more coherent methods of information and data discovery for large multi-disciplinary projects and virtual organizations. They will use the open source VIVO software application to illustrate how linked data can transform scientific project communication and dissemination via front end discovery based on rich networked metadata. The VIVO platform provides new capabilities for researchers and educators to use structured, interpretable data, permitting direct interlinking of information and data across platforms and projects. The project will structure data into an ontology-based, standard data format (RDF) for re-use, leveraging web identifier and vocabulary structures that have been well developed and widely adopted in the geoscience and cyberinfrastructure communities."
"1440293","EarthCube Building Blocks: Collaborative Proposal: Enabling Scientific Collaboration and Discovery through Semantic Connections","ICER","EarthCube","09/01/2014","08/04/2014","Matthew Mayernik","CO","University Corporation For Atmospheric Res","Standard Grant","Eva E. Zanzerkia","07/31/2017","$856,480.00","Michael Daniels","mayernik@ucar.edu","3090 Center Green Drive","Boulder","CO","803012252","3034971000","GEO","8074","7433","$0.00","Data, information, ideas, and technologies diffuse through social and organizational networks, if the impediments to their adoption are low and the benefits of new approaches are clear. This project brings together the National Center for Atmospheric Research (NCAR), UNAVCO, and Cornell University to understand how to improve the processes of collaboration and resource sharing in the geosciences by demonstrating and encouraging the adoption of structured information systems rooted in common standards. Using two large geoscience research programs as case studies, this effort will demonstrate how semantic web and linked data technology can play an essential role in the coordination and organization of scientific virtual organizations and their products, thereby accelerating the pace of scientific discovery and innovation. <br/><br/><br/>The researchers will use a well-developed open source web application as an integrating data layer to expose the informational relationships and organizational collaborations within the case studies. This project will be an exemplar of using linked data to support virtual organizations in the geosciences. These efforts will feed into new tools that leverage linked data to support information and data exchange, and will produce recommendations on engaging user communities in linked data projects. This project will provide insight into how the geosciences can leverage linked data to produce more coherent methods of information and data discovery for large multi-disciplinary projects and virtual organizations. They will use the open source VIVO software application to illustrate how linked data can transform scientific project communication and dissemination via front end discovery based on rich networked metadata. The VIVO platform provides new capabilities for researchers and educators to use structured, interpretable data, permitting direct interlinking of information and data across platforms and projects. The project will structure data into an ontology-based, standard data format (RDF) for re-use, leveraging web identifier and vocabulary structures that have been well developed and widely adopted in the geoscience and cyberinfrastructure communities."
"1639750","EarthCube Building Blocks: Collaborative Proposal: An Expanded Implementation of Cloud-Hosted Real-Time Data Services for the Geosciences (CHORDS)","ICER","EarthCube","09/01/2016","09/01/2016","Michael Daniels","CO","University Corporation For Atmospheric Res","Standard Grant","Eva E. Zanzerkia","08/31/2019","$742,673.00","","daniels@ucar.edu","3090 Center Green Drive","Boulder","CO","803012252","3034971000","GEO","8074","7433","$0.00","While advances in sensing, hardware and wireless communications are permitting for previously unmeasured phenomena to be observed across unprecedented scales, it is the ability to act on these data that promises to transform modern geoscientific experimentation. The importance of real-time scientific data (data that are used as soon as they are collected) is ever increasing, particularly in mission critical scenarios, where informed decisions must be made rapidly. Many of the phenomenon occurring within the geosciences can benefit from better coverage of real-time data. Geosciences phenomenon range from hurricanes and severe weather, to earthquakes, volcano eruptions and floods and real-time data are essential to understand these phenomena and predict their impacts. The National Science Foundation funds many small teams of researchers that reside at Universities whose measurements can be of benefit to a better understanding of these phenomenon in order to ultimately improve forecasts and predictions. This is where Cloud-Hosted Real-time Data Services for the Geosciences, or CHORDS, fits in.<br/><br/>CHORDS makes it simple for small research teams to make their real-time data available to the research community in standard formats. By following a few simple steps, a CHORDS ?portal? can be created for a research team and their data can be streamed into it very easily. CHORDS can also be used to access data from large NSF research platforms like radars, aircraft, ships and operational networks of sophisticated instrumentation. Once these data are ingested by a CHORDS portal, they are exposed in standard formats and are available to complex scientific tools such as prediction models and other analysis or decision-support systems. Since the CHORDS concept will be exposed to small research teams at Universities, this will allow college students to learn about the importance of real-time data and how to incorporate these data into their analysis. By having more and higher quality measurements available thorough CHORDS, models and other tools can make more accurate forecasts and provide better-informed decisions to mitigate the impacts and improve the understanding of these phenomenon."
"1639714","EarthCube Data Infrastructure: Laying the Groundwork for an Ocean Protein Portal","ICER","EarthCube","09/01/2016","08/31/2016","Mak Saito","MA","Woods Hole Oceanographic Institution","Standard Grant","Eva E. Zanzerkia","08/31/2018","$499,595.00","Danie Kinkade","msaito@whoi.edu","183 OYSTER POND ROAD","WOODS HOLE","MA","025431041","5082893542","GEO","8074","7433","$0.00","The measurement of the biological inventory of proteins within an organism, known as proteomics, has emerged as an important new biological methodology within the past decade. When this new technology is applied to environmental communities of microbes, typically called metaproteomics for its inclusion of a biological community, it has shown potential to significantly improve the understanding of ocean ecology and biogeochemistry by allowing a broad diagnosis of ecosystems across space and time. In this manner the measurement of proteins and the enzymes that catalyze throughout the ocean basins has great potential as a tool for ocean scientists interested in the chemistry and biology of the oceans. Yet being a relatively new data type, based in mass spectra rather than DNA sequence, proteomic datasets have their own specific informatics complexities. Currently these datasets are not easily accessed by the broader biological and chemical oceanographic communities. The researchers will develop an Ocean Protein Portal that will enable non-expert users to interrogate these large and complex ocean protein datasets.<br/><br/>The ability to connect protein distributions in the oceans, with their implied chemical functionality, with chemical and biological ocean datasets has the potential to enable a broad array of microbial and biogeochemical discovery.The proposed cyberinfrastructure will benefit the broader biological and chemical oceanographic communities through making microbial protein data widely accessible and enabling connections between biogeochemical data and the enzymes that catalyze their reactions. This foundational infrastructure would be accessible to life scientists from other (non-ocean) domains as well. The portal will also contribute to the interpretation of GEOTRACES trace metal and isotope ocean full depth ocean via the incorporation of future protein datasets and linkages to the chemical datasets in BCO-DMO. This project will provide BCO-DMO with an opportunity to research and employ new techniques for efficient data mining combined with semantic technologies that will enable better data discovery and access for its community. In addition, working closely with the proteomics community will allow BCO-DMO data managers to gain working experience with this emerging data type.Specific goals include: 1)<br/>creating text-based and sequence-based search capability of processed protein datasets, 2) creating a geospatial global map visualization as well as table output of the query protein?s occurrence in the oceans, 3) providing an Ocean Data View compatible table export of geospatial and temporal distributions of the queried protein, 4) providing an analytic capability to answer the question the taxonomic origin of the protein components, building on our METATRYP Python software and including a lowest common ancestor analysis for each peptide component of the queried protein sequence, 5) creating linkages between protein datasets and relevant environmental datasets within BCO-DMO, and 6) creating a repository for processed and raw ocean protein data."
"1540997","EarthCube IA: Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics","ICER","EarthCube","09/01/2015","07/30/2015","Mark Uhen","VA","George Mason University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$252,843.00","","muhen@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","GEO","8074","7433","$0.00","Paleontologists provide data about the past distribution and diversity of life. These data are useful both to geologists, because they can help determine the age of rocks, reconstruct past environments, and constrain models of the Earth system; and to biologists interested in the evolutionary history of organisms and the behavior of ecological systems during past global changes. Currently, data about fossils are dispersed across thousands of scientific publications, and dozens of small to large databases, only some of which are publicly available via the Internet. Even publicly available databases can be difficult to access because each stores different kinds of data with different conventions, requiring researchers to individually harmonize searches and their outputs. This project brings together six paleobiological databases so that they share a single set of Internet-based commands by which researchers and the public can easily access fossil records from all of Earth history. By coordinating with other emerging efforts in geological and biological data sharing, best practices, and protocols, we ensure that data will be freely available to all, enabling new scientific syntheses and discovery, more powerful educational opportunities, and general exploration of the history of life on Earth.<br/><br/>The paleobiological sciences sit at the nexus between geosciences and the biosciences, with close interdependencies in both domains. Within the geosciences, information about the past spatiotemporal distribution of organisms, species, and assemblages of species is essential to a wide array of allied disciplines: to sedimentologists and economic geologists studying facies relationships and employing biostratigraphic controls for correlating rock strata, to structural geologists and geophysicists seeking biogeographic constraints on reconstructions of former tectonic plate positions, to paleoclimatologists extracting paleoclimatic signals from paleoecological data, and to earth system modelers seeking to understand how biospheric dynamics have shaped, and continue to shape, the history of the Earth-Life system. Within the biosciences, the fossil record is essential for understanding how contemporary ecological systems are shaped by historical legacies of slow-acting processes, for testing climate-driven models of species distribution and diversity that are being used to project the impacts of 21st century climate change, for constraining phylogenetic models of species divergence and rates of evolution, and for understanding the fundamental drivers of biodiversity (i.e. species extinctions and originations). In an era of global change, when stewarding biodiversity is an urgent societal concern, conservation biologists, global change ecologists, and earth system scientists are all looking to the past to study the behavior of the Earth-Life system during rapid transitions. Paleobiological data are currently served by a wide array of databases that vary in structure, composition, temporal scales, types of data and metadata. To conduct ?global? or holistic analyses of the paleobiological record it is necessary to retrieve data from a variety of these databases - requiring queries of each database to retrieve the types of data needed. The purpose of this project is to make six different paleobiological databases interoperable so that they can be accessed via a common Application Programming Interface (API) to query the data from these and other databases. Towards that end, five key records of North American Pleistocene lakes will be uploaded and become available through this integrative project. This project also will increase the interoperability between these paleobiological resources and contemporary databases of species distributions and diversity, enabling continuous time-series analyses (e.g., of biodiversity) from the beginning of life on earth to today. Integration of the paleobiological databases with databases of the stratigraphic record (Macrostrat) will enhance the value of both types of data. New R packages will facilitate retrieval and analysis of data from all of the databases. Finally, this proposal establishes a Paleobiological Data Consortium, consisting of leaders of cyberinfrastructure resources in the paleobiosciences and allied disciplines, with the goal of sharing best practices and protocols among the geoinformatic and bioinformatic communities."
"1540984","EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API","ICER","EarthCube","09/01/2015","07/30/2015","Christopher Norris","CT","Yale University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$274,244.00","Talia Karim, Susan Butts, Lawrence Gall","christopher.norris@yale.edu","Office of Sponsored Projects","New Haven","CT","065208327","2037854689","GEO","8074","7433","$0.00","Understanding future environmental change requires researchers to access and integrate data from the geological and biological sciences, in order to answer questions about how environmental change will affect life on Earth. In many cases the data needed to answer these questions already exists but, unfortunately, technology has not kept pace with research needs. This places increasing demands on researchers, who have to search for and download data from multiple separate online databases; compile published information from many different literature sources; and track down specimens housed in museum and other collections scattered around the world. The time needed to search and retrieve this information is enormous and, once found, the data often have to be standardized before they can be used. This project will tackle this problem by developing software tools to connect three established, well-supported, and critically important data sources: the Paleobiology Database (PBDB, paleontological, literature based), iDigPaleo (paleontological, specimen based) and iDigBio (neontological, specimen based). This project will allow users of any one of these databases to access and query the others at the same time, returning a much richer, combined set of data to the user. Connecting these resources will open up a whole host of research questions that are currently difficult to answer, even by multiple researchers working as a team. The development of this system will allow scientists to ask and answer new research questions affecting fields as diverse as biogeographic/niche modeling, systematics, functional morphology, evolutionary biology, ecology, climatology, conservation biology, oceanography, and petroleum geology. This project will fundamentally change the nature of the research questions that can be addressed by the scientific community.<br/><br/>The connectivity between modern and fossil, and specimen and literature-based resources does not currently exist. The digital infrastructure provided by the composite ePANDDA application programming interfaces (APIs) will streamline and normalize data acquisition, including retrieval from disparate data sources, and will facilitate coordination with future data initiatives. Rather than creating another portal for the aggregation of data, ePANDDA will unify results that normally would have required multiple searches on numerous platforms. For the researcher, this eliminates a significant barrier to data collection and processing. Researchers will now have the ability to collaborate across disciplinary boundaries to study earth system processes and the nature of biotic response to environmental change across both space and time. Linking publications to specimens will enrich the potential of museum collections and augment their value for both research and education. The ePANDDA project also provides an opportunity to build collaborative programs that leverage existing education and outreach activities in addition to the primary research goals."
"1540929","EarthCube IA: Collaborative Proposal: Enhancing Paleontological and Neontological Data Discovery API","ICER","EarthCube","09/01/2015","07/30/2015","Mark Uhen","VA","George Mason University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$115,394.00","","muhen@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","GEO","8074","7433","$0.00","Understanding future environmental change requires researchers to access and integrate data from the geological and biological sciences, in order to answer questions about how environmental change will affect life on Earth. In many cases the data needed to answer these questions already exists but, unfortunately, technology has not kept pace with research needs. This places increasing demands on researchers, who have to search for and download data from multiple separate online databases; compile published information from many different literature sources; and track down specimens housed in museum and other collections scattered around the world. The time needed to search and retrieve this information is enormous and, once found, the data often have to be standardized before they can be used. This project will tackle this problem by developing software tools to connect three established, well-supported, and critically important data sources: the Paleobiology Database (PBDB, paleontological, literature based), iDigPaleo (paleontological, specimen based) and iDigBio (neontological, specimen based). This project will allow users of any one of these databases to access and query the others at the same time, returning a much richer, combined set of data to the user. Connecting these resources will open up a whole host of research questions that are currently difficult to answer, even by multiple researchers working as a team. The development of this system will allow scientists to ask and answer new research questions affecting fields as diverse as biogeographic/niche modeling, systematics, functional morphology, evolutionary biology, ecology, climatology, conservation biology, oceanography, and petroleum geology. This project will fundamentally change the nature of the research questions that can be addressed by the scientific community.<br/><br/>The connectivity between modern and fossil, and specimen and literature-based resources does not currently exist. The digital infrastructure provided by the composite ePANDDA application programming interfaces (APIs) will streamline and normalize data acquisition, including retrieval from disparate data sources, and will facilitate coordination with future data initiatives. Rather than creating another portal for the aggregation of data, ePANDDA will unify results that normally would have required multiple searches on numerous platforms. For the researcher, this eliminates a significant barrier to data collection and processing. Researchers will now have the ability to collaborate across disciplinary boundaries to study earth system processes and the nature of biotic response to environmental change across both space and time. Linking publications to specimens will enrich the potential of museum collections and augment their value for both research and education. The ePANDDA project also provides an opportunity to build collaborative programs that leverage existing education and outreach activities in addition to the primary research goals."
"1251557","EarthCube GEO Domain Workshop Proposal: Envisioning a Digital Crust for Simulating Continental&#8208; Scale Subsurface Fluid Flow in Earth System Models","EAR","EarthCube","09/01/2012","02/03/2015","Jennifer Arrigo","MA","Consortium of Universities for the Advancement of Hydrologic Sci","Standard Grant","Thomas Torgersen","02/28/2015","$84,681.00","Norman Jones, Ying Fan Reinfelder","jarrigo@cuahsi.org","196 Boston Avenue","Medford","MA","021554255","3392215400","GEO","8074","7433","$0.00","In order to advance the understanding of the critical zone and deeper crust and to better couple the exchange of mass and energy between the surface and the subsurface, this project will hold 3-day workshop to develop a long?]term vision of a digital representation of the continental crust of N. America and design concepts for prototype data model(s). The digital catalog of crustal structure, composition and permeability (as well as parameters from which permeability could be inferred) define the mechanisms by which to integrate vast amounts of dcisparate data types and to construct a coherent, 3D picture of subsurface structure and material properties, so that we can begin to represent subsurface fluid flow in Earth system models and elucidate its critical controls in the evolution of the Earth system from the past to the present and the future.<br/><br/>Fluid circulation in the subsurface, from the critical zone to the deeper crust, plays an essential role in surface, near-surface, and crustal dynamics. In the critical zone (<50m), soil water is a ecologic filter and niche differentiator where energy is abundant, explaining patterns in plant distribution globally and locally; and shallow groundwater is a primary source for rivers, lakes and<br/>wetlands in dry seasons and regions, thereby sustaining and modifying land and aquatic ecosystems, influencing water quality, and buffering against droughts and temperature extremes. Deeper in the crust (<1km), the large sedimentary formations and fractured rocks hold the fresh?]water aquifers that support major societies in arid and semi-arid regions. In the deeper crust (>1km), fluid flow affects diagenesis, hydrocarbons, ore deposits, faulting, earthquakes, and geothermal fields and involves water, gas and hydrocarbon flow. What are the flow paths through the soils and rocks? How fast are the flows and how long are the residence times? And how will they respond to changes in climate and land surface drivers? The answers depend on a quantitative description of the subsurface flow fields, driven by the hydraulic gradient but strongly controlled by the permeability of the Earth?fs material. Creating a digital catalogue by which to reconstruct this poorly sampled region of the planet will enable multiple aspects of the Earth sciences to advance transformatively."
"1343802","EarthCube Building Blocks: A Broker Framework for Next Generation Geoscience (BCube)","ICER","EarthCube","09/15/2013","07/24/2015","Siri Jodha Khalsa","CO","University of Colorado at Boulder","Standard Grant","Eva E. Zanzerkia","08/31/2016","$1,529,918.00","Stefano Nativi, Ruth Duerr, Francoise Pearlman, Jay Pearlman","khalsa@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","GEO","8074","7433","$0.00","The grand challenges of geoscience require working across traditional disciplinary<br/>boundaries. Scientists are being called upon to find, access, and use diverse and voluminous<br/>data types that are described with semantics. The BCube project has put together a strong<br/>team of geoscientists, cyberinfrastructure experts and social scientists to address these<br/>interoperability challenges using a maturing Brokering Framework for discovery, access, semantics,<br/>web crawling, workflows and enhanced user services. The first three have been explored for<br/>geoscience and are mature enough to provide near term engagement of geoscientists in a test<br/>bed environment. Crawling, workflow and services will be developed during the project. The<br/>geoscientists, (including early career scientists) from the domains of hydrology, oceans, polar, <br/>weather, will compile community needs and assess broker capabilities in an increasing complex series of user scenarios.<br/>To address the cultural barriers, BCube includes social science and education in the project team. BCube engages five major<br/>repositories (DataOne, OOI, USGS, NCAR/RAL, NSIDC) to test and demonstrate interconnections<br/>with the Broker Framework, with extension to international repositories in the second year.<br/><br/>The broker discovery and access modules have two important and unique characteristics: a design<br/>that builds interoperability without putting a burden upon either users or providers and an<br/>interfaced web crawling capability to find new data, models and services. New capabilities<br/>also come as the Broker translates cyberinfrastructure research in areas such as semantics<br/>and workflow into a user-oriented capability for cross-discipline geoscience research. An<br/>agile development process will support rapid adaptations to changing user needs. Since not<br/>all needs can be anticipated, the Broker will also have APIs for scientists to write modules<br/>for their own applications. BCube will look at the cultural issues in cross-discipline research<br/>to improve acceptance and use of the broker. Both the technical and cultural broker attributes<br/>will be exercised through user scenarios that start with individual geoscience research issues<br/>and move to more complex cross-discipline research studies. This will develop reference cases<br/>for metrics, monitoring and validating progress as the Broker Framework evolves and matures.<br/><br/>To address the grand challenges facing society, geoscientists need a sustainable and evolvable<br/>cyberinfrastructure supporting cross-discipline research with powerful interoperability. Success<br/>in addressing the project?s six diverse domains will demonstrate this and engender advancements<br/>in the broader geosciences. The Broker module for web 2.0 will support use of crowd sourcing<br/>and citizen science. BCube?s education analyses and early career scientists will consider<br/>the best way to reach a new generation. Expansion to international data access will be demonstrated<br/>through collaboration with the BCube?s international repository partners and a special interest<br/>group of the international Research Data Alliance."
"1213026","III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments","IIS","INFO INTEGRATION & INFORMATICS, ICER","10/01/2012","01/25/2016","Naphtali Rishe","FL","Florida International University","Standard Grant","Maria Zemankova","09/30/2017","$1,331,000.00","Tao Li","rishen@cs.fiu.edu","11200 SW 8TH ST","Miami","FL","331990001","3053482494","CSE","7364, 7699","7925, 7433, 7364, 9251","$0.00","Researchers at Florida International University (IIS-1213026), University of Illinois at Chicago (IIS-1213013), Brown University (IIS-1212508), and Northwestern University (IIS-1213038) are developing a high-performance model for information processing and fusion in mobile environments, providing a collaborative integration between the real and virtual worlds. This model, applicable to the fields of computational transportation and mobile sensing, enables querying and visualization of moving objects data (MOD) and their relationship to static and dynamic geospatial data. Research project addresses the issues of: balancing the processing of location-based data streams coming into MOD servers with efficient processing of visualization-related queries; determining optimal distribution of queries/tasks among multiple regional servers; maximizing the scalability of prediction techniques in terms of efficient management of objects' data and queries; modeling data uncertainty; coupling map generalization with trajectories' data reduction when zooming across different scales; resolving issues of privacy and security; and enabling semantic querying. A demonstration of the outcomes is available within the TerraFly testbed (http://TerraFly.fiu.edu) -- a public Geographic Information System (GIS) mapping engine and location-based data repository.<br/><br/>This work explores the novel steps towards combining the real and virtual worlds, an emerging research frontier. The virtual world is relatively well understood, but the combination of the real and virtual poses great challenges and promises transformative results with high potential payoff, including in-car navigation systems, massive fleets of mobile sensors, self-navigating vehicles, situation command, and location-based services. While advancing Computer Science, the project also leverages prior investment of, and provides direct benefit to, NSF, NASA, DoI, DoT, DHS, and other stakeholders such as the NSF EarthCube project. By improving the efficiency of spatial, temporal, and moving object data management and making these results available to constituencies via TerraFly, EarthCube and other venues, the project will produce societal benefits. This project provides a foundation for improving the quality of services in multiple applications such as disaster management, environmental monitoring, transportation, education, and logistics. The resulting technologies may serve as a base to advance research on self-navigating vehicles, robots, and mobile sensors. In particular, this work facilitates the technologies of Informed Traveler Programs, dynamic navigation, situation control, and airborne observational systems. The project provides rich educational and research opportunities for students from the collaborating institutions -- including underrepresented students. In addition, educational modules are developed, and research results will be incorporated in curriculum expansions. Further information is available at the project's website (http://CAKE.fiu.edu/MOD)."
"1332257","Integrated Data Management System for Critical Zone Observatories","EAR","GLOBAL CHANGE, GEOBIOLOGY & LOW TEMP GEOCHEM, CZO: CRITICAL ZONE OBSER SOLIC","12/01/2012","05/02/2014","Anthony Aufdenkampe","PA","Stroud Water Research Center","Standard Grant","Paul E Filmer","03/31/2016","$1,532,537.00","","aufdenkampe@stroudcenter.org","970 Spencer Road","Avondale","PA","193119514","6102682153","GEO","1577, 7295, 7693","7693","$0.00","The objective of the project is to develop a comprehensive, integrated data management system for the NSF-funded Critical Zone Observatory (CZO) program, called CZOData. The overall goal for CZOData is to support, empower, and broaden the impact of CZO science and maximize the return on investment of the CZO program by transforming capabilities to easily share, integrate, analyze and preserve the wide range of multi-disciplinary data generated within and across CZOs. <br/><br/>The CZOData design is based on the experience of the collaborative project team in building the current CZOData prototype and on other foundational cyber-infrastructure systems. The principal investigators at the University of Boulder and the Stroud Water Research Center are Earth surface scientists who provided high-level oversight of the CZOData prototype and provide a direct link to the scientific community collecting and using CZO data. Team members at San Diego Supercomputing Center (SDSC) and Utah State University (USU) are primary developers of the Hydrological Information System (HIS) developed by the Consortium for the Advancement of Hydrological Sciences, Inc. (CUAHSI). Team members at Columbia University developed and lead the Integrated Earth Data Applications (IEDA), Geoinformatics for Geochemistry (GfG), EarthChem and the System for Earth Sample Registration (SESAR) projects. Team members at the Applied Physics Laboratory at the University of Washington developed and maintain the Northwest Association for Ocean Observing Systems (NANOOS) Visualization System (NVS). <br/><br/>This project combines state-of-the-art computer science and cyber-infrastructure technologies and international metadata standards with a strong effort to engage the science community in the process of developing and testing the CZOData system. This collaborative, community-based approach to developing scientific cyber-infrastructure has been actively encouraged by the NSF-supported EarthCube initiative and thus complements those goals (http://www.nsf.gov/geo/earthcube/). The approach with CZOData is based on integrating site-based data with system capabilities' such as consistent data publication, cataloguing, discovery and access infrastructure. These new capabilities will strongly leverage other CI efforts described above. The resulting system will support new CZO research that was not possible before while easing the data management burden on CZO scientists.<br/><br/>The vision is that the proposed CZOData will serve as a model for the greater Earth surface science community. The CZOData project is a collaborative, community-guided cyber-infrastructure project for integrating multi-disciplinary data and providing interoperability with other systems. Thus, CZOData will inform the development of other large geoinformatics initiatives, such a the Open Geospatial Consortium (OGC), Long-Term Environmental Research (LTER) observatories, DataOne, OpenTopography, the Implementing Organization of the International Geosample Number (IGSN e.v.), and the Integrated Ocean Observing System (IOOS). Also, by incorporating system research and development with graduate education, we will move towards cultivating a new generation of researchers skilled in both different facets of environmental research and in advanced information management and computing."
"1213013","III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","09/18/2012","Ouri Wolfson","IL","University of Illinois at Chicago","Standard Grant","Maria Zemankova","09/30/2017","$1,166,599.00","Maria Cruz, Bo Xu","wolfson@cs.uic.edu","809 S MARSHFIELD","Chicago","IL","606124305","3129962862","CSE","7364","7925","$0.00","Researchers at Florida International University (IIS-1213026), University of Illinois at Chicago (IIS-1213013), Brown University (IIS-1212508), and Northwestern University (IIS-1213038) are developing a high-performance model for information processing and fusion in mobile environments, providing a collaborative integration between the real and virtual worlds. This model, applicable to the fields of computational transportation and mobile sensing, enables querying and visualization of moving objects data (MOD) and their relationship to static and dynamic geospatial data. Research project addresses the issues of: balancing the processing of location-based data streams coming into MOD servers with efficient processing of visualization-related queries; determining optimal distribution of queries/tasks among multiple regional servers; maximizing the scalability of prediction techniques in terms of efficient management of objects' data and queries; modeling data uncertainty; coupling map generalization with trajectories' data reduction when zooming across different scales; resolving issues of privacy and security; and enabling semantic querying. A demonstration of the outcomes is available within the TerraFly testbed (http://TerraFly.fiu.edu) -- a public Geographic Information System (GIS) mapping engine and location-based data repository.<br/><br/>This work explores the novel steps towards combining the real and virtual worlds, an emerging research frontier. The virtual world is relatively well understood, but the combination of the real and virtual poses great challenges and promises transformative results with high potential payoff, including in-car navigation systems, massive fleets of mobile sensors, self-navigating vehicles, situation command, and location-based services. While advancing Computer Science, the project also leverages prior investment of, and provides direct benefit to, NSF, NASA, DoI, DoT, DHS, and other stakeholders such as the NSF EarthCube project. By improving the efficiency of spatial, temporal, and moving object data management and making these results available to constituencies via TerraFly, EarthCube and other venues, the project will produce societal benefits. This project provides a foundation for improving the quality of services in multiple applications such as disaster management, environmental monitoring, transportation, education, and logistics. The resulting technologies may serve as a base to advance research on self-navigating vehicles, robots, and mobile sensors. In particular, this work facilitates the technologies of Informed Traveler Programs, dynamic navigation, situation control, and airborne observational systems. The project provides rich educational and research opportunities for students from the collaborating institutions -- including underrepresented students. In addition, educational modules are developed, and research results will be incorporated in curriculum expansions. Further information is available at the project's website (http://CAKE.fiu.edu/MOD)."
"1212508","III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","09/18/2012","Roberto Tamassia","RI","Brown University","Standard Grant","Maria Zemankova","09/30/2017","$250,000.00","","rt@cs.brown.edu","BOX 1929","Providence","RI","029129002","4018632777","CSE","7364","7925, 9150","$0.00","Researchers at Florida International University (IIS-1213026), University of Illinois at Chicago (IIS-1213013), Brown University (IIS-1212508), and Northwestern University (IIS-1213038) are developing a high-performance model for information processing and fusion in mobile environments, providing a collaborative integration between the real and virtual worlds. This model, applicable to the fields of computational transportation and mobile sensing, enables querying and visualization of moving objects data (MOD) and their relationship to static and dynamic geospatial data. Research project addresses the issues of: balancing the processing of location-based data streams coming into MOD servers with efficient processing of visualization-related queries; determining optimal distribution of queries/tasks among multiple regional servers; maximizing the scalability of prediction techniques in terms of efficient management of objects' data and queries; modeling data uncertainty; coupling map generalization with trajectories' data reduction when zooming across different scales; resolving issues of privacy and security; and enabling semantic querying. A demonstration of the outcomes is available within the TerraFly testbed (http://TerraFly.fiu.edu) -- a public Geographic Information System (GIS) mapping engine and location-based data repository.<br/><br/>This work explores the novel steps towards combining the real and virtual worlds, an emerging research frontier. The virtual world is relatively well understood, but the combination of the real and virtual poses great challenges and promises transformative results with high potential payoff, including in-car navigation systems, massive fleets of mobile sensors, self-navigating vehicles, situation command, and location-based services. While advancing Computer Science, the project also leverages prior investment of, and provides direct benefit to, NSF, NASA, DoI, DoT, DHS, and other stakeholders such as the NSF EarthCube project. By improving the efficiency of spatial, temporal, and moving object data management and making these results available to constituencies via TerraFly, EarthCube and other venues, the project will produce societal benefits. This project provides a foundation for improving the quality of services in multiple applications such as disaster management, environmental monitoring, transportation, education, and logistics. The resulting technologies may serve as a base to advance research on self-navigating vehicles, robots, and mobile sensors. In particular, this work facilitates the technologies of Informed Traveler Programs, dynamic navigation, situation control, and airborne observational systems. The project provides rich educational and research opportunities for students from the collaborating institutions -- including underrepresented students. In addition, educational modules are developed, and research results will be incorporated in curriculum expansions. Further information is available at the project's website (http://CAKE.fiu.edu/MOD)."
"1213038","III: Large: Collaborative Research: Moving Objects Databases for Exploration of Virtual and Real Environments","IIS","INFO INTEGRATION & INFORMATICS","10/01/2012","09/18/2012","Goce Trajcevski","IL","Northwestern University","Standard Grant","Maria Zemankova","09/30/2017","$300,000.00","","goce@eecs.northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7364","7925","$0.00","Researchers at Florida International University (IIS-1213026), University of Illinois at Chicago (IIS-1213013), Brown University (IIS-1212508), and Northwestern University (IIS-1213038) are developing a high-performance model for information processing and fusion in mobile environments, providing a collaborative integration between the real and virtual worlds. This model, applicable to the fields of computational transportation and mobile sensing, enables querying and visualization of moving objects data (MOD) and their relationship to static and dynamic geospatial data. Research project addresses the issues of: balancing the processing of location-based data streams coming into MOD servers with efficient processing of visualization-related queries; determining optimal distribution of queries/tasks among multiple regional servers; maximizing the scalability of prediction techniques in terms of efficient management of objects' data and queries; modeling data uncertainty; coupling map generalization with trajectories' data reduction when zooming across different scales; resolving issues of privacy and security; and enabling semantic querying. A demonstration of the outcomes is available within the TerraFly testbed (http://TerraFly.fiu.edu) -- a public Geographic Information System (GIS) mapping engine and location-based data repository.<br/><br/>This work explores the novel steps towards combining the real and virtual worlds, an emerging research frontier. The virtual world is relatively well understood, but the combination of the real and virtual poses great challenges and promises transformative results with high potential payoff, including in-car navigation systems, massive fleets of mobile sensors, self-navigating vehicles, situation command, and location-based services. While advancing Computer Science, the project also leverages prior investment of, and provides direct benefit to, NSF, NASA, DoI, DoT, DHS, and other stakeholders such as the NSF EarthCube project. By improving the efficiency of spatial, temporal, and moving object data management and making these results available to constituencies via TerraFly, EarthCube and other venues, the project will produce societal benefits. This project provides a foundation for improving the quality of services in multiple applications such as disaster management, environmental monitoring, transportation, education, and logistics. The resulting technologies may serve as a base to advance research on self-navigating vehicles, robots, and mobile sensors. In particular, this work facilitates the technologies of Informed Traveler Programs, dynamic navigation, situation control, and airborne observational systems. The project provides rich educational and research opportunities for students from the collaborating institutions -- including underrepresented students. In addition, educational modules are developed, and research results will be incorporated in curriculum expansions. Further information is available at the project's website (http://CAKE.fiu.edu/MOD)."
"1153164","Integrated Data Management System for Critical Zone Observatories","EAR","GLOBAL CHANGE, GEOBIOLOGY & LOW TEMP GEOCHEM, CZO: CRITICAL ZONE OBSER SOLIC","04/15/2012","11/06/2012","Anthony Aufdenkampe","CO","University of Colorado at Boulder","Standard Grant","Enriqueta Barrera","04/30/2013","$1,503,590.00","Anthony Aufdenkampe","aufdenkampe@stroudcenter.org","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","GEO","1577, 7295, 7693","","$0.00","The objective of the project is to develop a comprehensive, integrated data management system for the NSF-funded Critical Zone Observatory (CZO) program, called CZOData. The overall goal for CZOData is to support, empower, and broaden the impact of CZO science and maximize the return on investment of the CZO program by transforming capabilities to easily share, integrate, analyze and preserve the wide range of multi-disciplinary data generated within and across CZOs. <br/><br/>The CZOData design is based on the experience of the collaborative project team in building the current CZOData prototype and on other foundational cyber-infrastructure systems. The principal investigators at the University of Boulder and the Stroud Water Research Center are Earth surface scientists who provided high-level oversight of the CZOData prototype and provide a direct link to the scientific community collecting and using CZO data. Team members at San Diego Supercomputing Center (SDSC) and Utah State University (USU) are primary developers of the Hydrological Information System (HIS) developed by the Consortium for the Advancement of Hydrological Sciences, Inc. (CUAHSI). Team members at Columbia University developed and lead the Integrated Earth Data Applications (IEDA), Geoinformatics for Geochemistry (GfG), EarthChem and the System for Earth Sample Registration (SESAR) projects. Team members at the Applied Physics Laboratory at the University of Washington developed and maintain the Northwest Association for Ocean Observing Systems (NANOOS) Visualization System (NVS). <br/><br/>This project combines state-of-the-art computer science and cyber-infrastructure technologies and international metadata standards with a strong effort to engage the science community in the process of developing and testing the CZOData system. This collaborative, community-based approach to developing scientific cyber-infrastructure has been actively encouraged by the NSF-supported EarthCube initiative and thus complements those goals (http://www.nsf.gov/geo/earthcube/). The approach with CZOData is based on integrating site-based data with system capabilities' such as consistent data publication, cataloguing, discovery and access infrastructure. These new capabilities will strongly leverage other CI efforts described above. The resulting system will support new CZO research that was not possible before while easing the data management burden on CZO scientists.<br/><br/>The vision is that the proposed CZOData will serve as a model for the greater Earth surface science community. The CZOData project is a collaborative, community-guided cyber-infrastructure project for integrating multi-disciplinary data and providing interoperability with other systems. Thus, CZOData will inform the development of other large geoinformatics initiatives, such a the Open Geospatial Consortium (OGC), Long-Term Environmental Research (LTER) observatories, DataOne, OpenTopography, the Implementing Organization of the International Geosample Number (IGSN e.v.), and the Integrated Ocean Observing System (IOOS). Also, by incorporating system research and development with graduate education, we will move towards cultivating a new generation of researchers skilled in both different facets of environmental research and in advanced information management and computing."
"1239848","EAGER: Collaborative Research: Developing a Community Computational Infrastructure for Earth System Model Research and Applications","EAR","EarthCube","04/01/2012","03/27/2012","James Famiglietti","CA","University of California-Irvine","Standard Grant","Barbara L. Ransom","03/31/2013","$63,813.00","","jfamigli@uci.edu","141 Innovation Drive, Ste 250","Irvine","CA","926173213","9498247295","GEO","8074","7433, 7916","$0.00","This EAGER award focuses on exploring the feasibility of the implementation of a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube. Led by a team of expert Earth system modelers, this project focuses on developing new approaches for integrating and coupling model components so that holistic geoscience scenarios that involve the interaction of large scale climate and atmospheric circulation models and smaller, more heterogeneous component models of surface earth processes can be explored and more effectively used by a broader range of users. The project engages participants from a number of major NSF-funded geoscience modeling investments (CSDMS, NCAR, CUHAUSI). A main goal of the of the work is to bridge the gaps between present modeling frameworks, data standards, and computational architectures. The approach includes collection of all relevant approaches and then comparing their pros and cons and linking existing different ""plug and play"" modeling components together and assessing the accuracy and robustness of model results. Major project goals are to see if more standard modeling protocols can be developed and to develop a general roadmap for improving the interoperability and meshing of model components that address phenomena at wildly different spatial and temporal scales. Broader impacts of the work include building new modeling infrastructure for science and leveraging prior NSF investments in cyberinfrastructure. It also improves the utility of, ease of use, and broader access of scientists and other potential users to more fully integrated and powerful earth systems models."
"1339765","SI2-SSI: Collaborative Research: Building Sustainable Tools and Collaboration for Volcanic and Related Hazards","ACI","DEEP EARTH PROCESSES SECTION, Software Institutes, EarthCube, Front in Earth Sys Dynamics, PETROLOGY AND GEOCHEMISTRY","10/01/2013","09/15/2016","Matthew Jones","NY","SUNY at Buffalo","Continuing grant","Rajiv Ramnath","09/30/2018","$1,366,491.00","Marcus Bursik, Abani Patra, Matthew Jones, Greg Valentine, Tevfik Kosar","jonesm@ccr.buffalo.edu","520 Lee Entrance","Amherst","NY","142282567","7166452634","CSE","7571, 8004, 8074, 8016, 1573","7433, 8009, 019Z, 9102, 9179","$0.00","This project is focused on creating and upgrading software infrastructure for a large community of scientists engaged in volcanology research and associated hazard analysis. Specifically, the project will reengineer three widely used tools (TITAN2D - block and ash flows, TEPHRA and Puff - ash transport and dispersal) and develop support for workflows that use these tools to analyze risk from volcanic hazards. Reengineering will encompass modularization so researchers may easily experiment with different modeling approaches, incorporation of techniques to make the tools efficient on new computing architectures like GPUs and many-core chips. The workflows are intended to tackle the challenges of managing complex and often large data flows associated with these tools in validation processes and in probabilistic inference based on the outcomes of the modeling. The tools and workflows will be made available using the popular vhub.org platform. This project will help provide a standard well managed hardware/software platform and approaches to standardize the documentation associated with input data, source code, and output data. This will ensure that model calculations are reproducible.<br/><br/>The wider use of these high fidelity tools and their use in mitigating hazards is likely to have a significant effect on hazard analysis and management. The project will also engage in several major workshops and in training activities. Project personnel will also engage in the Earthcube initiative - popularizing computational methodologies, online access and dissemination mechanisms through the VHub platform."
"1450488","Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities","ACI","PHYSICAL & DYNAMIC METEOROLOGY, Software Institutes, EarthCube","08/01/2015","06/14/2016","Carl Maltzahn","CA","University of California-Santa Cruz","Standard Grant","Rajiv Ramnath","07/31/2018","$695,525.00","","carlosm@ucsc.edu","1156 High Street","Santa Cruz","CA","950641077","8314595278","CSE","1525, 8004, 8074","7433, 8009","$0.00","Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.<br/><br/>The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities."
"1450170","Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities","ACI","PHYSICAL & DYNAMIC METEOROLOGY, Software Institutes, EarthCube","08/01/2015","08/04/2015","William Capehart","SD","South Dakota School of Mines and Technology","Standard Grant","Rajiv Ramnath","07/31/2018","$183,956.00","","William.Capehart@sdsmt.edu","501 East Saint Joseph Street","Rapid City","SD","577013995","6053941218","CSE","1525, 8004, 8074","4444, 7433, 8009, 9150","$0.00","Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.<br/><br/>The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities."
"1450168","Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities","ACI","PHYSICAL & DYNAMIC METEOROLOGY, Software Institutes, EarthCube","08/01/2015","08/04/2015","Gretchen Mullendore","ND","University of North Dakota Main Campus","Standard Grant","Rajiv Ramnath","07/31/2018","$168,182.00","","gretchen@atmos.und.edu","University Station","Grand Forks","ND","582026059","7017774278","CSE","1525, 8004, 8074","4444, 7433, 8009, 9150","$0.00","Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.<br/><br/>The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities."
"1450089","Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities","ACI","PHYSICAL & DYNAMIC METEOROLOGY, Software Institutes, EarthCube","08/01/2015","08/04/2015","Russ Schumacher","CO","Colorado State University","Standard Grant","Rajiv Ramnath","07/31/2018","$177,173.00","","russ.schumacher@colostate.edu","601 S Howes St","Fort Collins","CO","805232002","9704916355","CSE","1525, 8004, 8074","4444, 7433, 8009","$0.00","Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.<br/><br/>The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities."
"1339768","SI2-SSI: Collaborative Research: Building Sustainable Tools and Collaboration for Volcanic and Related Hazards","ACI","Software Institutes, EarthCube","10/01/2013","09/16/2013","Charles Connor","FL","University of South Florida","Standard Grant","Rajiv Ramnath","09/30/2017","$194,869.00","","cbconnor@usf.edu","3702 Spectrum Blvd.","Tampa","FL","336129446","8139742897","CSE","8004, 8074","7433, 8009","$0.00","This project is focused on creating and upgrading software infrastructure for a large community of scientists engaged in volcanology research and associated hazard analysis. Specifically, the project will reengineer three widely used tools (TITAN2D - block and ash flows, TEPHRA and Puff - ash transport and dispersal) and develop support for workflows that use these tools to analyze risk from volcanic hazards. Reengineering will encompass modularization so researchers may easily experiment with different modeling approaches, incorporation of techniques to make the tools efficient on new computing architectures like GPUs and many-core chips. The workflows are intended to tackle the challenges of managing complex and often large data flows associated with these tools in validation processes and in probabilistic inference based on the outcomes of the modeling. The tools and workflows will be made available using the popular vhub.org platform. This project will help provide a standard well managed hardware/software platform and approaches to standardize the documentation associated with input data, source code, and output data. This will ensure that model calculations are reproducible.<br/><br/>The wider use of these high fidelity tools and their use in mitigating hazards is likely to have a significant effect on hazard analysis and management. The project will also engage in several major workshops and in training activities. Project personnel will also engage in the Earthcube initiative - popularizing computational methodologies, online access and dissemination mechanisms through the VHub platform."
"1450195","Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities","ACI","PHYSICAL & DYNAMIC METEOROLOGY, Software Institutes, EarthCube","08/01/2015","08/04/2015","Robert Fovell","NY","SUNY at Albany","Standard Grant","Rajiv Ramnath","07/31/2018","$246,111.00","","rfovell@albany.edu","1400 WASHINGTON AVE","Albany","NY","122220100","5184374550","CSE","1525, 8004, 8074","4444, 7433, 8009","$0.00","Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.<br/><br/>The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities."
"1239703","EAGER: Collaborative Research: Developing a Community Computational Infrastructure for Earth System Model Research and Applications","EAR","EarthCube","04/01/2012","03/27/2012","Jennifer Arrigo","MA","Consortium of Universities for the Advancement of Hydrologic Sci","Standard Grant","Barbara L. Ransom","12/31/2013","$27,636.00","","jarrigo@cuahsi.org","196 Boston Avenue","Medford","MA","021554255","3392215400","GEO","8074","7433, 7916","$0.00","This EAGER award focuses on exploring the feasibility of the implementation of a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube. Led by a team of expert Earth system modelers, this project focuses on developing new approaches for integrating and coupling model components so that holistic geoscience scenarios that involve the interaction of large scale climate and atmospheric circulation models and smaller, more heterogeneous component models of surface earth processes can be explored and more effectively used by a broader range of users. The project engages participants from a number of major NSF-funded geoscience modeling investments (CSDMS, NCAR, CUHAUSI). A main goal of the of the work is to bridge the gaps between present modeling frameworks, data standards, and computational architectures. The approach includes collection of all relevant approaches and then comparing their pros and cons and linking existing different ""plug and play"" modeling components together and assessing the accuracy and robustness of model results. Major project goals are to see if more standard modeling protocols can be developed and to develop a general roadmap for improving the interoperability and meshing of model components that address phenomena at wildly different spatial and temporal scales. Broader impacts of the work include building new modeling infrastructure for science and leveraging prior NSF investments in cyberinfrastructure. It also improves the utility of, ease of use, and broader access of scientists and other potential users to more fully integrated and powerful earth systems models."
"1239603","EAGER: Collaborative Research: Interoperability Testbed ? Assessing a Layered Architecture for Integration of Existing Capabilities","EAR","EarthCube","04/01/2012","08/07/2012","Yong Liu","IL","University of Illinois at Urbana-Champaign","Standard Grant","Barbara L. Ransom","03/31/2013","$18,000.00","","yongliu@ncsa.illinois.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","GEO","8074","7433, 7916","$0.00","ABSTRACT <br/>This EAGER award creates an interoperability test bed to identify the components of an effective layered architecture for geoscience and environmental science research. In a layered architecture, every layer consists of different technologies, each of which uses different interaction protocols. The proposed project will examine a wide variety of existing technologies in terms of their effectiveness in working across present data silos. These technologies include data grids, workflow systems, policy management systems, web visualization services, and security protocols that work with various repository catalogs. Project goals are focused on developing cyberinfrastructure tools and approaches that allow geoscience data repositories to enable new science and more effectively make their data holdings discoverable and available to the public. Essential elements of the project include the collection and comparision of various approaches and existing tools to check effectiveness in handling and integrating geoscience data, and by automating processes needed to integrate various databases and data types. The project is led by a team of experts in cyberinfrastructure and geoscience data management and employs a spiral softwar3ee development approach. Broader impacts of the work include building infrastructure for science in order to facilitate data-enabled science in the geosciences. It will also produce results that are likely to be applicable to fields outside of the geosciences. The effort supports a larger NSF effort to establish a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube."
"1239632","EAGER: Collaborative Research: Interoperability Testbed-Assessing a Layered Architecture for Integration of Existing Capabilities","EAR","EarthCube","04/01/2012","03/28/2012","Jeffery Horsburgh","UT","Utah State University","Standard Grant","Barbara L. Ransom","03/31/2013","$18,000.00","","jeff.horsburgh@usu.edu","Sponsored Programs Office","Logan","UT","843221415","4357971226","GEO","8074","7433, 7916, 9150","$0.00","ABSTRACT <br/>This EAGER award creates an interoperability test bed to identify the components of an effective layered architecture for geoscience and environmental science research. In a layered architecture, every layer consists of different technologies, each of which uses different interaction protocols. The proposed project will examine a wide variety of existing technologies in terms of their effectiveness in working across present data silos. These technologies include data grids, workflow systems, policy management systems, web visualization services, and security protocols that work with various repository catalogs. Project goals are focused on developing cyberinfrastructure tools and approaches that allow geoscience data repositories to enable new science and more effectively make their data holdings discoverable and available to the public. Essential elements of the project include the collection and comparision of various approaches and existing tools to check effectiveness in handling and integrating geoscience data, and by automating processes needed to integrate various databases and data types. The project is led by a team of experts in cyberinfrastructure and geoscience data management and employs a spiral softwar3ee development approach. Broader impacts of the work include building infrastructure for science in order to facilitate data-enabled science in the geosciences. It will also produce results that are likely to be applicable to fields outside of the geosciences. The effort supports a larger NSF effort to establish a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube."
"1239746","EAGER: Collaborative Research: Developing a Community Computational Infrastructure for Earth System Model Research and Applications","EAR","EarthCube","04/01/2012","03/27/2012","David Gochis","CO","University Corporation For Atmospheric Res","Standard Grant","Barbara L. Ransom","03/31/2014","$50,000.00","","gochis@ucar.edu","3090 Center Green Drive","Boulder","CO","803012252","3034971000","GEO","8074","7433, 7916","$0.00","This EAGER award focuses on exploring the feasibility of the implementation of a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube. Led by a team of expert Earth system modelers, this project focuses on developing new approaches for integrating and coupling model components so that holistic geoscience scenarios that involve the interaction of large scale climate and atmospheric circulation models and smaller, more heterogeneous component models of surface earth processes can be explored and more effectively used by a broader range of users. The project engages participants from a number of major NSF-funded geoscience modeling investments (CSDMS, NCAR, CUHAUSI). A main goal of the of the work is to bridge the gaps between present modeling frameworks, data standards, and computational architectures. The approach includes collection of all relevant approaches and then comparing their pros and cons and linking existing different ""plug and play"" modeling components together and assessing the accuracy and robustness of model results. Major project goals are to see if more standard modeling protocols can be developed and to develop a general roadmap for improving the interoperability and meshing of model components that address phenomena at wildly different spatial and temporal scales. Broader impacts of the work include building new modeling infrastructure for science and leveraging prior NSF investments in cyberinfrastructure. It also improves the utility of, ease of use, and broader access of scientists and other potential users to more fully integrated and powerful earth systems models."
"1340265","EC3 - Earth-Centered Communication for Cyberinfrastructure: Challenges of field data collection, management, and integration","ICER","EarthCube","09/15/2013","08/26/2013","Matty Mookerjee","CA","Sonoma State University","Standard Grant","Eva E. Zanzerkia","08/31/2016","$299,329.00","Thomas Shipley, Basil Tikoff, Amy Ellwein, James Bowring","matty.mookerjee@sonoma.edu","1801 East Cotati Avenue","Rohnert Park","CA","949283609","7076644423","GEO","8074","7433","$0.00","Scientists who work in the field have a common set of issues when it comes to documenting,storing, and representing data. Members from the different geological communities would benefitgreatly from the opportunity to discuss the types of data that they collect in the field with a group of cyberinfrastructure and software development professionals and researchers. By holding meetings in the field, the computer scientists will gain a better appreciation for the types of data that are typically collected in the field, common methods for collecting those data, the field tools/technology that are employed, data recording conventions, and the types of question typically addressed with these data. ""The field"" is an ideal location for appreciating geological concepts, and the very act of being in the field, together with other professionals, often foster personal connections that promote successful collaborations<br/>and the exchange of ideas. <br/><br/>Work on this RCN will facilitate digitization of geological field data. The researchers will take steps to: 1) Document what exists currently for field data collection; 2) Assemble a community for discussing and exploring field data collection issues, specifically targeting young investigators; 3) Motivate distinct communities to work together on common issues associated with digitization; 4) Evaluate what is missing in the creation of open and accessible data. The objective of the RCN Proposal is to develop communication between cyberinfrastructure community and those involved in field-based, solid earth geoscience. In order to facilitate knowledge of the activities, they will conduct a series of both informal and formal meetings as national meetings - workshops at GSA and townhall meetings at AGU and AAPG). The goal of the initial meetings will be to: 1) foster community awareness of EarthCube-related activities, 2) discover and catalog the additional existing resources, 3) determine ways of giving publication ?credit? for recording and sharing digital data, 4) identify attributes of a clearinghouse website that would be most useful, and 5) find ways of motivating the community to move quickly toward digital data collection/conversion and data sharing."
"1450439","Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities","ACI","PHYSICAL & DYNAMIC METEOROLOGY, Software Institutes, EarthCube","08/01/2015","08/04/2015","Allen Evans","WI","University of Wisconsin-Milwaukee","Standard Grant","Rajiv Ramnath","07/31/2018","$164,381.00","","evans36@uwm.edu","P O BOX 340","Milwaukee","WI","532010340","4142294853","CSE","1525, 8004, 8074","4444, 7433, 8009","$0.00","Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.<br/><br/>The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities."
"1339834","Collaborative Research: SI2-SSI: The Community-Driven BiG CZ Software System for Integration and Analysis of Bio- and Geoscience Data in the Critical Zone","ACI","GEOBIOLOGY & LOW TEMP GEOCHEM, EAR, ECOSYSTEM STUDIES, EarthCube, Software Institutes, CZO: CRITICAL ZONE OBSER SOLIC","12/01/2013","09/20/2013","Anthony Aufdenkampe","PA","Stroud Water Research Center","Standard Grant","Rajiv Ramnath","11/30/2017","$1,366,089.00","Kerstin Lehnert, Jeffery Horsburgh, Robert Cheetham, Emilio Mayorga","aufdenkampe@stroudcenter.org","970 Spencer Road","Avondale","PA","193119514","6102682153","CSE","7295, 6898, 1181, 8074, 8004, 7693","7433, 8009","$0.00","The Critical Zone (CZ) science community takes as its charge the effort to integrate theory, models and data from the multitude of disciplines collectively studying processes on the Earth's surface. The Critical Zone is Earth's permeable near-surface layer - from the atmosphere at the vegetation's canopy to the lower boundary of actively circulating groundwaters. The Critical Zone was a term coined by the National Research Council's Basic Research Opportunities in the Earth Sciences (BROES) Report (2001) to highlight the imperative for a new approach to thoroughly multi-disciplinary research on the zone of the Earth?s surface that is critical to sustaining terrestrial life on our planet. In January 2013, 103 members of the CZ community met for the CZ-EarthCube Domain Workshop (NSF Award #1252238) to prioritize the CZ community's key science drivers, key computational and information technology (""cyber"") challenges and key cyber needs. They identified that the central scientific challenge of the critical zone science community is to develop a ""grand unifying theory"" of the critical zone through a theory-model-data fusion approach. Work participants unanimously described that the key missing need of this approach was a future cyberinfrastructure for seamless 4D visual exploration of the integrated knowledge (data, model outputs and interpolations) from all the bio and geoscience disciplines relevant to critical zone structure and function, similar to today?s ability to easily explore historical satellite imagery and photographs of the earth's surface using Google Earth. This project takes the first ""BiG"" steps toward answering that need.<br/><br/>The overall goal of this project is to co-develop with the CZ science and broader community, including natural resource managers and stakeholders, a web-based integration and visualization environment for joint analysis of cross-scale bio and geoscience processes in the critical zone (BiG CZ), spanning experimental and observational designs. Our Project Objectives are to: (1) Engage the CZ and broader community to co-develop and deploy the BiG CZ software stack; (2) Develop the BiG CZ Portal web application for intuitive, high-performance map-based discovery, visualization, access and publication of data by scientists, resource managers, educators and the general public; (3) Develop the BiG CZ Toolbox to enable cyber-savvy CZ scientists to access BiG CZ Application Programming Interfaces (APIs); and (4) Develop the BiG CZ Central software stack to bridge data systems developed for multiple critical zone domains into a single metadata catalog. The entire BiG CZ Software system will be developed on public repositories as a modular suite of fully open source software projects. It will be built around a new Observations Data Model Version 2.0 (ODM2) that is being developed by members of the BiG CZ project team, with community input, under separate funding (NSF Award #1224638)."
"1449668","EAGER: Repository Cross-Linking for Open Archiving and Sharing of Scientific Data and Articles","ICER","NSF Public Access Initiative, EarthCube","12/01/2014","07/09/2014","Matthew Mayernik","CO","University Corporation For Atmospheric Res","Standard Grant","Eva E. Zanzerkia","02/29/2016","$72,553.00","Don Middleton","mayernik@ucar.edu","3090 Center Green Drive","Boulder","CO","803012252","3034971000","GEO","7414, 8074","7433, 7916","$0.00","The open availability and wide accessibility of scientific articles, data sets, and other digital resources is becoming the norm for 21st century science. Growing numbers of repositories of scientific resources enable researchers to discover, understand, and build upon previous work at greater scales than was previously possible. Many interrelationships exist between research articles, data, software, and other services used to produce scientific findings. Repositories for these resources, however, typically only supporting one particular kind of resource, or at most will support a couple of resource types, such as data and software. This has led to the siloing of information in a vast number of repositories. Producers and users of scientific resources would benefit from repositories with different specializations and user communities working together at a technical and process level to provide greater services than any one repository can provide. Through developing common workflows and information exchange protocols, this project will demonstrate how repository interconnections can be built in ways that establish connections between related resources (e.g. data, software, services, etc.). <br/><br/>This project will provide a model for how multiple repositories of diverse resources can exchange<br/>and connect related information via complementary workflows and metadata sharing. The project<br/>will consider two different cases: 1) connecting resources that are already hosted by repositories,<br/>and 2) connecting resources as they are newly deposited into repositories. These are common<br/>cases among data, articles, and software repositories. Case #1 looks backward in time, and<br/>case #2 looks forward in time. This project will produce a pilot implementation of repository cross-linking, using two repositories provided and managed by the University Corporation for Atmospheric Research (UCAR) / National Center for Atmospheric Research (NCAR) as the development bed: 1) the OpenSky repository, which hosts and provides access to the record of scholarship produced by UCAR and NCAR staff, and is the platform for publishing the NCAR Technical Notes series, and 2) is the Earth System Grid (ESG), which is a NCAR-hosted infrastructure for the distribution and access of climate models, data, and software. Building connections between repositories increases public access to geosciences information and data by increasing the visibility of data and information across previously unconnected systems, thereby increasing discoverability, and by increasing the utility of data through explicitly linking data to important documentation. Theproject outcomes will be shared and explored with the relevant stakeholders communities through a workshop, and with the communities brought together through EarthCube, namely, the geosciences, informatics experts, scientific publishers, and data repositories."
"1249607","INSPIRE: ENABLING TRANSFORMATION IN THE SOCIAL SCIENCES, GEOSCIENCES, AND CYBERINFRASTRUCTURE THROUGH STAKEHOLDER ALIGNMENT AND NEW INSTITUTIONAL THEORY, METHODS, AND ANALYTICS","EAR","SCIENCE, TECH & SOCIETY, Science of Organizations, EarthCube, SciSIP Infrastructure, INSPIRE","10/01/2012","09/27/2012","Joel Cutcher-Gershenfeld","IL","University of Illinois at Urbana-Champaign","Standard Grant","Barbara L. Ransom","09/30/2016","$800,000.00","Barbara Lawrence, Michael Haberman, Joseph Mark Nolan, Courtney Flint","joelcg@brandeis.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","GEO","7603, 8031, 8074, 8075, 8078","7433, 7626, 8653, 9179, 0000, OTHR","$0.00","This INSPIRE award is partially funded by the Directorate of Geosciences and Office of Cyberinfrastructure as part of their committment to EarthCube, a major new NSF cyberinfrastructure activity to create a bold, integrated, geoscience data and knowledge management system for the 21st Century, and by three Programs in the Directorate for Social, Behavioral, and Economic Sciences (Science of Science and Innovation Policy; Science, Technology, and Society; and Science of Organizations). This is transformative, interdisciplinary, research that enables more effective design and implementation of community-driven cyberinsrastructure that will create an interoperable system of data systems and data types that serve a broad and disparate community of geoscience users with different backgrounds, needs, and scientific cultures. The research will also pioneer new social and behavioral science theory, methods, and analytics that address new and emerging ways that stakeholders are aligned around big, complex, infrastructure projects. The research is transformative in nature because it is a first-of-its kind project in which a major NSF community-driven infrastructure project of this magnitude has incorporated, as an integral part of its project structure, social science and an analysis of the community/stakeholder building process. It also breaks new ground in the developing of quantitative approaches to measure the evolution of collective community and individual perceptions over time. This type of understanding is critical when building trust and partnerships between science and technology communities that rarely, if ever, interact. The project involves the intimate interaction of social scientists, geoscientists, and cyberinfrastructure and computer science experts, with the results of the stakeholder studies being used to help improve the cyberinfrastructure design-and-build process, as well as guide the formation of the organizational and governance structures that will be needed to effectively manage community engagement and implementation of the final system. This research employs novel visualization tools and will develop innovative quantitative means for assessing stakeholder agreement and its evolution over time. The analysis of data and results will assist in identifing the most effective targets for infrastructure investment and understanding and improving community engagement in the design process, thus ensuring that whatever is created adequately serves end-user needs. Broader impacts of the work include the training of PhD students, accelerating progress in large NSF-initiated science and technology projects, and generating insights that will inform policy, planning, and resource allocation."
"1239623","EAGER: Interoperability Testbed - Assessing a Layered Architecture for Integration of Existing Capabilities","EAR","EarthCube","04/01/2012","03/28/2012","Ilkay Altintas","CA","University of California-San Diego","Standard Grant","Barbara L. Ransom","03/31/2013","$18,000.00","","altintas@sdsc.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","GEO","8074","7433, 7916","$0.00","ABSTRACT <br/>This EAGER award creates an interoperability test bed to identify the components of an effective layered architecture for geoscience and environmental science research. In a layered architecture, every layer consists of different technologies, each of which uses different interaction protocols. The proposed project will examine a wide variety of existing technologies in terms of their effectiveness in working across present data silos. These technologies include data grids, workflow systems, policy management systems, web visualization services, and security protocols that work with various repository catalogs. Project goals are focused on developing cyberinfrastructure tools and approaches that allow geoscience data repositories to enable new science and more effectively make their data holdings discoverable and available to the public. Essential elements of the project include the collection and comparision of various approaches and existing tools to check effectiveness in handling and integrating geoscience data, and by automating processes needed to integrate various databases and data types. The project is led by a team of experts in cyberinfrastructure and geoscience data management and employs a spiral softwar3ee development approach. Broader impacts of the work include building infrastructure for science in order to facilitate data-enabled science in the geosciences. It will also produce results that are likely to be applicable to fields outside of the geosciences. The effort supports a larger NSF effort to establish a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube."
"1239697","EAGER: Collaborative Research: Interoperability Testbed - Assessing a Layered Architecture for Integration of Existing Capabilities","EAR","EarthCube","04/01/2012","03/28/2012","Scott Peckham","CO","University of Colorado at Boulder","Standard Grant","Barbara L. Ransom","03/31/2013","$18,000.00","","Scott.Peckham@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","GEO","8074","7433, 7916","$0.00","ABSTRACT <br/>This EAGER award creates an interoperability test bed to identify the components of an effective layered architecture for geoscience and environmental science research. In a layered architecture, every layer consists of different technologies, each of which uses different interaction protocols. The proposed project will examine a wide variety of existing technologies in terms of their effectiveness in working across present data silos. These technologies include data grids, workflow systems, policy management systems, web visualization services, and security protocols that work with various repository catalogs. Project goals are focused on developing cyberinfrastructure tools and approaches that allow geoscience data repositories to enable new science and more effectively make their data holdings discoverable and available to the public. Essential elements of the project include the collection and comparision of various approaches and existing tools to check effectiveness in handling and integrating geoscience data, and by automating processes needed to integrate various databases and data types. The project is led by a team of experts in cyberinfrastructure and geoscience data management and employs a spiral softwar3ee development approach. Broader impacts of the work include building infrastructure for science in order to facilitate data-enabled science in the geosciences. It will also produce results that are likely to be applicable to fields outside of the geosciences. The effort supports a larger NSF effort to establish a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube."
"1450405","Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities","ACI","PHYSICAL & DYNAMIC METEOROLOGY, Software Institutes, EarthCube","08/01/2015","08/04/2015","Steven Greybush","PA","Pennsylvania State Univ University Park","Standard Grant","Rajiv Ramnath","07/31/2018","$99,953.00","","sjg213@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","1525, 8004, 8074","4444, 7433, 8009","$0.00","Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.<br/><br/>The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities."
"1450177","Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities","ACI","PHYSICAL & DYNAMIC METEOROLOGY, Software Institutes, EarthCube","08/01/2015","08/04/2015","Brian Ancell","TX","Texas Tech University","Standard Grant","Rajiv Ramnath","07/31/2018","$166,428.00","","brian.ancell@ttu.edu","349 Administration Bldg","Lubbock","TX","794091035","8067423884","CSE","1525, 8004, 8074","4444, 7433, 8009","$0.00","Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.<br/><br/>The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities."
"1450180","Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities","ACI","PHYSICAL & DYNAMIC METEOROLOGY, Software Institutes, EarthCube","08/01/2015","08/04/2015","Mohan Ramamurthy","CO","University Corporation For Atmospheric Res","Standard Grant","Rajiv Ramnath","07/31/2018","$98,702.00","","mohan@ucar.edu","3090 Center Green Drive","Boulder","CO","803012252","3034971000","CSE","1525, 8004, 8074","4444, 7433, 8009","$0.00","Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.<br/><br/>The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of ""nuclei,"" which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities."
"1263984","Increasing the Access to and the Relevance of Marine Seismic Data","OCE","MARINE GEOLOGY AND GEOPHYSICS, SHIP OPERATIONS, OCEANOGRAPHIC TECHNICAL SERVCE, OCEAN DRILLING PROGRAM, EarthCube","03/01/2013","06/08/2016","James Austin, Jr.","TX","University of Texas at Austin","Standard Grant","Barbara L. Ransom","12/31/2016","$99,947.00","","jamie@ig.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","GEO","1620, 5411, 5415, 5720, 8074","0000, 7433, OTHR","$0.00","This workshop brings together US and non-US representatives of the marine geology and geophysics community, as well as the offshore hydrocarbon industry to discuss shared data challenges in the marine geophysics area, in particular issues surrounding the collection, processing, and availability of 3D seismic data. Workshop Goals are to review successful examples of academic and industry shared-use activities in marine geophysics and discuss lessons learned, to discuss the possibility of R/V Marcus Langseth (the NSF-owned 3D seismic research vessel) operations that could both benefit the academic and industrial sector, and to discuss a possible joint industry-academic data acquisition and data interpretation scenario. Data discovery and accessibility issues and cyberinfrastructure needs related to EarthCube, the new NSF activity to integrate and improve the computing and data management needs of the NSF Geosciences Directorate, will also be discussed and summarized in documents to be made available to the public. This meeting is designed to address problems that have a significant present and future influence on the marine geophysicsl research and the education of the next generation of marine geophysicists. It will also explore improved sustainability of the Langseth 3-D seismic platform."
"1239702","EAGER: Collaborative Research: Interoperability Testbed-Assessing a Layered Architecture for Integration of Existing Capabilities","EAR","EarthCube","04/01/2012","03/28/2012","Janet Fredericks","MA","Woods Hole Oceanographic Institution","Standard Grant","Barbara L. Ransom","03/31/2013","$26,895.00","","jfredericks@whoi.edu","183 OYSTER POND ROAD","WOODS HOLE","MA","025431041","5082893542","GEO","8074","7433, 7916","$0.00","ABSTRACT <br/>This EAGER award creates an interoperability test bed to identify the components of an effective layered architecture for geoscience and environmental science research. In a layered architecture, every layer consists of different technologies, each of which uses different interaction protocols. The proposed project will examine a wide variety of existing technologies in terms of their effectiveness in working across present data silos. These technologies include data grids, workflow systems, policy management systems, web visualization services, and security protocols that work with various repository catalogs. Project goals are focused on developing cyberinfrastructure tools and approaches that allow geoscience data repositories to enable new science and more effectively make their data holdings discoverable and available to the public. Essential elements of the project include the collection and comparision of various approaches and existing tools to check effectiveness in handling and integrating geoscience data, and by automating processes needed to integrate various databases and data types. The project is led by a team of experts in cyberinfrastructure and geoscience data management and employs a spiral softwar3ee development approach. Broader impacts of the work include building infrastructure for science in order to facilitate data-enabled science in the geosciences. It will also produce results that are likely to be applicable to fields outside of the geosciences. The effort supports a larger NSF effort to establish a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube."
"1239693","EAGER: Collaborative Research: Interoperability Testbed-Assessing a Layered Architecture for Integration of Existing Capabilities","EAR","EarthCube","04/01/2012","07/30/2014","Clifford Matsumoto","CO","Colorado State University","Standard Grant","Barbara L. Ransom","03/31/2015","$17,972.00","","cliff.matsumoto@colostate.edu","601 S Howes St","Fort Collins","CO","805232002","9704916355","GEO","8074","7433, 7916","$0.00","ABSTRACT <br/>This EAGER award creates an interoperability test bed to identify the components of an effective layered architecture for geoscience and environmental science research. In a layered architecture, every layer consists of different technologies, each of which uses different interaction protocols. The proposed project will examine a wide variety of existing technologies in terms of their effectiveness in working across present data silos. These technologies include data grids, workflow systems, policy management systems, web visualization services, and security protocols that work with various repository catalogs. Project goals are focused on developing cyberinfrastructure tools and approaches that allow geoscience data repositories to enable new science and more effectively make their data holdings discoverable and available to the public. Essential elements of the project include the collection and comparision of various approaches and existing tools to check effectiveness in handling and integrating geoscience data, and by automating processes needed to integrate various databases and data types. The project is led by a team of experts in cyberinfrastructure and geoscience data management and employs a spiral softwar3ee development approach. Broader impacts of the work include building infrastructure for science in order to facilitate data-enabled science in the geosciences. It will also produce results that are likely to be applicable to fields outside of the geosciences. The effort supports a larger NSF effort to establish a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube."
"1239615","EAGER: Collaborative Research: Interoperability Testbed-Assessing a Layered Architecture for Integration of Existing Capabilities","EAR","EarthCube","04/01/2012","03/28/2012","Liping Di","VA","George Mason University","Standard Grant","Barbara L. Ransom","03/31/2013","$18,000.00","","ldi@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","GEO","8074","7433, 7916","$0.00","ABSTRACT <br/>This EAGER award creates an interoperability test bed to identify the components of an effective layered architecture for geoscience and environmental science research. In a layered architecture, every layer consists of different technologies, each of which uses different interaction protocols. The proposed project will examine a wide variety of existing technologies in terms of their effectiveness in working across present data silos. These technologies include data grids, workflow systems, policy management systems, web visualization services, and security protocols that work with various repository catalogs. Project goals are focused on developing cyberinfrastructure tools and approaches that allow geoscience data repositories to enable new science and more effectively make their data holdings discoverable and available to the public. Essential elements of the project include the collection and comparision of various approaches and existing tools to check effectiveness in handling and integrating geoscience data, and by automating processes needed to integrate various databases and data types. The project is led by a team of experts in cyberinfrastructure and geoscience data management and employs a spiral softwar3ee development approach. Broader impacts of the work include building infrastructure for science in order to facilitate data-enabled science in the geosciences. It will also produce results that are likely to be applicable to fields outside of the geosciences. The effort supports a larger NSF effort to establish a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube."
"1239678","EAGER: Collaborative Research: Interoperability Testbed-Assessing a Layered Architecture for Integration of Existing Capabilities","EAR","EarthCube","04/01/2012","03/28/2012","Reagan Moore","NC","University of North Carolina at Chapel Hill","Standard Grant","Barbara L. Ransom","03/31/2013","$61,719.00","","rwmoore@renci.org","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","GEO","8074","7433, 7916","$0.00","ABSTRACT <br/>This EAGER award creates an interoperability test bed to identify the components of an effective layered architecture for geoscience and environmental science research. In a layered architecture, every layer consists of different technologies, each of which uses different interaction protocols. The proposed project will examine a wide variety of existing technologies in terms of their effectiveness in working across present data silos. These technologies include data grids, workflow systems, policy management systems, web visualization services, and security protocols that work with various repository catalogs. Project goals are focused on developing cyberinfrastructure tools and approaches that allow geoscience data repositories to enable new science and more effectively make their data holdings discoverable and available to the public. Essential elements of the project include the collection and comparision of various approaches and existing tools to check effectiveness in handling and integrating geoscience data, and by automating processes needed to integrate various databases and data types. The project is led by a team of experts in cyberinfrastructure and geoscience data management and employs a spiral softwar3ee development approach. Broader impacts of the work include building infrastructure for science in order to facilitate data-enabled science in the geosciences. It will also produce results that are likely to be applicable to fields outside of the geosciences. The effort supports a larger NSF effort to establish a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube."
"1239718","EAGER: Collaborative Research: Developing a Community Computational Infrastructure for Earth System Model Research and Applications","EAR","EarthCube","04/01/2012","03/27/2012","Scott Peckham","CO","University of Colorado at Boulder","Standard Grant","Barbara L. Ransom","03/31/2013","$60,000.00","","Scott.Peckham@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","GEO","8074","7433, 7916","$0.00","This EAGER award focuses on exploring the feasibility of the implementation of a new paradigm in the development of an integrative and interoperable data and knowledge management system for the geosciences for a new NSF initiative called EarthCube. Led by a team of expert Earth system modelers, this project focuses on developing new approaches for integrating and coupling model components so that holistic geoscience scenarios that involve the interaction of large scale climate and atmospheric circulation models and smaller, more heterogeneous component models of surface earth processes can be explored and more effectively used by a broader range of users. The project engages participants from a number of major NSF-funded geoscience modeling investments (CSDMS, NCAR, CUHAUSI). A main goal of the of the work is to bridge the gaps between present modeling frameworks, data standards, and computational architectures. The approach includes collection of all relevant approaches and then comparing their pros and cons and linking existing different ""plug and play"" modeling components together and assessing the accuracy and robustness of model results. Major project goals are to see if more standard modeling protocols can be developed and to develop a general roadmap for improving the interoperability and meshing of model components that address phenomena at wildly different spatial and temporal scales. Broader impacts of the work include building new modeling infrastructure for science and leveraging prior NSF investments in cyberinfrastructure. It also improves the utility of, ease of use, and broader access of scientists and other potential users to more fully integrated and powerful earth systems models."
"1206274","Coordinating Office for Research on the Sedimentary Crust, Deep-Time and the Earth-Life System","EAR","GLOBAL CHANGE, SEDIMENTARY GEO & PALEOBIOLOGY","03/15/2013","08/03/2016","Dena Smith","CO","Geological Society of America Today","Cooperative Agreement","Judith Ellen Skog","01/31/2017","$975,707.00","Philip Gingerich, Lisa Park Boush, Howard Harper, Martin Perlmutter","dena@colorado.edu","3300 PENROSE PL","Boulder","CO","803011806","3033571000","GEO","1577, 7459","1304, EGCH, 7459","$0.00","This grant supports a sedimentary geology, deep-time, and Earth-life system science community coordinating Office (STEPPE, Sedimentary geology, Time, Environment, Paleontology, Paleoclimate, and Energy) to facilitate collaboration and communication among existing and new initiatives, build capacity, and promote research into the deep-time record of Earth processes. The Geological Society of America (GSA), the Society for Sedimentary Geology (SEPM), and the Paleontological Society (PS) will provide financial and in-kind support to the office.<br/><br/>Intellectual Merit and Broader Impacts: To predict the boundaries for human life on this planet--those imposed by climate change, energy, water issues, and our impact on the biosphere--we must have an integrated, deep-time perspective, or our vision will be incomplete, and our ability to make predictions about natural and human-made events and outcomes will be limited. Single sub-disciplines or even whole disciplines cannot provide the breadth and depth of information needed to address real-world issues. All sedimentary crust research groups examine different parts of a larger research problem, and current initiatives reflect different perspectives and/or emphases for sedimentary-crust research, especially in the deep past. It is clear that broad segments of the community is working toward an integrated approach, but lack a platform to coordinate and integrate these efforts. The 2011 National Research Council report on Understanding Earth's Deep Past, states that it is essential to make ""A transition from single researcher or small group research efforts to a much broader-based interdisciplinary collaboration of observation-based scientists with climate modelers for team-based studies of important paleoclimate events,"" and this requires coordination. The STEPPE office will provide that platform and that coordination. <br/>The STEPPE office will help facilitate the EarthCube vision for geoscience cyberinfrastructure by bringing together various relevant geoinformatics efforts, and work to ensure that other cyberinfrastructure needs are articulated and coordinated. In addition, the STEPPE office will work with the community and with education partners to develop state-of-the-art education and outreach programs involving K-12, decision makers, and the general public through formal and informal educational activities. The STEPPE office will enhance communication between the research community and State, Federal and international agencies and organizations, including industry, in order to build capacity and voice community perspectives. The office will ensure that the independence and importance of existing and planned community initiatives is maintained, and also enhanced through this group effort. The office will promote individual initiatives and coordinate efforts among them. Better communication, coordination and collaboration will help to develop more effective research strategies for the entire community and help meet goals of the 2009 NSF GeoVision Report. The office will help the community develop new strategies and tools for understanding Earth-environment-life relationships with greater sophistication, and for application to our understanding of Earth-system processes."
"1445821","Workshop Support for Focused Technical Workshop on Improving Data Mobility & Management for International Climate Science","ACI","Campus Cyberinfrastrc (CC-NIE)","07/01/2014","06/25/2014","Jennifer Schopf","IN","Indiana University","Standard Grant","Kevin L. Thompson","05/31/2016","$44,316.00","","jmschopf@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","8080","7556","$0.00","The Focused Technical Workshop on Improving Data Mobility & Management for International Climate Science (FTW for Climate Science) will enable an active dialogue between climate scientists, climate data managers, and cyberinfrastructure engineers with the goal of setting longer-term relationship building in motion. The workshop also hopes to provide climate researchers with information about a set of broad, concrete, and immediately useful tools and resources for improved data transport and management. The FTW on Climate Science is sponsored by ESnet, Internet2, Indiana University (IU), National Center for Atmospheric Research (NCAR), and National Oceanic and Atmospheric Administration (NOAA) and will be hosted at the NOAA Boulder Labs, in Boulder, Colorado, in July 2014.<br/><br/>The workshop will bring together experts to discuss recent research technology advances and research techniques in data management for climate science. The format is being designed to encourage lively, interactive discussions with the goal of developing a set of tangible next steps for supporting this data-intensive science community. Participation key stakeholders from multiple agencies and programs provides the climate science community with the knowledge, tools, and partners necessary to improve data transfer performance as data scale continues to increase. This has the potential to have broad reaching effects in a science area that is critical to society. By increasing performance to match increased data scale, scientific productivity for this community is expected to increase. This workshop will leverage existing NSF supported projects, including work with EarthCube."
"1440015","Collaborative Research: USG Support for the Past Global Changes Project International Program Office","EAR","GLOBAL CHANGE","09/01/2014","08/10/2016","Loutre Marie-France","","Past Global Changes","Continuing grant","Justin Lawrence","08/31/2018","$1,378,839.00","","marie-france.loutre@pages.unibe.ch","Zaehringerstrasse 25","Bern 3012","","","0316315608","GEO","1577","1304, 5950, EGCH","$0.00","The Past Global Changes Program, is an open and international organization that coordinates global change science internationally, prioritizes key topics, facilitates cross-disciplinary research, promotes syntheses of results, and ensures dissemination of data, results, and knowledge. PAGES fills a unique niche and adds value to individual and national research. Over the next four years, PAGES will organize interdisciplinary working groups and cross-cutting activities that address relevant community-driven science issues, via open and international workshops, and synthesize knowledge and data. Its objectives are to link data products with Earth system modeling, translate regional knowledge of climatic and environmental changes into actionable information useful for decision-makers, and build capacity among young scientists and in nations less established in science. PAGES' activities all center around four themes: the Climate theme will inform climate projection efforts, and combined with modern and historical observational evidence will contribute to climate services. The Environment theme will address research topics central to Future Earth and inform environmental management efforts such as landscape conservation, ecosystem management, and fire control. The Humans theme will inform adaptation strategies and contribute to specific solutions for policy makers and resource managers; there is transformative potential to develop novel approaches involving social scientists or economists within this theme. Results from the cross-topical integrated activities on tipping points, extreme events, and warmer worlds, are targeted to inform risk assessments and natural disaster mitigation.<br/><br/>PAGES will exist under the new Future Earth program and intensify its partnership with the World Climate Research Program. The community-built scientific structure proposed here will align with these programs' agendas. PAGES' new structure will encourage integrative activities related to the sustainability issues prioritized by Future Earth and the World Climate Research Program. In addition to the research output generated by scientific activities, PAGES will ensure broad impact by: identifying key science issues that can only be addressed through a transnational community approach; advocating for the incorporation of scientific evidence into wider Earth system science and international assessments; communicating scientific results to Global Environmental Change scientists, the media and public; contributing to data management in collaboration with NSF-EarthCube and NOAA; and building capacity among developing country and young scientists through active involvement, educational meetings, mentorships, and by organizing the Open Science and Young Scientists Meetings.<br/><br/>PAGES has a record of producing scientific output, including over 300 publications since 2010, with numerous major syntheses. Many publications obtained wide attention in the broader scientific community and contributed substantially to the latest Intergovernmental Panel on Climate Change (IPCC) assessment. Long-lived value was created by coherent data compilations that increased the number of available data by ~5 times. PAGES intends to support transnational working groups, to provide vehicles for data-model integration, and to facilitate community data syntheses that add expertise and value to individual results and contribute to international assessments such as the IPCC and Intergovernmental Platform on Biodiversity and Ecosystem Services. Under the new structure the Climate theme will address climate dynamics at the regional to global scales to obtain improved records of climate forcing, sensitivity and Earth system feedback. It will also assess model skills and provide insight into non-linearities, thresholds and the predictability of climate over long time intervals. The Environment theme will address the components of the biosphere that interact with climate change and introduce long-term feedback into the Earth system including biogeochemical cycling, ecosystem dynamics and ecosystem services. The Humans theme will address long-term environmental changes where humans are a major agent and where environmental changes have an effect on the functioning and well-being of ecosystem services and societies. In addition, cross-topical integrated activities such as thresholds and tipping points, extreme events, warmer worlds and data management, will encourage an interdisciplinary, synthesizing approach among the scientific community and other stakeholders."
"1248152","Facilities Support: The CUAHSI Water Data Center","EAR","INSTRUMENTATION & FACILITIES, HYDROLOGIC SCIENCES","04/01/2013","04/22/2016","Richard Hooper","MA","Consortium of Universities for the Advancement of Hydrologic Sci","Cooperative Agreement","Russell C. Kelz","03/31/2017","$2,685,070.00","Alva Couch, Diana Dalbotten, Antony Berthelote","rhooper@cuahsi.org","196 Boston Avenue","Medford","MA","021554255","3392215400","GEO","1580, 1579","0000","$0.00","1248152 <br/>Hooper<br/><br/>This Cooperative agreement supports the Consortium for the Advancement of the Hydrologic Sciences (CUAHSI) to construct and maintain a web-accessible water-data center (WDC) that builds off the prototype Hydrologic Information System (HIS) developed at the University of Texas. Over the next three years , WDC development will offer new access to water data holdings, discovery tools, archival and sharing/publishing capabilities and will build a consistent set of data format standards definitions, data format translators, analysis software tools, mobile platform applications and provide for user training and support. WDC will provide access to a range of water data now held in a multitude of data formats and across numerous platforms with vastly different access tools. Data to be ingested in WDC will include the data holdings of the USGS National Water Information Service, EPA and NOAAs National Climate Data Center (NCDC), other federal and state agency data holdings, and academic and private foundation water data holdings. WDC will integrate the use of cloud computing and data services to facilitate data discovery and use and include tools for real time state-of-health monitoring of operational sensor networks. The WDC concept directly addresses NSF data policies and will be integrated into in a growing network of geoscience information system services (e.g., Unidata, OpenTopography, EarthChem through participation in GEOs EarthCube initiative). WDC PIs will continue international efforts for developing and adopting consistent data standards for hydrologic observation web-base publication through participation in international standards-setting bodies (e.g., the Open Geospatial Consortium (OGC) and the Global Earth Observation System of Systems (GEOSS)). The PIs also plan a set of outreach activates focused on Native Americans (in collaboration with tribal college and governmental partners) for building and development of water management data tools in support of the tribal resources management needs.<br/><br/>***"
"1341831","Workshop on Cyberinfrastructure for Polar Sciences","PLR","POLAR CYBERINFRASTRUCTURE, Software Institutes","07/01/2013","07/07/2015","Jonathan Pundsack","MN","University of Minnesota-Twin Cities","Standard Grant","Neil R. Swanberg","06/30/2016","$99,998.00","","pundsack@umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","GEO","5407, 8004","7433, 7556","$0.00","The Polar Cyberinfrastructure Program at the National Science Foundation has the potential<br/>to transform polar research, by facilitating the transmission and integration of <br/>tools and knowledge across the polar and cyberinfrastructure communities. Community input is essential<br/>to the process of realizing these goals, to ensure that the infrastructure investments meet<br/>the on-the-ground requirements of scientists working in each domain. <br/>In this regard, the PI proposes to organize a workshop to identify and define<br/>priorities for how to further and enable better polar science through cyberinfrastructure. <br/>The workshop will produce a final report to the Polar Cyberinfrastructure Program. The workshop and report will address<br/>engagement and building bridges between computer and polar sciences, what can be accomplished<br/>in the short-term (1-5 years) and long-term (5-10+ years). Topics that will be discussed include<br/>big data and data access, software tools for data and metadata acquisition, workflow support,<br/>data analysis, data visualization, and modeling, computing capabilities, interoperability<br/>with data from other domains, as well as policies and procedures that address the polar scientists?<br/>and engineers? concerns regarding, for example, data sharing, data citation, intellectual<br/>property, and career advancement. Participants from the broadest range of science domains will be engaged, including early career scientists. <br/>The format of the workshop will be similar to those organized through the EarthCube program, with presentations and breakout sessions."
"1550920","EAGER-NEON: Collaborative Research: Formation of a NEON Microbial Metagenomics Data Synthesis Working Group","EF","MACROSYSTEM BIOLOGY","10/01/2015","08/03/2015","Emma Aronson","CA","University of California-Riverside","Standard Grant","Larry Halverson","09/30/2017","$92,730.00","","emma.aronson@ucr.edu","Office of Research","RIVERSIDE","CA","925211000","9518275535","BIO","7959","7350, 7916","$0.00","The goal of this collaborative project is to enhance the ability to analyze microbial metagenomics datasets of the National Ecological Observatory Network (NEON). Microbial metagenomics, the characterization of microbial communities by the genes present in the sample, is important for fully understanding microbial processes. This project will enhance the comparative analytical capabilities available to the scientific community for describing properties of microbial communities, which will enable better integration of biological and geoscience data with other current earth-systems observing efforts. These improved analytic tools will facilitate developing better interconnections between environmental factors, biogeochemical processes, and microbial ecosystem structure and function in a more holistic fashion. The project will establish a Synthesis Working Group that will collect community input for guiding cyber-infrastructure and bioinformatics tool development and for answering fundamental questions with the NEON microbial metagenomics data sets. <br/><br/>This collaborative project will form and coordinate a Synthesis Working Group for analysis and integration of NEON metagenomics data, leveraging ongoing development of bioinformatics and cyber-infrastructure tools for metagenomic data in partnership with other concurrent earth-systems observing efforts EarthCube and Critical Zone Observatories. The Synthesis Working Group will enhance scientific advancement by 1) facilitating formation of a diverse team to inform and utilize NEON microbial metagenomic data, 2) exploring strategies for synthesis of NEON metagenomic data using existing and new bioinformatics and cyberinfrastructure tools, and 3) synthesizing NEON metagenomic datasets via integration with multiple existing and developing open data archives. This project will enable comparisons that cannot be adequately synthesized today, which is necessary for evaluating the sustainability and resilience of microbial ecosystems, as well as the function of these microbial communities in supporting key ecosystem services. The project will engender broad scientific dissemination, use, and intercomparison of NEON data products through targeted scientific outreach activities and engagement of the scientific community, including integration of NEON with other earth-systems observing efforts."
"1216894","Conceptualizing an Institute for Sustainable Earth and Environmental Software (ISEES)","ACI","ADVANCES IN BIO INFORMATICS, CYBERINFRASTRUCTURE, ICER, Software Institutes","10/01/2012","09/10/2012","Matthew Jones","CA","University of California-Santa Barbara","Standard Grant","Daniel Katz","09/30/2014","$582,660.00","Mark Schildhauer, Carol Meyer, William Michener, Peter Fox","jones@nceas.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","CSE","1165, 7231, 7699, 8004","7433, 8060, 8211","$0.00","The University of California Santa Barbara is awarded a grant for a one-year community-driven process to develop a strategic plan for the creation and operation of an Institute for Sustainable Earth and Environmental Software (ISEES) that would provide development and sustainable support of innovative and interoperable scientific software tools that can transform science at the intersection of earth, environmental, and life sciences. Software is critical to advances in environmental science, but is in crisis due to issues that are prevalent in scientific software, such as code complexity and opacity, lack of scalability, lack of openness and interoperability, and lack of formal versioning and management of software evolution for sustainability. The vision for ISEES is to advance the state of science software by engaging earth and environmental research communities to address the software barriers that most impede grand challenge earth science. This project will work with community efforts such as EarthCube to develop a strategic plan that improves capabilities for scientific discovery within overlapping disciplines within the geological and biological sciences, such as ecology, oceanography, and atmospheric science. ISEES would engage a large swath of the science community in projects that will create and mature software that facilitates bold new science advances. For each science topic identified as a community priority, participants in this planning effort will collaboratively address the entire software lifecycle, from product conceptualization, to requirements analysis, design, development, testing, deployment, long-term support, and decommissioning. A robust workforce development program will be specified to sustain software advances made through ISEES. <br/><br/>The planning process will be diverse, including earth, life, and environmental scientists and experts from software engineering, computer science, informatics, and library sciences. A series of design workshops that use proven, formal planning and assessment methods will meet in three topical clusters to conceptualize and articulate a grand vision and strategy for how ISEES will transform the software lifecycle and galvanize the research community. A Science Cluster collates and articulates grand challenges within earth observational sciences that focus and drive ISEES' software activities and define exemplary collaborative science activities that support detailed requirements analysis. A Software Cluster analyzes requirements for scientific software and proposes approaches for ISEES to address these via improvements across the full science software lifecycle. And, a Sustainability and Adoption Cluster examines sustainability and governance challenges, and proposes models for engaging the research community, governing ISEES, and developing an effective workforce that can sustain the portfolio of science software curated through ISEES. Community experts lead each working group and collectively comprise a Steering Committee that synthesizes recommendations, presents these results and gathers feedback at a Town Hall co-located at a major science conference, and combines this with recommendations from an open call for comments on the Internet to create the final Strategic Plan describing the mission, design, and impact of ISEES."
"1428421","MRI: Acquisition of an X-Ray Fluorescence scanner for automated high-resolution sensing of Earth system archives","EAR","MAJOR RESEARCH INSTRUMENTATION, INSTRUMENTATION & FACILITIES","08/01/2014","08/06/2014","Anders Carlson","OR","Oregon State University","Continuing grant","David Lambert","07/31/2016","$392,000.00","Alan Mix, Robert Wheatcroft, Joseph Stoner, Julie Pett-Ridge","acarlson@coas.oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","GEO","1189, 1580","1189","$0.00","The growing evidence for pervasive impacts of humanity on Earth's natural systems makes it critical to assess natural variability in these diverse systems, the extent to which humans perturbed the mean state or extreme ends, and if these perturbations are beyond the systems natural variance. Changes in sediment chemistry reflect changes in physical, biological and anthropogenic processes shaping Earth's surface, recording change in climate, rivers, glacial ice, and ocean conditions and productivity, and humans. This Major Research Instrumentation award funds the acquisition of a high-resolution scanner for rapid, cost-effective and non-destructive analyses of major and trace elemental content of sedimentary records to address this research theme. Next-generation high-resolution scanners measure elemental concentrations from Aluminum to Uranium at high precision and high resolution, and co-register a high-resolution color image of the sample and/or an internal image. These data are collected orders of magnitude faster than traditional wet-chemistry and imaging approaches (hours vs. weeks-months), and the high resolution of scanning is impossible to achieve by physical sampling. This rapidity of data acquisition via next generation high resolution scanning at otherwise impossible resolutions opens new doors for tackling questions of Earth's natural systems behaviors over their full dynamic range including human impacts. The acquisition of a high-resolution elemental scanner and its pairing with the Oregon State University-Marine Geology Repository will have an immediate broad impact on the Pacific Northwest research community where this instrument is greatly needed, and service will extend to national and international research communities. The instrument will enhance at least 10 courses with for experiential learning, and train graduate and undergraduate students in data-intensive geochemical studies. The scanner will promote diversity in Earth sciences through its use of Research Experience for Undergraduates and Increasing Diversity in Earth Sciences programs, coaching underrepresented groups in state-of-the-art studies of Earth's natural systems.<br/><br/>Researchers at Oregon State and the College of Earth, Ocean, and Atmospheric Sciences (CEOAS) will use rapid, high-resolution, and accurate measurements of geochemical changes in sedimentary records to track variations in Earth's natural systems from sediment source to sink. A next-generation X-ray fluorescence (XRF) scanner purchased with this award will be an essential tool for the study of sedimentary geochemical archives of Earth system processes. OSU's acquisition of an XRF scanner would be the first such instrument in the Pacific Northwest, significantly advancing scientific exploration. CEOAS has extensive experience managing large labs, analytical equipment, and serving external users. The NSF-funded OSU Marine Geology Repository will house the XRF scanner, efficient for application to one of the nation's largest core archives and complementing existing tools including Geotek multisensing core logging tracks and medical CT-scanner. These tools will serve the OSU, regional, national and international research communities. Availability of advanced high-resolution sensing tools will support data-intensive projects consistent with modern ""big data"" initiatives like NSF's EarthCube. Specific research programs that the instrument will immediately catalyze include: 1) Reconstructing the Quaternary history of the Greenland, Cordilleran, Laurentide and Antarctic ice sheets and their sensitivity to global warming using existing and new sediment archives. 2) Paleoclimate studies of ocean climate adjacent to these ice sheets, tropical Pacific changes and their impact on the carbon cycle, and late-Holocene seasonal to century-scale changes in the high latitudes, all of which are to determine the range of natural variability relative to recent deviations. 3) Construct seasonal to century-scale changes in Earth's critical zone that extends from the top of vegetation to the base of weathered bedrock upon which humanity depends and is impacting. 4) Investigate preindustrial paleoenvironments and human-landscape interactions, a baseline for recent critical zone changes. 5) Document the frequency and severity of past earthquakes in the Pacific Northwest and their impacts on the critical zone."
"1341929","EAGER: Collaborative Research: SAVI: Leveraging the Ocean Data Interoperability Platform (ODIP) for International Marine Science","OCE","INTERNATIONAL COORDINATION ACT","08/01/2013","07/28/2014","Suzanne Carbotte","NY","Columbia University","Continuing grant","James S. Holik","11/30/2015","$99,967.00","Vicki Ferrini, Robert Arko","carbotte@ldeo.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","GEO","1679","","$0.00","Leveraging US-R2R and EU-ODIP Informatics for International Marine Science <br/><br/>Since the 2009 launch, the Rolling Deck to Repository (R2R; http://rvdata.us/) program has made dramatic progress in routinely capturing shipboard data from the entire US academic fleet of 25 active service vessels. The R2R team has developed innovative technology to overcome the wide diversity of data practices, naming conventions and data formats across the fleet, which is managed by 18 independent operating institutions, large and small. As of September 2012, R2R had cataloged 11,026,386 data files from 2,644 cruises. <br/><br/>These NSF-funded accomplishments clearly benefit the US research community, but inquiries in the marine sciences are becoming more global in scope. While other nations and regions, notably the Europeans and the Australians, have also made tremendous progress in gathering data sets and placing them online, inevitably barriers to discovery and access can exist for a host of reasons, from basic awareness of resources to conflicts in search and access protocols, naming conventions and data formats. <br/><br/>Rather than continuing to independently develop (expensive) wheels, ODIP proposes to establish formal collaboration mechanisms to synchronize US, European and Australian efforts with a series of technical workshops designed to make practical advances, rather than a series of meetings in which PI?s stand up and make presentations. The Ocean Data Interoperability Platform (ODIP) has been launched as a combined US-EU-Australian project specifically because ocean data interoperability must span national boundaries. <br/><br/>R2R is a collaborative NSF program, funded through 31 August 2014, combining the efforts of LDEO, SIO, WHOI and FSU. The R2R team requests funding to (1) enhance the flexible discovery and harvesting of R2R content through implementing a ?Linked Data? approach; (2) map key vocabularies used by R2R to their EU counterparts, allowing users to search across US and EU resources using the terms with which they are familiar; and (3) upgrade existing R2R ISO 19115 metadata records to be compliant with the EU INSPIRE schema, which specifically addresses documenting quality. These efforts will be carried out in coordination with a number of other current interoperability projects, such as the work of the EarthCube Interoperability Concept Group, Unidata, and the COOPEUS project."
"0955816","INTEROP--Spatial Ontology Community of Practice: an Interdisciplinary Network to Support Geospatial Data Sharing, Integration, and Interoperability","ACI","CYBERINFRASTRUCTURE, DATA INTEROPERABILITY NETWORKS","09/01/2010","04/01/2011","Nancy Wiegand","WI","University of Wisconsin-Madison","Standard Grant","Robert Chadduck","08/31/2014","$733,142.00","Mike Dean, Naijun Zhou, Gary Berg-Cross, James Wilson","wiegand@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7231, 7701","7701, 9251","$0.00","Award: 0955816<br/>PI: Nancy Weigand<br/>Project Title: Spatial Ontology Community of Practice: an Interdisciplinary Network to Support Geospatial Data Sharing, Integration and Interoperability (INTEROP)<br/><br/><br/>Geospatial data, which describe location information for geographic features, are pervasive across many disciplines and fundamental for diverse applications, such as economic development, natural resources, environmental protection, and emergency response. But, re-using geospatial data remains difficult because of the heterogeneity. Although progress has been made by initiatives such as the National Spatial Data Infrastructure (NSDI) and Geospatial One-Stop to distribute data, it is now necessary to address issues of standards harmonization and agreement on the meanings of relevant concepts from diverse data sets due to the use of different community views. Semantic interoperability has been recognized as a stumbling block to collaboration needed by research communities. As a solution, well designed, formal ontologies, relying on agreements between communities on unambiguous representation of concepts and relationships for a given problem area, can be used as an analytic tool to bridge community gaps. Unfortunately, many communities lack the expertise to develop, test, and disseminate such ontologies on their own, and, further, common ontologies require agreement across a range of communities. The purpose of this Network is to create such opportunities for the geospatial community and extend the results to related communities. The Network can be considered as an umbrella over other more specific domains linked through the Network. The Network is based on an existing Spatial Ontology Community of Practice (SOCoP) network that already has a core group of active participants from academia, government, and industry. <br/><br/>Mechanisms for the Network include an on-line collaboration environment, a repository for geospatial ontologies with tools; educational and participatory workshops for a broad geospatial community to solicit input on use cases, smaller working group sessions on one or two chosen domains to collaborate on developing ontologies that work across use cases, and interactions with standards groups for formal publishing of ontologies, demonstrations, and research activities. The SOCoP INTEROP network will also provide training and outreach in cross-area standards, data-sharing, and information management in scientific and local communities by demonstrating the power of cooperative modeling of semantics. An educational component on geospatial ontologies will also be developed. The project will contribute to a model to incorporate semantics into the next phase of the National Spatial Data Infrastructure"
"1550852","EAGER-NEON: Collaborative Research: Formation of a NEON Microbial Metagenomics Data Synthesis Working Group","EF","MACROSYSTEM BIOLOGY","10/01/2015","08/03/2015","Folker Meyer","IL","University of Chicago","Standard Grant","Larry Halverson","09/30/2017","$173,451.00","","folker@mcs.anl.gov","5801 South Ellis Avenue","Chicago","IL","606375418","7737028669","BIO","7959","7350, 7916","$0.00","The goal of this collaborative project is to enhance the ability to analyze microbial metagenomics datasets of the National Ecological Observatory Network (NEON). Microbial metagenomics, the characterization of microbial communities by the genes present in the sample, is important for fully understanding microbial processes. This project will enhance the comparative analytical capabilities available to the scientific community for describing properties of microbial communities, which will enable better integration of biological and geoscience data with other current earth-systems observing efforts. These improved analytic tools will facilitate developing better interconnections between environmental factors, biogeochemical processes, and microbial ecosystem structure and function in a more holistic fashion. The project will establish a Synthesis Working Group that will collect community input for guiding cyber-infrastructure and bioinformatics tool development and for answering fundamental questions with the NEON microbial metagenomics data sets. <br/><br/>This collaborative project will form and coordinate a Synthesis Working Group for analysis and integration of NEON metagenomics data, leveraging ongoing development of bioinformatics and cyber-infrastructure tools for metagenomic data in partnership with other concurrent earth-systems observing efforts EarthCube and Critical Zone Observatories. The Synthesis Working Group will enhance scientific advancement by 1) facilitating formation of a diverse team to inform and utilize NEON microbial metagenomic data, 2) exploring strategies for synthesis of NEON metagenomic data using existing and new bioinformatics and cyberinfrastructure tools, and 3) synthesizing NEON metagenomic datasets via integration with multiple existing and developing open data archives. This project will enable comparisons that cannot be adequately synthesized today, which is necessary for evaluating the sustainability and resilience of microbial ecosystems, as well as the function of these microbial communities in supporting key ecosystem services. The project will engender broad scientific dissemination, use, and intercomparison of NEON data products through targeted scientific outreach activities and engagement of the scientific community, including integration of NEON with other earth-systems observing efforts."
"1339793","Collaborative Research: SI2-SSI: The Community-Driven Big-CZ Software System for Integration and Analysis of Bio- and Geoscience Data in the Critical Zone","ACI","Software Institutes","12/01/2013","08/09/2016","Ilya Zaslavsky","CA","University of California-San Diego","Standard Grant","Rajiv Ramnath","11/30/2017","$433,911.00","David Valentine","zaslavsk@sdsc.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","8004","7433, 8009","$0.00","The Critical Zone (CZ) science community takes as its charge the effort to integrate theory, models and data from the multitude of disciplines collectively studying processes on the Earth's surface. The Critical Zone is Earth's permeable near-surface layer - from the atmosphere at the vegetation's canopy to the lower boundary of actively circulating groundwaters. The Critical Zone was a term coined by the National Research Council's Basic Research Opportunities in the Earth Sciences (BROES) Report (2001) to highlight the imperative for a new approach to thoroughly multi-disciplinary research on the zone of the Earth?s surface that is critical to sustaining terrestrial life on our planet. In January 2013, 103 members of the CZ community met for the CZ-EarthCube Domain Workshop (NSF Award #1252238) to prioritize the CZ community's key science drivers, key computational and information technology (""cyber"") challenges and key cyber needs. They identified that the central scientific challenge of the critical zone science community is to develop a ""grand unifying theory"" of the critical zone through a theory-model-data fusion approach. Work participants unanimously described that the key missing need of this approach was a future cyberinfrastructure for seamless 4D visual exploration of the integrated knowledge (data, model outputs and interpolations) from all the bio and geoscience disciplines relevant to critical zone structure and function, similar to today?s ability to easily explore historical satellite imagery and photographs of the earth's surface using Google Earth. This project takes the first ""BiG"" steps toward answering that need.<br/><br/>The overall goal of this project is to co-develop with the CZ science and broader community, including natural resource managers and stakeholders, a web-based integration and visualization environment for joint analysis of cross-scale bio and geoscience processes in the critical zone (BiG CZ), spanning experimental and observational designs. Our Project Objectives are to: (1) Engage the CZ and broader community to co-develop and deploy the BiG CZ software stack; (2) Develop the BiG CZ Portal web application for intuitive, high-performance map-based discovery, visualization, access and publication of data by scientists, resource managers, educators and the general public; (3) Develop the BiG CZ Toolbox to enable cyber-savvy CZ scientists to access BiG CZ Application Programming Interfaces (APIs); and (4) Develop the BiG CZ Central software stack to bridge data systems developed for multiple critical zone domains into a single metadata catalog. The entire BiG CZ Software system will be developed on public repositories as a modular suite of fully open source software projects. It will be built around a new Observations Data Model Version 2.0 (ODM2) that is being developed by members of the BiG CZ project team, with community input, under separate funding (NSF Award #1224638)."
"1224638","Developing a Community Information Model and Supporting Software to Extend Interoperability of Sensor and Sample Based Earth Observations","EAR","HYDROLOGIC SCIENCES, GEOINFORMATICS, CZO: CRITICAL ZONE OBSER SOLIC","08/01/2012","08/01/2013","Jeffery Horsburgh","UT","Utah State University","Continuing grant","Russell C. Kelz","07/31/2015","$551,176.00","Ilya Zaslavsky, Kerstin Lehnert, Anthony Aufdenkampe, Emilio Mayorga","jeff.horsburgh@usu.edu","Sponsored Programs Office","Logan","UT","843221415","4357971226","GEO","1579, 7255, 7693","9150","$0.00","1224638<br/>Horsburgh<br/><br/>This EAR Geoinformatics Program grant supports a two year project to develop a community information model and related software to enable web based interoperability of earth observations derived from sensors and samples that span now discrete data and informatics initiatives for multiple communities. The system would target specific existing web service data repositories in order to demonstrate how the information model can support federation of earth observations data across multiple data publication systems. Specific repositories include the Consortium of Universities for the Advancement of Hydrologic Science, Inc. (CUAHSI) Hydrologic Information System (HIS), EarthChem, the Critical Zone Observatory (CZO) Integrated Data Management System (CZOData), the Integrated Ocean Observing System (IOOS) and the Data Observations Network for Earth (DataONE). The plan calls for collaboration with the related Pis of these projects (through subward support) to improve capture, sharing, and archival these data and associated metadata by building ontologies for describing, encoding and publishing data in common formats to allow interoperability. The plan involves community workshops to engage stakeholders and students in the design of the model. The model would incorporate international standards for data description and publishing utilizing Open Geospataial Consortium standards and domain specific markup languages. It is hoped that the results will feed directly into the larger EarthCube cyberinfrastructure initiative. <br/><br/>***"
"1265197","Operations Support For Continental Scientific Drilling Workshops","EAR","INSTRUMENTATION & FACILITIES","01/15/2013","10/20/2014","Andrew Cohen","AZ","University of Arizona","Standard Grant","David Lambert","12/31/2014","$54,031.00","","cohen@email.arizona.edu","888 N Euclid Ave","Tucson","AZ","857194824","5206266000","GEO","1580","","$0.00","This award will support the planning and assessment of future continental scientific drilling (CSD) opportunities for the Earth sciences community. As a result of recent meetings (2011, 2012) of the Science Planning and Education and Outreach Committees of DOSECC a plan was put into place to provide NSF with broad community input concerning specific CSD science objectives in six broad areas for which the Science Planning and Education and Outreach Committees concluded that significant opportunities existed for CSD advances in the near future:<br/><br/>1) Scientific Drilling and the Evolution of the Earth System: Climate, Biota, Biogeochemistry, and Extreme Events.<br/>2) Drilling, active tectonics and magmatism (volcanics, fault zones, Geoprisms, post-SAFOD).<br/>3) Drilling into High-enthalpy Geothermal Systems: A Collaborative Initiative to Promote Scientific Opportunities.<br/>4) Drilling, sampling, and imaging the depths of the critical zone.<br/>5) EarthCube GEO Domain Workshop: Cyberinfrastructure for Paleogeoscience.<br/>6) Broadening the Scope of Education and Outreach to Enhance the Scientific and Societal Impacts of Continental Scientific Drilling.<br/><br/>This award will support an on-campus IT support analyst and an off-campus workshop coordinator who will both assist the individual conveners with routine pre- and mid-workshop tasks and, most importantly, will help assemble a combined workshop report that documents and synthesizes the findings of all of these meetings, vis--vis the needs of the continental scientific drilling community."
"1440412","SI2-SSE: Wavelet Enabled Progressive Data Access and Storage Protocol (WASP)","ACI","ADVANCES IN BIO INFORMATICS, PHYSICAL & DYNAMIC METEOROLOGY, Software Institutes, EarthCube","10/01/2014","07/25/2014","Lawrence Frank","CA","University of California-San Diego","Standard Grant","Rajiv Ramnath","09/30/2017","$500,000.00","","lfrank@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","CSE","1165, 1525, 8004, 8074","4444, 7433, 8005","$0.00","Advances in digital imaging methods are revolutionizing a wide range of scientific disciplines by facilitating the acquisition of huge amounts of data that allow the visualization and analysis of complex, multidimensional images. Concurrently, modern computing technologies enable numerical modeling of a broad gamut of scientific phenomena, resulting in vast quantities of numerical data, which are just the starting point for the scientific exploration that modern computational and visualization methods enable. This is particularly true in the biological and geosciences, two seemingly very different disciplines. These capabilities come with a cost: increasing data size and complexity require more sophisticated methods for data analysis and visualization. This project will conduct research that will lead to a common software framework for supporting a multi scale progressive data refinement method based upon the representation of the data as a wavelet expansion, and enabling interactive exploration of large data sets for the bio and geoscience communities. The development of a general toolkit for wavelet based representations of data will have broad impact, allowing the multi scale analysis, storage, and visualization for data collected in a wide range of fields and on a multitude of platforms, from high end computing facilities to laptop computers used by students, field biologists, and others.<br/><br/>Analysis and visualization of large data sets play an important role in scientific discovery. Efficient, and broadly available tools to accomplish these tasks are crucial for a wide range of scientific and educational fields. However, efficient analysis and visualization is a non trivial problem as the size and complexity of data increases. This research addresses this challenge through a general progressive access, multi scale data representation for efficient handling of structured data sets across a range of science domains. The development is based upon a wavelet enabled data representation developed by NCAR for geoscience applications. The tools will utilize the very flexible and open source standard NetCDF format, and the methods will be documented as a set of conventions and a toolkit developed that incorporates and integrates these components for dissemination. In addition to an open source toolkit, these tools will be integrated into the VAPOR (NCAR) and STK (CSCI) platforms, thus expanding the capabilities and efficiencies of these platforms for the geo and bio sciences communities, respectively.  Advancements generated by this project will be openly disseminated to the user community through an open source toolkit."
"1450451","SI2-SSI: Community Software for Extreme-Scale Computing in Earthquake System Science","ACI","GEOPHYSICS, GEOINFORMATICS, Software Institutes, EarthCube, CDS&E","09/01/2015","08/17/2015","Thomas Jordan","CA","University of Southern California","Standard Grant","Vipin Chaudhary","08/31/2019","$2,200,000.00","Kim Olsen, Yifeng Cui, Ricardo Taborda","tjordan@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","1574, 7255, 8004, 8074, 8084","7433, 8009, 8004","$0.00","The Software Environment for Integrated Seismic Modeling (SEISM) Project of the Southern California Earthquake Center (SCEC) will develop advanced earthquake simulation software capable of using high-performance computing to produce new information about earthquakes and the hazards they present. SCEC's SEISM project is developing an integrated, sustainable community software framework for earthquake system science to serve diverse communities of earthquake scientists and engineers, computer scientists, and at-risk stakeholders. The SEISM project is a collaboration among several diverse user communities with shared interests in reducing seismic risk and enhancing seismic resilience. SCEC SEISM researchers are addressing scientific problems that limit the accuracy and scale in current numerical representations of earthquake processes. SEISM computational improvements in seismic hazard calculations will benefit earthquake system science worldwide. The SCEC SEISM project will educate a diverse STEM workforce from the undergraduate to early-career level, and it will cross-train scientists and engineers in a challenging high-performance environment. As one application of SEISM, the researchers will develop new simulations for the Great California ShakeOut, which is engaging millions of people in earthquake preparedness exercises.<br/><br/>Earthquake simulations at the spatiotemporal scales required for probabilistic seismic hazard analysis present some of the toughest computational challenges in geoscience, requiring extreme-scale computing. The Southern California Earthquake Center is creating a Software Environment for Integrated Seismic Modeling (SEISM) that will provide the extreme-scale simulation capability needed to transform probabilistic seismic hazard analysis into a physics-based science. This project will advance SEISM through a user-driven research and development agenda that will push validated SEISM capabilities to higher seismic frequencies and towards extreme-scale computing. It will develop an integrated, sustainable community software framework for earthquake system science to serve diverse communities of earthquake scientists and engineers, computer scientists and at-risk stakeholders. A new SEISM-T framework will support both in-situ and post-hoc data processing to make efficient use of available heterogeneous architectures. The main goal of the project is to increase the 4D outer-scale/inner-scale ratio of simulations at constant time-to-solution by two orders of magnitude above current capabilities. The software development plan will use an agile process of test-driven development, continuous software integration, automated acceptance test suites for each application, frequent software releases, and attention to user feedback. The researchers will take advantage of the SCEC Implementation Interface to develop a dialog among user communities regarding the application of SEISM to the reduction of seismic risk and enhancement of seismic resilience. This research will address fundamental scientific problems that limit the accuracy and scale range in current numerical representations of earthquake processes, which will benefit earthquake system science worldwide. This project will educate a diverse STEM workforce from the undergraduate to early-career level, and it will cross-train scientists and engineers in a challenging high-performance environment. As one application of SEISM, the project team will develop new simulations for the Great California ShakeOut, which is engaging millions of people in earthquake preparedness exercises."
"1550281","SI2-SSI: Collaborative Research: ENKI: Software infrastructure that ENables Knowledge Integration for Modelling Coupled Geochemical and Geodynamical Processes","ACI","Software Institutes, EarthCube","09/01/2016","08/19/2016","Peter Fox","NY","Rensselaer Polytechnic Institute","Standard Grant","Vipin Chaudhary","08/31/2019","$450,001.00","","foxp@rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","CSE","8004, 8074","7433, 8004","$0.00","Earth scientists seek to understand the mechanisms of planetary evolution from a process perspective in order to promote the progress of science. They model the chemistry of melting of the interiors of planets as a result of heat flow within the body. They calculate the flows of energy and mass from the interior to the surface. They model the interaction of fluids and rocks, which drives chemical weathering and the formation of ore deposits. They seek to understand the synthesis and stabilities of organic compounds and their economic and biological roles. They study the interactions of atmosphere, oceans, biosphere and land as a dynamically coupled evolving chemical system. To achieve this level of understanding of planetary evolution, Earth scientists use software tools that encode two fundamentally different types of models: (1) thermodynamic models of naturally occurring materials, and (2) models of transport that track physical flows of both fluids and solids. Much of the fundamental science of planetary evolution lies in understanding coupled thermodynamic and transport models. This grant funds development of a software infrastructure that supports this coupled modeling of the chemical evolution of planetary bodies. It is their aim to establish an essential and active community resource that will engage a large number of researchers, especially early career scientists, in the exercise of model building and customization. <br/><br/>This is a project to create ENKI, a collaborative model configuration and testing portal that will transform research and education in the fields of geochemistry, petrology and geophysics. ENKI will provide software tools in computational thermodynamics and fluid dynamics. It will support development and access to thermochemical models of Earth materials, and establish a standard infrastructure of web services and libraries that permit these models to be integrated into fluid dynamical transport codes. This infrastructure will allow scientific questions to be answered by quantitative simulations that are presently difficult to impossible because of the lack of interoperable software frameworks. ENKI, via the adoption of state-of-the-art model interfacing (OpenMI) and deployment environments (HubZero), will modernize how thermodynamic and fluid dynamic models are used by the Earth science community in five fundamental ways: (1) provenance tracking will enable automatic documentation of model development and execution workflows, (2) new tools will assist users in updating thermochemical models as new data become available, with the ability to merge these data and models into existing repositories and frameworks, (3) automated code generation will eliminate the need for users to manually code web services and library modules, (4) visualization tools and standard test suites will facilitate validation of model outcomes against observational data, (5) collaborative groups will be able to share and archive models and modeling workflows with associated provenance for publication. With these tools we seek to transform the large community of model users, who currently depend on a small group of dedicated and experienced researchers for model development and maintenance, into an empowered ensemble of model developers who take ownership of the process and bring their own expertise, intuition and perspective to shaping the software tools they use in daily research. ENKI development will be community driven. Participation of a dedicated and diverse group of early career professionals will guide us in user interface development - insuring portal capabilities are responsive to user needs, and in development of a rich set of documentation, tutorials and examples. All software associated with this project will be released as open source."
"1550337","SI2-SSI: Collaborative Research: ENKI: Software infrastructure that ENables Knowledge Integration for Modeling Coupled Geochemical and Geodynamical Processes","ACI","Software Institutes, EarthCube","09/01/2016","08/19/2016","Marc Spiegelman","NY","Columbia University","Standard Grant","Vipin Chaudhary","08/31/2019","$245,093.00","","mspieg@ldeo.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","8004, 8074","7433, 8004, 8009","$0.00","Earth scientists seek to understand the mechanisms of planetary evolution from a process perspective in order to promote the progress of science. They model the chemistry of melting of the interiors of planets as a result of heat flow within the body. They calculate the flows of energy and mass from the interior to the surface. They model the interaction of fluids and rocks, which drives chemical weathering and the formation of ore deposits. They seek to understand the synthesis and stabilities of organic compounds and their economic and biological roles. They study the interactions of atmosphere, oceans, biosphere and land as a dynamically coupled evolving chemical system. To achieve this level of understanding of planetary evolution, Earth scientists use software tools that encode two fundamentally different types of models: (1) thermodynamic models of naturally occurring materials, and (2) models of transport that track physical flows of both fluids and solids. Much of the fundamental science of planetary evolution lies in understanding coupled thermodynamic and transport models. This grant funds development of a software infrastructure that supports this coupled modeling of the chemical evolution of planetary bodies. It is their aim to establish an essential and active community resource that will engage a large number of researchers, especially early career scientists, in the exercise of model building and customization. <br/><br/>This is a project to create ENKI, a collaborative model configuration and testing portal that will transform research and education in the fields of geochemistry, petrology and geophysics. ENKI will provide software tools in computational thermodynamics and fluid dynamics. It will support development and access to thermochemical models of Earth materials, and establish a standard infrastructure of web services and libraries that permit these models to be integrated into fluid dynamical transport codes. This infrastructure will allow scientific questions to be answered by quantitative simulations that are presently difficult to impossible because of the lack of interoperable software frameworks. ENKI, via the adoption of state-of-the-art model interfacing (OpenMI) and deployment environments (HubZero), will modernize how thermodynamic and fluid dynamic models are used by the Earth science community in five fundamental ways: (1) provenance tracking will enable automatic documentation of model development and execution workflows, (2) new tools will assist users in updating thermochemical models as new data become available, with the ability to merge these data and models into existing repositories and frameworks, (3) automated code generation will eliminate the need for users to manually code web services and library modules, (4) visualization tools and standard test suites will facilitate validation of model outcomes against observational data, (5) collaborative groups will be able to share and archive models and modeling workflows with associated provenance for publication. With these tools we seek to transform the large community of model users, who currently depend on a small group of dedicated and experienced researchers for model development and maintenance, into an empowered ensemble of model developers who take ownership of the process and bring their own expertise, intuition and perspective to shaping the software tools they use in daily research. ENKI development will be community driven. Participation of a dedicated and diverse group of early career professionals will guide us in user interface development - insuring portal capabilities are responsive to user needs, and in development of a rich set of documentation, tutorials and examples. All software associated with this project will be released as open source."
"0743429","Semantic Enhancements for Ecological Data Management","DBI","ADVANCES IN BIO INFORMATICS","08/01/2008","08/28/2013","Matthew Jones","CA","University of California-Santa Barbara","Standard Grant","Peter H. McCartney","07/31/2014","$599,999.00","Joshua Madin, Mark Schildhauer, Margaret O'Brien, Shawn Bowers","jones@nceas.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","BIO","1165","1165, 9183, 9184, BIOT","$0.00","The University of California at Santa Barbara is awarded a grant to address semantic data heterogeneity in ecology by developing and deploying innovative software services that use ontologies and automated reasoning. Ontology-based searches will allow scientists to find data using familiar and meaningful scientific terms, but with better precision and recall than is possible with text-based searches available today. The Morpho and Metacat data-management tools, initially developed by the Knowledge Network for Biocomplexity, will be extended to support semantic annotations, semantic queries, and sensible data summarization. These tools will provide an open, interoperable semantic software framework. The broader ecological and informatics community will contribute use cases, usability requirements, and feedback on the proposed additions through workshops at the National Center for Ecological Analysis and Synthesis and the Long Term Ecological Research Network. Improving and extending the Morpho and Metacat software systems will benefit the hundreds of ecological field stations in the US and abroad that currently utilize this software for data archiving and discovery. These new semantic software capabilities and improved usability of existing tools will result in more scalable and efficient data synthesis, thereby allowing scientists, students, and educators to better understand and manage complex systems and human-induced global problems. The project will be a collaborative effort with the University of California at Davis."
"1440095","Collaborative Proposal: ATREX - integrated open source data analysis software for mineral and environmental sciences","EAR","CI REUSE, EarthCube","09/01/2014","09/03/2014","Lars Ehm","NY","SUNY at Stony Brook","Standard Grant","Eva E. Zanzerkia","08/31/2017","$128,804.00","","lars.ehm@stonybrook.edu","WEST 5510 FRK MEL LIB","Stony Brook","NY","117940001","6316329949","GEO","6892, 8074","7433","$0.00","Synchrotron radiation user facilities are critical resourcces which enable state-of-the-art research and training in mineralogy, mineral physics and environmental science. Access to these facilties is very competitive and time allocated for experiments is constrained. The most popular and fundamental type of experiment is X-ray diffraction, which produces information on crystal structure, symmetry, chemical bonding, composition and density of minerals and other crystalline solids. Modern synchrotron-based diffraction experiments are typically conducted with the use of area detectors, in which case the data is recorded as digital diffraction images. Technology used in synchrotron experiments evolves rapidly increasing the speed of the data collection and producing massive volumes of experimental data, posing new serious challenges for data analysis. The experiments are often decision-driven, and require at least partial real time data interpretation to guide the experimenter. Software offering such real time analysis capabilities is currently not available. This proposal is a collaborative effort to provide this scientific community with easily accessible tools and training opportunities for using these codes.<br/><br/>This project focuses on a combination of novel tools for diffraction-based synchrotron research in Earth and environmental sciences including: (IM1) New capabilities for structure determination of unknown phases and identification of known phases in natural and synthetic samples; (IM2) Opening new possibilities for real time analysis in studies of solid state dynamic processes; (IM3) Robust Bayesian analysis of outliers, uncertainties and missing data; and (IM4) Creation of new free advanced tools for utilizing the available mineralogical database in synchrotron research. Utilizing a combination of existing, well-tested and widely used software components developed in the Interactive Data Language , Python, the project creates a new integrated multiplatform, open-source Python software package ATREX (Advanced Tools for Research in Extreme Xtallography), with unique capabilities to process diffraction image data from samples in all forms from glasses and melts, bulk powders, though coarse multi grains, to single crystals, which will support new data types produced by novel ultrafast X-ray imaging detectors, offer extensive automated serial processing capabilities for massive data sets and will allow real time data analysis for time-constrained decision-driven synchrotron experiments. ATREX will include database access capabilities utilizing the free American Mineralogist Crystal Structure Database."
"1546351","BIGDATA: Collaborative Research: IA: Quantifying Plankton Diversity with Taxonomy and Attribute Based Classifiers of Underwater Microscope Images","IIS","ADVANCES IN BIO INFORMATICS, BIOLOGICAL OCEANOGRAPHY, EarthCube, Big Data Science &Engineering","10/01/2016","09/14/2016","Jules Jaffe","CA","University of California-San Diego Scripps Inst of Oceanography","Standard Grant","Elizabeth R. Blood","09/30/2019","$916,113.00","Peter Franks","jjaffe@ucsd.edu","8602 La Jolla Shores Dr","LA JOLLA","CA","920930210","8585341293","CSE","1165, 1650, 8074, 8083","7433, 8083","$0.00","Plankton play an essential role in the global ecosystem, forming the base of marine food webs, linking the atmosphere to the deep ocean, and regulating a myriad of ecologically and climatologically important processes. Despite their importance, however, the technology to assess abundances and distributions of plankton has been limited. Changes in abundances of individual species are particularly poorly resolved; this includes the harmful algal blooms that have profound economic, societal, and ecosystem effects in many coastal systems. Traditional tools such as nets and bottles can destroy fragile organisms during sampling. Underwater microscopes, on the other hand, allow observation of the organisms undisturbed, and in their natural setting. New underwater microscopes are generating many thousands of high-resolution images of individual plankton each day. Before these images can be used for scientific analyses, the imaged organisms must be identified and classified. However, the vast number of images generated by such microscopes has led to a serious bottleneck: identification and classification of the images takes an impossibly long time for individuals to accomplish. Fortunately, advances in computer vision science have shown great promise in accurately performing such classification tasks. The main goal of this award is to explore and develop computer vision approaches for plankton image classification. A team of instrumentation specialists, an ocean ecologist, and a computer scientist, including two graduate students and one post doctoral student, will formulate, implement, and test methods to advance the goal of efficient and accurate automated plankton image classification. The advances made in this award will enable both improved classification algorithms in computer science, and vast new data streams for plankton ecology.<br/><br/>Plankton form the base of marine food webs, link the atmosphere to the deep ocean, and regulate global biogeochemical cycles. Plankton are often studied either through bulk measures, or by manual enumeration of individual taxa. Novel underwater microscope systems such as the Scripps Plankton Camera System (SPCS) are generating tens of thousands of images of individual plankton daily. However, without accurate annotation of the images, the potential science is limited. This project will explore the use of many-layer, deep Convolutional Neural Nets (CNN) as automated computer recognition methods; these techniques hold promise for classifying the nearly one trillion underwater microscope images that have been collected by a variety of research groups around the globe. The primary source of images will be a pair of microscopes that have been operating for 2 years from the Scripps Inst. of Oceanography's pier, yielding 200 million regions of interest. The project will build a large data base of training sets using a novel approach: a bench-top imaging system that is capable of rapidly producing thousands of annotated images showing organisms in all orientations and configurations identical to that in the field. Based on these automatically collected training sets, and hand annotation of in situ images from experts, a deep (many layer) CNN will embed taxonomic and attribute constraints, and will be used to classify the organisms imaged. With success, this massive, growing, taxonomically classified dataset will enable unprecedented, transformative, taxon-specific explorations of the dynamics of the planktonic ecosystem on time scales from hours to decades."
"1450409","Collaborative Research: SI2-SSI: Landlab: A Flexible, Open-Source Modeling Framework for Earth-Surface Dynamics","ACI","GEOMORPHOLOGY & LAND USE DYNAM, Software Institutes, EarthCube","08/01/2015","07/14/2015","Gregory Tucker","CO","University of Colorado at Boulder","Standard Grant","Rajiv Ramnath","07/31/2020","$789,777.00","Daniel Hobley","gtucker@cires.colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","CSE","7458, 8004, 8074","7433, 8009","$0.00","Earth scientists discover and predict the behavior of the natural world in part through the use of computer models. Models are used to study a wide range of phenomena, such as soil erosion, flooding, plant growth, landslide occurrence, and many other processes. Models can be used to develop scientific understanding by comparing model calculations with the real world. They can also be used to make predictions about how nature will behave under certain conditions. In the areas of geosciences that deal with the earth's surface, one bottleneck in the development and use of models is the effort required to build, test, and debug the necessary software. This project contributes to scientific research and discovery by creating open source software tools that scientists can use to more efficiently create, modify, or combine computer models that represent portions of earth's surface and the processes occurring thereon. The project combines software development with user training and web-based resources, so that the products will be openly accessible, well documented, and widely disseminated within the relevant scientific communities. The project also contributes to K-12, undergraduate, and graduate-level education in computational modeling and earth-surface processes.<br/><br/>This project catalyzes research in earth-surface dynamics by developing a software framework that enables rapid creation, refinement, and reuse of two-dimensional (2D) numerical models. The phrase earth-surface dynamics refers to a remarkably diverse group of science and engineering fields that deal with our planet's surface and near-surface environment: its processes, its management, and its responses to natural and human-made perturbations. Scientists who want to use an earth-surface model often build their own unique model from the ground up, re-coding the basic building blocks of their model rather than taking advantage of codes that have already been written. Whereas the end result may be novel software programs, many person-hours are lost rewriting existing code, and the resulting software is often idiosyncratic, poorly documented, and unable to interact with other software programs in the same scientific community and beyond, leading to lost opportunities for exploring an even wider array of scientific questions than those that can be addressed using a single model. The Landlab model framework seeks to eliminate these redundancies and lost opportunities, and simultaneously lower the bar for entry into numerical modeling, by creating a user- and developer-friendly software library that provides scientists with the fundamental building blocks needed for modeling earth-surface dynamics. The framework takes advantage of the fact that nearly all surface-dynamics models share a set of common software elements, despite the wide range of processes and scales that they encompass. Providing these elements in the context of a popular scientific programming environment, with strong user support and community engagement, contributes to accelerating progress in the diverse sciences of the earth's surface.<br/><br/>The Landlab modeling framework is designed so that grid creation, data storage, and sharing of data among process components is done for the user. The framework is generic enough so that the coupling of two process components, whether they are squarely within a geoscience subdiscipline, or they cross subdisciplines, is the same. This architecture makes it easy to explore a wide range of questions in the geosciences without the need for much coding. Further, the model code is primarily written in Python, a language that is relatively easy for casual programmers to learn. Because of these attributes, the Landlab modeling framework has the potential to add computational modeling to the toolbox of a wide array of geoscientists, and to clear a path for trans-disciplinary earth-surface modeling that explores societally relevant topics, such as land-cover changes in response to climate change, as well as modeling of topics that currently require the coupling of sophisticated but harder-to-use models, such as sediment source-to-sink dynamics. The project will generate several proof-of-concept studies that are interesting in their own right, and demonstrate the capabilities of the modeling framework. Community engagement is fostered by presenting clinics and demonstrations at professional venues aimed at hydrologists, sedimentologists, critical zone scientists, and the broader earth and environmental sciences community. The team also supports visits by individual scientists for on-site training beyond these clinics. Input/output tools allow compatibility with data from relevant NSF-supported research. The project supports four graduate students and three postdoctoral researchers, and also includes modeling workshops for fifth to seventh grade girls in a community that has a greater than 50% minority population."
"1245076","COLLABORATIVE RESEARCH: From Data to Users: A Prototype Open Modeling Framework","EAR","EarthCube","07/15/2012","07/20/2012","Richard Hooper","MA","Consortium of Universities for the Advancement of Hydrologic Sci","Standard Grant","Barbara L. Ransom","06/30/2014","$15,324.00","","rhooper@cuahsi.org","196 Boston Avenue","Medford","MA","021554255","3392215400","GEO","8074","7433, 0000, 7916, OTHR","$0.00","Because Earth is a complex coupled interacting system, where no one element is independent of any other, there are both pressing scientific and societal needs to improve our understanding how various physical, biological, and hydrological processes interact in surface Earth systems. This requires the development of new and increasingly more sophisticated ways of mathematically describing these systems and improvements in software and user interfaces that will dramatically enhance our ability to simulate these systems to improve the accuracy and reliability of model predictions of weather, floods, droughts, and climate variability. Such improved models will allow researchers to make better use of available data across disciplines and improve theory and algorithms that are essential to understanding Earth system behavior. Unfortunately, at present there is significant overhead of time and effort needed for discovering, accessing, understanding, and preparing data required to populate these models, as well as long learning lead times on how to use presently available models, owing to their complexity. This research overcomes some of these limitations by developing an innovative open modeling framework that can integrate data and models easily and is easy to use so that not only the research community and operational professionals can use it, but also policy makers and other interested parties. This EAGER award allows the construction of a prototype open meta-modeling framework that significantly reduces the time and effort on the part of users in the preparatory work for data and model comparisons, model testing and validations, for making fundamental knowledge discoveries in surface and ground water hydrological systems. In this framework, components/modules interact via user-configured open interfaces that allow the addition and integration of hydrological models and data sources using a common meta-level architecture and scientific workflows. The proposed prototype is based on a recently completed modeling framework, HS-NWSRFS (Hydro-information System for improving the National Weather Service River Forecast System). It represents a collaboration between investigators from three institutions, NASA, and NWS Ohio River Forecast Center (OHRFC). The funded effort will significantly expand the present code into an open community framework prototype. Broader impacts of the work include interagency collaboration, improved hydrological forecasting for rivers, and support of a PI whose gender is under-represented in the sciences."
"0949446","Geoinformatics: Facility Support: Computational Infrastructure for Geodynamics","EAR","GEOPHYSICS, CONTINENTAL DYNAMICS PROGRAM, CI REUSE, EAR, GEOINFORMATICS, EarthCube","07/01/2010","06/28/2016","Louise Kellogg","CA","University of California-Davis","Cooperative Agreement","Robin Reichlin","06/30/2017","$7,724,260.00","L. Ridgway Scott","kellogg@ucdavis.edu","OR/Sponsored Programs","Davis","CA","956186134","5307547700","GEO","1574, 1581, 6892, 6898, 7255, 8074","7433, 1031","$0.00","The Computational Infrastructure of Geodynamics (CIG) will develop, support and disseminate community-accessible software for the greater geodynamics community from model developers to the broad spectrum of end-users. Software will support a tremendous variety of geodynamic research from mantle and core dynamics, to crustal and earthquake dynamics, to magma migration and seismology. To be successful, the CIG will develop and maintain a high level of community participation across this research spectrum to ensure:<br/>? Reusable, well-documented geodynamics software that can be demonstrated to be keeping pace with developments in hardware.<br/>? Basic software building blocks from which state-of-the-art modeling codes could be quickly assembled;<br/>? Extension of existing software frameworks to interlink multiple codes and data through a superstructure layer;<br/>? Strategic partnerships with the larger world of computational science and geoinformatics to ensure ?best practices? community-specific tool kits for scientific computations in solid-Earth sciences;<br/>? Specialized training and workshops for both the geodynamics and larger Earth Science communities; and<br/>? Hardware resources sufficient to support and facilitate software development and community use."
"1465216","Feedbacks between Vegetation, Aerosol and Cloud Processes Using Observations and a Unified Regional Climate Model","AGS","PHYSICAL & DYNAMIC METEOROLOGY, EarthCube","09/15/2015","08/08/2016","Lixin Lu","CO","Colorado State University","Continuing grant","Edward L. Bensman","08/31/2018","$435,415.00","Stephen Saleeby","lixin@cira.colostate.edu","601 S Howes St","Fort Collins","CO","805232002","9704916355","GEO","1525, 8074","4444, 7433","$0.00","The impacts of clouds and aerosols on terrestrial carbon and water cycles and the resultant feedbacks to atmospheric processes are core in understanding land-atmosphere coupling. This project will advance our understanding of vegetation-CO2-aerosol-cloud interactions, and improve the representation of CO2- and aerosol- induced feedbacks within a regional-scale modeling system. This study will use outreach to broaden K-12 education and the inform the public on these important interactions to help us better understand the earth's climate system. <br/><br/>This study will merge the existing CSU-RAMS coupled biosphere-atmosphere modeling system (SiB-RAMS) with the cloud-resolving Aerosol-RAMS (that includes direct and indirect effects) to form an integrated, process-based Vegetation-Aerosol-Cloud modeling system (VAC-RAMS). This will allow us to better understand spatial and temporal variability in land surface fluxes of energy, water, and CO2, induced by clouds, aerosols and cloud-aerosol interactions. The study will also identify ecosystem feedbacks that are critical to cloud-aerosol interactions and quantify these feedbacks using VAC-RAMS and observations from a 2007 field campaign. This will allow the investigators to assess the importance of aerosol forcing on clouds through biophysical and biogeochemical pathways."
"1315956","Infrastructure for Broadening Participation in STEM (IBP-STEM)","EAR","GLOB LEARN & OBSER TO BEN ENVI, RSCH EXPER FOR UNDERGRAD SITES, SPECIAL PROGRAMS IN ASTRONOMY, INFRASTRUCTURE PROGRAM, AGEP, EDUCATION AND HUMAN RESOURCES, EDUCATION/HUMAN RESOURCES,OCE, Antarctic Education, POSTDOCTORAL FELLOWSHIPS, EarthCube, Integrative Activities in Phys, EXP PROG TO STIM COMP RES","09/01/2013","04/07/2016","Ashanti Johnson","ME","Institute for Broadening Participation","Continuing grant","Lina C. Patino","08/31/2017","$1,299,990.00","","ajohnson@ibparticipation.org","P.O. Box 607","Damariscotta","ME","045430607","2075635929","GEO","1053, 1139, 1219, 1260, 1515, 1575, 1690, 5294, 7137, 8074, 9134, 9150","7433, 9150","$0.00","The underlying mission of the Infrastructure for Broadening Participation in STEM (IBP-STEM) initiative is to increase diversity in the Science, Technology, Engineering and Mathematics (STEM) workforce. The Institute for Broadening Participation (IBP) operates on a model of targeted activities supported by strategic infrastructure to support underrepresented students in their efforts to seek and successfully apply to research, funding, mentoring, and professional development opportunities, and succeed in their chosen academic and career pathways; assist faculty and administrators in their efforts to support and mentor students, build partnerships, and contribute to the pool of best practices; and grow diversity awareness and cultural competency in programs, departments, and institutions. IBP's four-pronged approach to broadening participation and increasing diversity in STEM includes: (1) Catalyzing partnerships to cultivate a community of practice and culture of diversity, reduce isolation among diversity practitioners and increase information sharing; (2) Extensive face-to-face and virtual outreach to draw constituents to the resources available via IBP that support students and faculty through the entire STEM pathway; (3) Creating and maintaining strategic web resources, open to all members of the STEM academy nationally, to make resources and information on programs, best practices, and references easily available and accessible; and (4) Synthesizing information to compile and translate research and best practices into materials and resources that are engaging, usable, and directly relevant to a broad constituency of STEM faculty, administrators, program staff, and students."
"1245171","Collaborative Research: From Data to Users: A Prototype Open Modeling Framework","EAR","EarthCube","07/15/2012","07/20/2012","Yao Liang","IN","Indiana University","Standard Grant","Barbara L. Ransom","06/30/2014","$88,495.00","","yliang@cs.iupui.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","GEO","8074","7433, 0000, 7916, OTHR","$0.00","Because Earth is a complex coupled interacting system, where no one element is independent of any other, there are both pressing scientific and societal needs to improve our understanding how various physical, biological, and hydrological processes interact in surface Earth systems. This requires the development of new and increasingly more sophisticated ways of mathematically describing these systems and improvements in software and user interfaces that will dramatically enhance our ability to simulate these systems to improve the accuracy and reliability of model predictions of weather, floods, droughts, and climate variability. Such improved models will allow researchers to make better use of available data across disciplines and improve theory and algorithms that are essential to understanding Earth system behavior. Unfortunately, at present there is significant overhead of time and effort needed for discovering, accessing, understanding, and preparing data required to populate these models, as well as long learning lead times on how to use presently available models, owing to their complexity. This research overcomes some of these limitations by developing an innovative open modeling framework that can integrate data and models easily and is easy to use so that not only the research community and operational professionals can use it, but also policy makers and other interested parties. This EAGER award allows the construction of a prototype open meta-modeling framework that significantly reduces the time and effort on the part of users in the preparatory work for data and model comparisons, model testing and validations, for making fundamental knowledge discoveries in surface and ground water hydrological systems. In this framework, components/modules interact via user-configured open interfaces that allow the addition and integration of hydrological models and data sources using a common meta-level architecture and scientific workflows. The proposed prototype is based on a recently completed modeling framework, HS-NWSRFS (Hydro-information System for improving the National Weather Service River Forecast System). It represents a collaboration between investigators from three institutions, NASA, and NWS Ohio River Forecast Center (OHRFC). The funded effort will significantly expand the present code into an open community framework prototype. Broader impacts of the work include interagency collaboration, improved hydrological forecasting for rivers, and support of a PI whose gender is under-represented in the sciences."
"0951576","DMUU: Center for Robust Decision Making on Climate and Energy Policy","SES","CCRI-DEC MAKING UNDER UNCERTAI, EarthCube, CROSS-DIRECTORATE ACTIV PROGR","09/15/2010","08/25/2014","Ian Foster","IL","University of Chicago","Cooperative Agreement","Cheryl L. Eavey","08/31/2016","$6,054,994.00","Kenneth Judd, Lars Hansen, Todd Munson, Elisabeth Moyer","foster@uchicago.edu","5801 South Ellis Avenue","Chicago","IL","606375418","7737028669","SBE","7264, 8074, 1397","7264, 7322, 7979, 9278, EGCH, 7433","$0.00","As additional governments are acknowledging the existence of climate change, many are systematically evaluating policy actions to reduce greenhouse gas emissions. Simultaneously, various groups like utilities, private-sector firms, and state and local governments are estimating the potential costs related to mitigation, adaption, or damage and the potential benefits of climate change and alternative policies. All of these decisions collectively will have economic impacts measuring into the trillions of dollars. Decisions of such magnitude should be based on the best possible analysis tools. Such tools inevitably must be based on computational models because of the complexity of the system of systems that need to be analyzed to project possible future states, identify potential unexpected consequences, and understand sensitivity to uncertainty. This interdisciplinary collaborative group will develop and disseminate tools to help individuals and organizations make more informed decisions relating both to short-term economic dislocations induced by climate policies and to long-term consequences of climate change. The group's primary product will be CIM-EARTH, a powerful and flexible framework of model components that can be used to help answer questions across a wide range of policy analyses. At the core of the CIM-EARTH framework will be an open-source, dynamic, general equilibrium model. The architecture of this framework will leverage high-performance computing and numerical methods that enable the evaluation of far more detailed models than existing code. The group will focus on enhanced representation of key energy producing and consuming sectors and on dynamic processes, such as capital investment and technology development. Another key component of the group's work will be the characterization of multiple types of uncertainty inherent in any complex system. CIM-EARTH will be developed in the newly created Center for Robust Decision Making on Climate and Energy Policy (DMCEP), which will be staffed by experts in economics, energy technologies, energy systems, climate modeling, and computational science who represent multiple institutions and countries.<br/><br/>Robust decision-making research is critical if policymakers are to fully understand the factors to be weighed in policy design and choice. While there are existing models that provide some guidance, they have shortcomings that limit their practical utility. This group will produce next-generation computational models for analyzing complex system of systems, with specific emphasis placed on advances in model components that represent economic systems. CIM-EARTH is expected to create a new standard for open-source modeling that encourages the participation of a community users and contributors. In addition, by incorporating recent advances in computer architecture, numerical methods, and economic modeling, CIM-EARTH will enhance methodologies that will be of tremendous value to other computational models with similar complexity. This collaborative group project is supported by the NSF Directorate for Social, Behavioral, and Economic Sciences through its Decision Making Under Uncertainty (DMUU) competition."
"1245067","Collaborative Research: From Data to Users: A Prototype Open Modeling Framework","EAR","EarthCube","07/15/2012","07/20/2012","Xu Liang","PA","University of Pittsburgh","Standard Grant","Barbara L. Ransom","06/30/2014","$97,487.00","","xuliang@pitt.edu","University Club","Pittsburgh","PA","152132303","4126247400","GEO","8074","7433, 0000, 7916, OTHR","$0.00","Because Earth is a complex coupled interacting system, where no one element is independent of any other, there are both pressing scientific and societal needs to improve our understanding how various physical, biological, and hydrological processes interact in surface Earth systems. This requires the development of new and increasingly more sophisticated ways of mathematically describing these systems and improvements in software and user interfaces that will dramatically enhance our ability to simulate these systems to improve the accuracy and reliability of model predictions of weather, floods, droughts, and climate variability. Such improved models will allow researchers to make better use of available data across disciplines and improve theory and algorithms that are essential to understanding Earth system behavior. Unfortunately, at present there is significant overhead of time and effort needed for discovering, accessing, understanding, and preparing data required to populate these models, as well as long learning lead times on how to use presently available models, owing to their complexity. This research overcomes some of these limitations by developing an innovative open modeling framework that can integrate data and models easily and is easy to use so that not only the research community and operational professionals can use it, but also policy makers and other interested parties. This EAGER award allows the construction of a prototype open meta-modeling framework that significantly reduces the time and effort on the part of users in the preparatory work for data and model comparisons, model testing and validations, for making fundamental knowledge discoveries in surface and ground water hydrological systems. In this framework, components/modules interact via user-configured open interfaces that allow the addition and integration of hydrological models and data sources using a common meta-level architecture and scientific workflows. The proposed prototype is based on a recently completed modeling framework, HS-NWSRFS (Hydro-information System for improving the National Weather Service River Forecast System). It represents a collaboration between investigators from three institutions, NASA, and NWS Ohio River Forecast Center (OHRFC). The funded effort will significantly expand the present code into an open community framework prototype. Broader impacts of the work include interagency collaboration, improved hydrological forecasting for rivers, and support of a PI whose gender is under-represented in the sciences."
"1440638","SI2-SSE: GEM3D: Open-Source Cartesian Adaptive Complex Terrain Atmospheric Flow Solver for GPU Clusters","ACI","Software Institutes, EarthCube, PHYSICAL & DYNAMIC METEOROLOGY","10/01/2014","08/13/2014","Inanc Senocak","ID","Boise State University","Standard Grant","Rajiv Ramnath","09/30/2017","$500,000.00","Grady Wright, Donna Calhoun, Elena Sherman","senocak@boisestate.edu","1910 University Drive","boise","ID","837251135","2084261574","CSE","8004, 8074, 1525","7433, 8005, 9150","$0.00","The U.S. Government invests in leadership supercomputing facilities through several agencies to advance scientific discovery in many fronts. This project is motivated by this national commitment to supercomputing research and the increasing availability of many-core computing hardware from workstations to supercomputers. Today scientists and engineers have access to extreme-scale computing resources. However, many legacy codes do not take advantage of recent innovations in computing hardware, and there is a lack of open-source simulation science software that can effectively leverage the many-core computing paradigm. Computational fluid dynamics (CFD) solvers have advanced many fields such as aerospace engineering and atmospheric sciences. Many current open-source CFD models and numerical weather prediction models do not take full advantage of the superior compute performance of graphics processing units (GPUs). By creating an open-source community model that can execute on multi-GPU workstations and large GPU clusters, the project team expects to broaden the use of high-performance computing in fluid dynamics applications. The immediate target application is wind modeling over complex terrain, to support research and development in wind resource assessment, power forecasting, atmospheric research, and air pollution. Through this project, the PIs will continue to transfer and expand the knowledge bases in GPU computing, computational mathematics, and software engineering to new students. Skill sets that transcend traditional disciplines are highly prized by national laboratories as there is a critical shortage of workforce who can conduct scientific research using supercomputers. Students and postdoctoral researchers who are involved in this project will contribute toward this critical workforce. <br/><br/>This project brings together engineers, applied mathematicians, and computer scientists. The entire suite of software elements will be designed for GPU clusters with an MPI-CUDA implementation that overlaps computation with communications using a three-dimensional decomposition for enhanced scalability. The implementation will balance performance and further development and ownership by a broader community of academic researchers. The team will follow modern software engineering practices for concurrent applications. An adaptive mesh refinement strategy that can scale on GPU clusters will be developed. A novel projection method based on radial basis functions will impose the divergence-free constraint on a hierarchy of adaptively refined grids. Software elements will be tested using unit testing and verification techniques for concurrent programs, and against data available from benchmark numerical problems. The flow solver will include modules for the immersed boundary approach for arbitrarily complex terrain and the dynamic large-eddy simulation technique. The software implementation and syntax will be intuitive to allow contributions from a larger community. The project team expects the proposed software to help reduce modeling errors with very high resolution simulations and contribute toward a fundamental understanding of turbulent winds over complex terrain. The PIs of this project will continue their teaching efforts in Parallel Scientific Computing, Computational Mathematics, and Software Engineering. The results will be disseminated through conference presentations and via a wiki site for the open-source project. Software elements will be released under an open-source GNU General Public License."
"1339723","SI2-SSI: Collaborative Research: STORM: A Scalable Toolkit for an Open Community Supporting Near Realtime High Resolution Coastal Modeling","ACI","PHYSICAL OCEANOGRAPHY, SPECIAL PROJECTS - CISE, SPECIAL PROJECTS - CCF, Software Institutes, EarthCube","10/01/2014","08/26/2014","Richard Luettich","NC","University of North Carolina at Chapel Hill","Standard Grant","Rajiv Ramnath","09/30/2018","$759,047.00","","rick_luettich@unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","CSE","1610, 1714, 2878, 8004, 8074","7433, 8009","$0.00","The ADCIRC coastal circulation and storm surge model has a long standing track record of extremely high societal impact. It has been used to define risk (e.g., 100-yr, 500-yr coastal flood levels) for the FEMA National Flood Insurance Program in coastal states from New York to Texas, it has been used to design the multi-billion dollar Hurricane and Storm Damage Risk Reduction System around greater New Orleans and southern Louisiana by the Army Corps of Engineers, it is currently run operationally by NOAA/NWS National Center for Environmental Prediction to forecast storm surge, to name just a few of its current and recent applications. Thus there is a well-established user network in place to convert improvements in ADCIRC into significant broader impacts. The proposed research provides transformative intellectual contributions that focus on applying new parallelization schemes to enable major advances in the algorithms, implementation and utilization of the ADCIRC model. The broadening of ADCIRC to a multi-algorithmic framework and the resulting performance gains that are anticipated will help ensure ADCIRC's sustainability as a core community model for at least the next 20 years. In addition, the proposed collaboration will impact computer science by serving as a high impact use case to inform the design of new approaches to efficient scalable computing. Together, the advancements in coastal modeling and parallelization technology will make a significant contribution to the science of modeling and HPC. The results of the proposed research will be disseminated to a wider community through ongoing educational outreach activities at the participating organizations as well as through refereed conference and journal papers, and invited presentations. The involvement of graduate students and post-doctoral fellows will be crucial towards the success of this project. The PIs have a long history of training and mentoring students and post-docs in computational science and engineering, coastal engineering and marine science. The recruitment and involvement of underrepresented groups in these efforts has always been a high priority. In addition, aspects of the proposed research will be incorporated into the curricula of several courses taught by the PIs in the areas of finite element methods, scientific computation, hydrology and oceanography.<br/>The aim of this project is to broaden the ADCIRC coastal circulation and storm surge model from a successful, but somewhat static coastal modeling tool that is tied to a single solution algorithm and the MPI parallelization paradigm, to a dynamic computational platform that is comprised of multiple solution algorithms, that readily admits new solution algorithms and that is built on a transformational new parallelization scheme that will allow us to scale to at least 256k compute cores on modern high performance computing (HPC) systems. We will do this by creating a living, evolving coastal modeling framework that will continue to lead the community in merging physical science / engineering and high performance computing and we will make the framework available to the broader community as a sustainable long term solution for its coastal modeling needs. In addition we will utilize these advancements in the highly demanding coastal storm surge forecasting system that we presently operate to demonstrate both improved robustness and speed of the model solution. We expect this effort will shorten the time required to provide reliable forecasting results and improve our ability to provide highly resolved, accurate, and physically complete predictions on an unprecedented scale. Concurrently, it should enable the use of smaller resources for simulations of increased scale which improves the usability and widens the applicability of ADCIRC in a broader community. The development of tightly integrated web-oriented products like CERA (www.coastalemergency.org) will enable the wide and timely dissemination of forecast modeling results to reach a broad audience."
"1550597","SI2-SSI: Lidar Radar Open Software Environment (LROSE)","ACI","PHYSICAL & DYNAMIC METEOROLOGY, Software Institutes, EarthCube","08/01/2016","09/06/2016","Michael Bell","HI","University of Hawaii","Standard Grant","Vipin Chaudhary","07/31/2020","$2,499,996.00","Wen-Chau Lee, Michael Dixon, Gary Barnes","mmbell@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","CSE","1525, 8004, 8074","7433, 8004, 8009, 9150, 4444","$0.00","Modern radars and lidars are a diverse class of instruments, capable of detecting molecules, aerosols, birds, bats and insects, winds, moisture, clouds, and precipitation. Scientists and engineers use them to perform research into air quality and pollution, dangerous biological plumes, cloud physics, cloud extent, climate models, numerical weather prediction, road weather, aviation safety, severe convective storms, tornadoes, hurricanes, floods, and movement patterns of birds, bats and insects. Radars and lidars are critical for protecting society from high impact weather and understanding the atmosphere and biosphere, but they are complex instruments that produce copious quantities of data that pose many challenges for researchers, students, and instrument developers. This project will develop a new set of tools called the Lidar Radar Open Software Environment (LROSE) to meet these challenges and help address the 'big data' problem faced by users in the research and education communities. This project will open new avenues of scientific investigation, including data assimilation to improve weather forecasts, and help to maximize returns on NSF investments in weather and climate research by providing better software tools to researchers, students, and educators. Improving the effectiveness of NSF research will provide significant scientific and societal benefits through an improved understanding of many diverse scientific topics that are relevant to public safety, national defense, and the global economy.<br/><br/>The LROSE project will develop a 'Virtual Toolbox' with a set of software tools needed for a diverse set of scientific applications. LROSE will be packaged so that it can be run on a virtual machine (VM), either locally or in the cloud, and stocked with core algorithm modules for those typical processing steps that are well understood and documented in the peer-reviewed literature. LROSE will enable the user community to use the core toolset to develop new research modules that address the specific needs of the latest scientific research. Through the VM Toolbox and a core software framework, other developers of open-source radar software can then provide their own compatible software tools to the set. By combining the open source approach with recent developments in virtual machines and cloud computing, we will develop a system that is both highly capable and easy to run on virtually any hardware, without the complexity of a compilation environment. The LROSE project will build on existing prototypes and available software elements, while facilitating community development of new techniques and algorithms to distribute a suite of documented software modules for performing radar and lidar analysis. These modules will each implement accredited scientific methods referencing published papers. The infrastructure and modules will allow researchers to run standard procedures, thereby improving the efficiency and reproducibility of the analyses, and encourage researchers to jointly develop new scientific approaches for data analysis. The use of collaborative open source methods will lead to a suite of available algorithmic modules that will allow scientists to explore radar and lidar data in new, innovative ways. Researchers will benefit from the improved toolset for advancing understanding of weather and climate, leading to a positive outcome in the advancement of scientific knowledge and societal benefits."
"1550482","SI2-SSI: Collaborative Research: ENKI: Software Infrastructure that ENables Knowledge Integration for Modeling Coupled Geochemical and Geodynamical Processes","ACI","PETROLOGY AND GEOCHEMISTRY, Software Institutes, EarthCube","09/01/2016","08/19/2016","Mark Ghiorso","WA","OFM Research","Standard Grant","Vipin Chaudhary","08/31/2019","$734,907.00","","ghiorso@ofm-research.org","28430 NE 47th Place","Redmond","WA","980538841","4258804418","CSE","1573, 8004, 8074","7433, 8004","$0.00","Earth scientists seek to understand the mechanisms of planetary evolution from a process perspective in order to promote the progress of science. They model the chemistry of melting of the interiors of planets as a result of heat flow within the body. They calculate the flows of energy and mass from the interior to the surface. They model the interaction of fluids and rocks, which drives chemical weathering and the formation of ore deposits. They seek to understand the synthesis and stabilities of organic compounds and their economic and biological roles. They study the interactions of atmosphere, oceans, biosphere and land as a dynamically coupled evolving chemical system. To achieve this level of understanding of planetary evolution, Earth scientists use software tools that encode two fundamentally different types of models: (1) thermodynamic models of naturally occurring materials, and (2) models of transport that track physical flows of both fluids and solids. Much of the fundamental science of planetary evolution lies in understanding coupled thermodynamic and transport models. This grant funds development of a software infrastructure that supports this coupled modeling of the chemical evolution of planetary bodies. It is their aim to establish an essential and active community resource that will engage a large number of researchers, especially early career scientists, in the exercise of model building and customization. <br/><br/>This is a project to create ENKI, a collaborative model configuration and testing portal that will transform research and education in the fields of geochemistry, petrology and geophysics. ENKI will provide software tools in computational thermodynamics and fluid dynamics. It will support development and access to thermochemical models of Earth materials, and establish a standard infrastructure of web services and libraries that permit these models to be integrated into fluid dynamical transport codes. This infrastructure will allow scientific questions to be answered by quantitative simulations that are presently difficult to impossible because of the lack of interoperable software frameworks. ENKI, via the adoption of state-of-the-art model interfacing (OpenMI) and deployment environments (HubZero), will modernize how thermodynamic and fluid dynamic models are used by the Earth science community in five fundamental ways: (1) provenance tracking will enable automatic documentation of model development and execution workflows, (2) new tools will assist users in updating thermochemical models as new data become available, with the ability to merge these data and models into existing repositories and frameworks, (3) automated code generation will eliminate the need for users to manually code web services and library modules, (4) visualization tools and standard test suites will facilitate validation of model outcomes against observational data, (5) collaborative groups will be able to share and archive models and modeling workflows with associated provenance for publication. With these tools we seek to transform the large community of model users, who currently depend on a small group of dedicated and experienced researchers for model development and maintenance, into an empowered ensemble of model developers who take ownership of the process and bring their own expertise, intuition and perspective to shaping the software tools they use in daily research. ENKI development will be community driven. Participation of a dedicated and diverse group of early career professionals will guide us in user interface development - insuring portal capabilities are responsive to user needs, and in development of a rich set of documentation, tutorials and examples. All software associated with this project will be released as open source."
"1550346","SI2-SSI:Collaborative Research: ENKI: Software infrastructure that ENables Knowledge Integration for Modeling Coupled Geochemical and Geodynamical Processes","ACI","Software Institutes, EarthCube","09/01/2016","08/19/2016","Dimitri Sverjensky","MD","Johns Hopkins University","Standard Grant","Vipin Chaudhary","08/31/2019","$217,827.00","","sver@jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","CSE","8004, 8074","7433, 8004, 8009","$0.00","Earth scientists seek to understand the mechanisms of planetary evolution from a process perspective in order to promote the progress of science. They model the chemistry of melting of the interiors of planets as a result of heat flow within the body. They calculate the flows of energy and mass from the interior to the surface. They model the interaction of fluids and rocks, which drives chemical weathering and the formation of ore deposits. They seek to understand the synthesis and stabilities of organic compounds and their economic and biological roles. They study the interactions of atmosphere, oceans, biosphere and land as a dynamically coupled evolving chemical system. To achieve this level of understanding of planetary evolution, Earth scientists use software tools that encode two fundamentally different types of models: (1) thermodynamic models of naturally occurring materials, and (2) models of transport that track physical flows of both fluids and solids. Much of the fundamental science of planetary evolution lies in understanding coupled thermodynamic and transport models. This grant funds development of a software infrastructure that supports this coupled modeling of the chemical evolution of planetary bodies. It is their aim to establish an essential and active community resource that will engage a large number of researchers, especially early career scientists, in the exercise of model building and customization. <br/><br/>This is a project to create ENKI, a collaborative model configuration and testing portal that will transform research and education in the fields of geochemistry, petrology and geophysics. ENKI will provide software tools in computational thermodynamics and fluid dynamics. It will support development and access to thermochemical models of Earth materials, and establish a standard infrastructure of web services and libraries that permit these models to be integrated into fluid dynamical transport codes. This infrastructure will allow scientific questions to be answered by quantitative simulations that are presently difficult to impossible because of the lack of interoperable software frameworks. ENKI, via the adoption of state-of-the-art model interfacing (OpenMI) and deployment environments (HubZero), will modernize how thermodynamic and fluid dynamic models are used by the Earth science community in five fundamental ways: (1) provenance tracking will enable automatic documentation of model development and execution workflows, (2) new tools will assist users in updating thermochemical models as new data become available, with the ability to merge these data and models into existing repositories and frameworks, (3) automated code generation will eliminate the need for users to manually code web services and library modules, (4) visualization tools and standard test suites will facilitate validation of model outcomes against observational data, (5) collaborative groups will be able to share and archive models and modeling workflows with associated provenance for publication. With these tools we seek to transform the large community of model users, who currently depend on a small group of dedicated and experienced researchers for model development and maintenance, into an empowered ensemble of model developers who take ownership of the process and bring their own expertise, intuition and perspective to shaping the software tools they use in daily research. ENKI development will be community driven. Participation of a dedicated and diverse group of early career professionals will guide us in user interface development - insuring portal capabilities are responsive to user needs, and in development of a rich set of documentation, tutorials and examples. All software associated with this project will be released as open source."
"1443037","CIF21 DIBBs: Collaborative Research: Cyberinfrastructure for Interpreting and Archiving U-series Geochronologic Data","ACI","PALEOCLIMATE PROGRAM, PETROLOGY AND GEOCHEMISTRY, MARINE GEOLOGY AND GEOPHYSICS, DATANET, EarthCube, EXP PROG TO STIM COMP RES","09/01/2014","08/25/2014","James Bowring","SC","College of Charleston","Standard Grant","Amy Walton","08/31/2017","$579,762.00","","bowringj@cofc.edu","66 GEORGE ST","CHARLESTON","SC","294240001","8439534973","CSE","1530, 1573, 1620, 7726, 8074, 9150","4444, 7433, 8048, 9150","$0.00","Uranium-series geochronology plays a critical role in understanding the time-scales and rates of climate change, sea-level change, and volcanic activity. There are no standardized data-handling protocols or community-based open data archives for raw isotopic data and reduced results. The U-series geochronology community wants to change this and is encouraged by NSF's vision for 21st century cyberinfrastructure. In this pilot demonstration project, software engineers and geochronologists collaborate to build open-source cyberinfrastructure that standardizes and facilitates U-series data analysis, reporting, and archiving and analysis and re-processing of the vast amounts of legacy data. The project uses the NSF-funded EarthChem-Geochron data repository that archives results from many dating schemes, stimulating inter-domain sharing and discovery. This cyberinfrastructure supports teaching and training at all levels and provides non-experts access to new knowledge. <br/><br/>This collaborative effort applies modern software engineering practices to solving the cyberinfrastructure problems of the U-series geochronology community, making the calculation, archiving, access, and interpretation activities of U-series geochronology as rigorous, seamless, and simple as possible. Currently, isotopic dates from U-series data are calculated and analyzed using legacy, platform-dependent software, and dates are difficult to synthesize because they have been published with disparate decay constants and reporting norms. This pilot project includes new software to calculate, visualize, and interpret U-series dates from new and legacy data, and new schema for data archiving at Geochron.org. Importantly, this project advances the sustainability of NSF's software ecosystem by building upon the cyberinfrastructure architecture already developed for the U-Pb geochronology community under the EARTHTIME umbrella."
"1443061","CIF21 DIBBs: Systematic Data-Driven Analysis and Tools for Spatiotemporal Solar Astronomy Data","ACI","OFFICE OF MULTIDISCIPLINARY AC, , DATANET, EarthCube","11/01/2014","08/14/2014","Rafal Angryk","GA","Georgia State University Research Foundation, Inc.","Standard Grant","Amy Walton","10/31/2017","$1,499,933.00","Petrus Martens, Katharine Reeves","angryk@cs.gsu.edu","G76Dahlberg Hall 30 Courtland St","Atlanta","GA","303023999","4044133500","CSE","1253, 1798, 7726, 8074","7433, 7480, 8048","$0.00","The large quantities of data produced by modern solar telescopes provide a rich and rapidly growing opportunity for discovery. These large data sets create an unprecedented ability to observe correlations between phenomena that have previously gone unexplored. However, to harness the power of these large data sets, it is necessary to provide the solar physics and space weather communities with software tools that will rapidly and accurately catalog, explore, track and correlate solar phenomena.<br/><br/>This project develops tools for processing large volumes of spatio-temporal solar data. Initially, the team enables tracking of all solar events previously identified by an international consortium (the Feature Finding Team of the Solar Dynamics Observatory) and reported to the Heliophysics Event Knowledgebase (HEK). Next, the team develops systematic spatiotemporal characterizations of solar event types, and identifies spatiotemporal co-occurrence patterns. Throughout the project, the team disseminates the generated data, discovered patterns, and developed software tools to the community. By adding an ability to track features previously identified by an international consortium, the project has potential to advance knowledge of solar phenomena, and the impact of such phenomena on space weather."
"1633124","BIGDATA: IA: Democratizing Massive Fluid Flow Simulations via Open Numerical Laboratories and Applications to Turbulent Flow and Geophysical Modeling","OCE","PHYSICAL OCEANOGRAPHY, EarthCube, Big Data Science &Engineering","10/01/2016","09/13/2016","Charles Meneveau","MD","Johns Hopkins University","Standard Grant","Eric C. Itsweire","09/30/2019","$952,570.00","Tamer Zaki, Gregory Eyink, Randal Burns, Alexander Szalay","meneveau@jhu.edu","3400 N CHARLES ST","Baltimore","MD","212182608","4105168668","GEO","1610, 8074, 8083","4444, 7433, 8083","$0.00","Computer simulations of turbulent fluid flows are playing an increasingly vital role in engineering applications (e.g. reducing drag forces on vehicles and predicting wind turbine aerodynamic efficiency) and in geophysical sciences (e.g. describing the fate of pollutant dispersion or Lagrangian transport and mixing in the ocean). Simulations consist of discretizing and integrating the partial differential equations governing fluid flow and transport forward in time, providing solutions for physical variables (fields such as velocity and pressure) as function of time and space in the entire domain of interest. Since such simulations generate enormous amounts of data, the prevailing approach has been for researchers to analyze the data ""on the fly"" during the simulation runs while only a small subset of time-steps are stored for subsequent analysis. As a result, often large simulations of the same process must be repeated after new questions arise that were not initially obvious. Many (or even most) breakthrough concepts cannot be anticipated in advance, as they will be motivated in part by output data and must then be tested against it. As a result, there is a need for methods to store entire space-time data from such simulations. This project develops innovative tools for the efficient creation of open numerical databases that contain massive outputs from computational fluid dynamics simulations used in turbulence research and geophysical transport modeling and makes these available to the entire community. Several of the datasets to be included into the Open Numerical Laboratory will be contributed by external researchers. In addition to enhancing engineering and geophysical fluid mechanics and turbulence research, democratized access to large-scale turbulent flow simulation data will also play a crucial role in education and training for the next generation of researchers. Active learning through new educational modules that allow students to query simulation datasets in unprecedented detail will provide new educational paradigms. More broadly, the lessons learned from this project will be generalizable to many other fields where numerical simulations generate very large datasets that are difficult to access using prevailing approaches. In this way, the project will enhance the scientific and broader impacts of the US high-performance scientific computing infrastructure. <br/><br/>This project will develop innovative tools for the efficient creation of open numerical databases that contain massive outputs from computational fluid dynamics simulations used in turbulence research and geophysical transport modeling. An ingest pipeline to be developed will enable users to transfer data from file systems containing the output of their massive direct numerical simulations, build a database, and serve it to the community for open exploratory data analysis and innovative turbulence and oceanic mixing research. To date, the investigators involved in this project have built an Open Numerical Laboratory focusing on direct numerical simulations (DNS) of canonical turbulent flows, in which the entire space-time data are available to the wider research community. However, the existing datasets are few in number and databases have been created one by one, using methodologies difficult to replicate on a massive scale. Moreover, emerging Exascale simulations will potentially result in data sets of unprecedented scale (tens to hundreds of PetaBytes). Advanced computer science algorithms will be required to tackle these challenges. This project will (a) develop automated, and scalable data management algorithms to ingest, index and serve very large data sets generated by a wide range of groups, (b) explore novel algorithms using spatio-temporal subsampling combined with online interpolation with re-simulation, yielding large compression factors depending on the subsampling stride, and (c) use machine learning algorithms to identify localized regions of interest in the simulations and save these 4D domains in a database for detailed follow-up analytics. The new databases will include data from (1) the largest channel flow DNS, (2) rotating and stratified turbulence of geophysical interest, (3) a DNS of developing wall boundary layer and (4) detailed ocean circulation models with complex boundary conditions. As part of the innovative domain science applications, data sets will be used to improve turbulence models using data-assimilation concepts, study Lagrangian vortex dynamics, and explore geophysical transport in a regional general circulation model of the North Atlantic Ocean."
"1251019","BIGDATA: Small: DCM: DA: Building a Mergeable and Interactive Distributed Data Layer for Big Data Summarization Systems","IIS","EarthCube, Big Data Science &Engineering","09/15/2013","04/02/2014","Feifei Li","UT","University of Utah","Standard Grant","Almadena Y. Chtchelkanova","08/31/2017","$701,386.00","Jeff Phillips","lifeifei@cs.utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","CSE","8074, 8083","7433, 7923, 8083, 9251, 9150","$0.00","Big data today is stored in a distributed fashion across many different machines or data sources. This poses new algorithmic and system challenges to performing efficient analysis on the full data set. To address these difficulties, the PIs are building the MIDDLE (Mergeable and Interactive Distributed Data LayEr) Summarization System and deploying it on large real-world datasets. The MIDDLE system builds and maintains a special class of summaries that can be efficiently constructed and updated while still allowing fine-grained analysis on the heavy tail. Mergeable summaries can represent any data set with a guaranteed tradeoff between size and accuracy, and any two such summaries can be merged to create a new summary with the same size-accuracy tradeoff.<br/><br/>Interactive summaries can be quickly adapted to a specified query range of data while maintaining the same size-accuracy tradeoffs relative to the data in that range. This allows accurate efficient analysis to zero-in on small subsets of big data.<br/>The MIDDLE system enables different big data users to develop a wide spectrum of efficient and scalable data analytic tasks through the use of data summaries. The MIDDLE system is being evaluated and refined with the aid of domain experts. Since the prospect of data-summary-based analytics becoming a part of standard techniques in processing big data is tantalizing, this research generates broader impacts on the nation's government agencies, research institutes, education system, and high-tech industries. Our broad impacts also extend to academia and community outreach, through the design and development big data curriculum and education, and the involvement of general public in understanding and using big data through concise summaries."
"1450468","SI2-SSI Integration of Synchrotron X-Ray Analysis Software Methods into the Larch Framework","ACI","OFFICE OF MULTIDISCIPLINARY AC, GEOPHYSICS, DMR SHORT TERM SUPPORT, Software Institutes, EarthCube","10/01/2015","09/16/2015","Matthew Newville","IL","University of Chicago","Standard Grant","Rajiv Ramnath","09/30/2018","$540,969.00","","newville@cars.uchicago.edu","5801 South Ellis Avenue","Chicago","IL","606375418","7737028669","CSE","1253, 1574, 1712, 8004, 8074","7433, 7574, 8009, 9216, 8004","$0.00","The solutions to many of the outstanding problems in geology, environmental science, material science, and biology require understanding the chemical state and detailed atomic structure of the molecules and solids that make up our world. Such problems range from understanding the molecular forms of arsenic in rice, determining the chemical composition of the earths interior, and improving the performance and reducing the environmental impact of batteries that are in our laptops, cellphones, and cars. The nation's synchrotron facilities provide powerful X-ray facilities that allow researchers to study these questions by investigating the chemical makeup and crystal structure of complex, real-world materials such as plant seeds, contaminated soils, human and animal tissue, minerals and meteorites, and working batteries and catalysts. Synchrotron measurement techniques have developed very rapidly over the past few decades, and are being used by many more researchers. The ability to handle and interpret the large and complex datasets now being routinely generated at these facilities is often a significant challenge, even for experts. The work here will develop the Larch X-ray analysis framework to provide open-source software that is easy to use and specific enough to correctly interpret several categories of synchrotron X-ray data. The approach will provide tools that are flexible enough to enable researchers to explore and interpret new combinations of data easily enough to make new connections and discoveries in a wide variety of scientific areas.<br/><br/><br/>This project will integrate visualization and analysis software for multiple synchrotron X-ray techniques into the open source and extensible Larch X-ray Analysis framework. The immediate focus of the work is to support visualization and quantitative analysis of the rich and complex data from X-ray microprobes, including X-ray fluorescence imaging, fluorescence and absorption spectroscopies, and X-ray diffraction. The Larch framework already provides a suite of analysis procedures for X-ray absorption spectroscopy and fluorescence imaging, and has been designed to be readily extensible by adding plug-ins in Python, widely used in scientific computing and being embraced in the synchrotron user communities. Existing state-of-the-art analysis procedures for X-ray fluorescence, X-ray absorption, and X-ray diffraction have been identified to be integrated into the Larch framework, adapting and translating the software as needed to be compatible with the open-source Python framework. With the combination of state-of-the-art analysis methods for multiple data types, Larch will provide a single well-supported and -documented analysis package with robust, easy to use analytic methods for a range of synchrotron X-ray data. By being easily extensible, the Larch package can also accommodate methods for other synchrotron X-ray techniques."
"1450412","Collaborative Research: SI2-SSI: Landlab: A Flexible, Open-Source Modeling Framework for Earth-Surface Dynamics","ACI","GEOMORPHOLOGY & LAND USE DYNAM, Software Institutes, EarthCube","08/01/2015","07/14/2015","Erkan Istanbulluoglu","WA","University of Washington","Standard Grant","Rajiv Ramnath","07/31/2020","$676,836.00","","erkani@u.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","CSE","7458, 8004, 8074","7433, 8009","$0.00","Earth scientists discover and predict the behavior of the natural world in part through the use of computer models. Models are used to study a wide range of phenomena, such as soil erosion, flooding, plant growth, landslide occurrence, and many other processes. Models can be used to develop scientific understanding by comparing model calculations with the real world. They can also be used to make predictions about how nature will behave under certain conditions. In the areas of geosciences that deal with the earth's surface, one bottleneck in the development and use of models is the effort required to build, test, and debug the necessary software. This project contributes to scientific research and discovery by creating open source software tools that scientists can use to more efficiently create, modify, or combine computer models that represent portions of earth's surface and the processes occurring thereon. The project combines software development with user training and web-based resources, so that the products will be openly accessible, well documented, and widely disseminated within the relevant scientific communities. The project also contributes to K-12, undergraduate, and graduate-level education in computational modeling and earth-surface processes.<br/><br/>This project catalyzes research in earth-surface dynamics by developing a software framework that enables rapid creation, refinement, and reuse of two-dimensional (2D) numerical models. The phrase earth-surface dynamics refers to a remarkably diverse group of science and engineering fields that deal with our planet's surface and near-surface environment: its processes, its management, and its responses to natural and human-made perturbations. Scientists who want to use an earth-surface model often build their own unique model from the ground up, re-coding the basic building blocks of their model rather than taking advantage of codes that have already been written. Whereas the end result may be novel software programs, many person-hours are lost rewriting existing code, and the resulting software is often idiosyncratic, poorly documented, and unable to interact with other software programs in the same scientific community and beyond, leading to lost opportunities for exploring an even wider array of scientific questions than those that can be addressed using a single model. The Landlab model framework seeks to eliminate these redundancies and lost opportunities, and simultaneously lower the bar for entry into numerical modeling, by creating a user- and developer-friendly software library that provides scientists with the fundamental building blocks needed for modeling earth-surface dynamics. The framework takes advantage of the fact that nearly all surface-dynamics models share a set of common software elements, despite the wide range of processes and scales that they encompass. Providing these elements in the context of a popular scientific programming environment, with strong user support and community engagement, contributes to accelerating progress in the diverse sciences of the earth's surface.<br/><br/>The Landlab modeling framework is designed so that grid creation, data storage, and sharing of data among process components is done for the user. The framework is generic enough so that the coupling of two process components, whether they are squarely within a geoscience subdiscipline, or they cross subdisciplines, is the same. This architecture makes it easy to explore a wide range of questions in the geosciences without the need for much coding. Further, the model code is primarily written in Python, a language that is relatively easy for casual programmers to learn. Because of these attributes, the Landlab modeling framework has the potential to add computational modeling to the toolbox of a wide array of geoscientists, and to clear a path for trans-disciplinary earth-surface modeling that explores societally relevant topics, such as land-cover changes in response to climate change, as well as modeling of topics that currently require the coupling of sophisticated but harder-to-use models, such as sediment source-to-sink dynamics. The project will generate several proof-of-concept studies that are interesting in their own right, and demonstrate the capabilities of the modeling framework. Community engagement is fostered by presenting clinics and demonstrations at professional venues aimed at hydrologists, sedimentologists, critical zone scientists, and the broader earth and environmental sciences community. The team also supports visits by individual scientists for on-site training beyond these clinics. Input/output tools allow compatibility with data from relevant NSF-supported research. The project supports four graduate students and three postdoctoral researchers, and also includes modeling workshops for fifth to seventh grade girls in a community that has a greater than 50% minority population."
"1345052","Climate Informatics Workshop","IIS","INFORMATION TECHNOLOGY RESEARC, COMPUTER SYSTEMS, INFO INTEGRATION & INFORMATICS, EarthCube","09/15/2013","09/04/2013","Claire Monteleoni","DC","George Washington University","Standard Grant","Sylvia J. Spengler","08/31/2017","$90,702.00","","cmontel@gwu.edu","2121 Eye Street NW","Washington","DC","200522000","2029946255","CSE","1640, 7354, 7364, 8074","1640, 7354, 7364, 7433, 7484, 7556","$0.00","Understanding and responding to climate change is a key scientific and societal challenge of the 21st century. Recent advances in satellites and environmental sensors have made it possible to gather vast quantities of data concerning temperature, sea ice, sea level, rainfall, vegetation, etc. There is an urgent need for scientific and technical expertise for developing and effectively applying computational tools that can make use of such data to build increasingly accurate predictive models that offer insights to inform our understanding of, and response to, climate change. <br/><br/>This award supports a series of three workshops on Climate Informatics, an emerging discipline at the intersection of climate sciences and data sciences. The workshops, through a combination of tutorials that introduce climate scientists and data scientists to each other's disciplines, invited talks by established researchers in climate informatics, breakout sessions and for identifying research challenges and opportunities for interdisciplinary collaborations, serve a critically important role in building a vibrant Climate Informatics research community. The award provides support for the participation of approximately 60 to graduate students in each of the three workshops. The workshops contribute to the education and interdisciplinary training of a diverse workforce in STEM areas that span Climate Sciences and Data Sciences (including Machine Learning, Data Mining, Inference, Decision Making) as well as efforts to broaden the participation of women and other underrepresented groups in STEM research and education. Additional information about the Climate Informatics Workshop Series can be found at: https://sites.google.com/site/1stclimateinformatics/"
"1651316","Workshop: Modeling Research in the Cloud; Boulder Colorado; Spring 2017","AGS","LARS SPECIAL PROGRAMS, EarthCube","09/01/2016","08/09/2016","Mohan Ramamurthy","CO","University Corporation For Atmospheric Res","Standard Grant","Nicholas F. Anderson","08/31/2017","$49,824.00","Wei Wang, Brian Jewett, David Bromwich, Clifford Mass","mohan@ucar.edu","3090 Center Green Drive","Boulder","CO","803012252","3034971000","GEO","7790, 8074","1525, 4444, 7433, 7556, 7790","$0.00","This project is to plan, organize and host a community workshop to explore the potential for advancing ""Modeling Research in the Cloud."" The workshop, to be held in Spring 2017 at UCAR's facilities in Boulder, CO, will assemble researchers, educators, students, forecasters, and information technology (IT) professionals in academia, government and the private sector (including major cloud computing vendors). Specifically, the workshop participants will discuss the opportunities, challenges, and benefits of performing modeling research in a cloud computing environment and the means to and potential for enabling a paradigm shift in the conduct of weather and climate prediction and process studies. To achieve the workshop goals, about 30 participants from the aforementioned segments will be invited to the workshop.<br/><br/>Intellectual Merit:<br/>Cloud computing represents a fundamental change in the way IT services are developed, deployed, operated, and paid for, placing science communities in general and weather and climate prediction community in particular in the middle of a major paradigm shift. The cloud appears to be a potential avenue for researchers to gain access to significant computing resources beyond the traditional supercomputing center for end-to-end modeling studies, democratizing access to high performance computing resources, vast amounts of storage, and unprecedented access to large volumes of data.<br/><br/>Historically, the modeling community has relied mostly on high performance computing facilities (e.g., NCAR-Wyoming Supercomputing facility and XSEDE) and local computing clusters to perform their predictions. With the maturity of and significant advances in cloud computing, it has recently emerged as an alternative new paradigm for hosting and delivering a broad array of services over the Internet. The purpose of the workshop is to facilitate an in-depth discussion of the myriad aspects and formulate approaches for integrating cloud computing capabilities into the weather and climate prediction landscape, to identify atmospheric sciences communities, based on their usage patterns, needs, and resources, who would best benefit and utilize it, and discuss the significance of such integration for advancing discoveries.<br/><br/>Broader Impacts:<br/>The workshop will help the community to work toward a transformation in the conduct of atmospheric prediction studies, enabling researchers and educators to carry out their work in more innovative, efficient, and productive ways and push beyond the boundaries of their current knowledge and approaches. In addition to democratizing access to computing, the workshop has the potential for transforming the conduct of atmospheric prediction studies. Cloud computing affords additional opportunities to advance data, cyber and geospatial literacy of students, and in the process the development of the next generation workforce, by enabling authentic data- and cyber-enabled inquiries.<br/><br/>There is a compelling need for students to understand and take advantage of rapidly developing and evolving cyberinfrastructure, data-related technologies, and data-enabled modes of scientific inquiry. The workshop will engage graduate students, offering opportunities for enhancing their skills in data science, big data, cloud computing, and professional development. The results of the workshop will also be disseminated broadly through Unidata newsletters and presentations at scientific and computing conferences, including the AMS and AGU meetings."
"1540994","EarthCubeIA: Collaborative Proposal: Building Interoperable Cyberinfrastructure (CI) at the Interface between Paleogeoinformatics and Bioinformatics","ICER","EarthCube","09/01/2015","07/30/2015","Alison Smith","OH","Kent State University","Standard Grant","Eva E. Zanzerkia","08/31/2017","$78,000.00","","alisonjs@kent.edu","OFFICE OF THE COMPTROLLER","KENT","OH","442420001","3306722070","GEO","8074","7433","$0.00","Paleontologists provide data about the past distribution and diversity of life. These data are useful both to geologists, because they can help determine the age of rocks, reconstruct past environments, and constrain models of the Earth system; and to biologists interested in the evolutionary history of organisms and the behavior of ecological systems during past global changes. Currently, data about fossils are dispersed across thousands of scientific publications, and dozens of small to large databases, only some of which are publicly available via the Internet. Even publicly available databases can be difficult to access because each stores different kinds of data with different conventions, requiring researchers to individually harmonize searches and their outputs. This project brings together six paleobiological databases so that they share a single set of Internet-based commands by which researchers and the public can easily access fossil records from all of Earth history. By coordinating with other emerging efforts in geological and biological data sharing, best practices, and protocols, we ensure that data will be freely available to all, enabling new scientific syntheses and discovery, more powerful educational opportunities, and general exploration of the history of life on Earth.<br/><br/>The paleobiological sciences sit at the nexus between geosciences and the biosciences, with close interdependencies in both domains. Within the geosciences, information about the past spatiotemporal distribution of organisms, species, and assemblages of species is essential to a wide array of allied disciplines: to sedimentologists and economic geologists studying facies relationships and employing biostratigraphic controls for correlating rock strata, to structural geologists and geophysicists seeking biogeographic constraints on reconstructions of former tectonic plate positions, to paleoclimatologists extracting paleoclimatic signals from paleoecological data, and to earth system modelers seeking to understand how biospheric dynamics have shaped, and continue to shape, the history of the Earth-Life system. Within the biosciences, the fossil record is essential for understanding how contemporary ecological systems are shaped by historical legacies of slow-acting processes, for testing climate-driven models of species distribution and diversity that are being used to project the impacts of 21st century climate change, for constraining phylogenetic models of species divergence and rates of evolution, and for understanding the fundamental drivers of biodiversity (i.e. species extinctions and originations). In an era of global change, when stewarding biodiversity is an urgent societal concern, conservation biologists, global change ecologists, and earth system scientists are all looking to the past to study the behavior of the Earth-Life system during rapid transitions. Paleobiological data are currently served by a wide array of databases that vary in structure, composition, temporal scales, types of data and metadata. To conduct ?global? or holistic analyses of the paleobiological record it is necessary to retrieve data from a variety of these databases - requiring queries of each database to retrieve the types of data needed. The purpose of this project is to make six different paleobiological databases interoperable so that they can be accessed via a common Application Programming Interface (API) to query the data from these and other databases. Towards that end, five key records of North American Pleistocene lakes will be uploaded and become available through this integrative project. This project also will increase the interoperability between these paleobiological resources and contemporary databases of species distributions and diversity, enabling continuous time-series analyses (e.g., of biodiversity) from the beginning of life on earth to today. Integration of the paleobiological databases with databases of the stratigraphic record (Macrostrat) will enhance the value of both types of data. New R packages will facilitate retrieval and analysis of data from all of the databases. Finally, this proposal establishes a Paleobiological Data Consortium, consisting of leaders of cyberinfrastructure resources in the paleobiosciences and allied disciplines, with the goal of sharing best practices and protocols among the geoinformatic and bioinformatic communities."
"1443046","CIF21 DIBBs: STORM: Spatio-Temporal Online Reasoning and Management of Large Data","ACI","PHYSICAL & DYNAMIC METEOROLOGY, DATANET, EarthCube","11/01/2014","08/10/2016","Feifei Li","UT","University of Utah","Standard Grant","Amy Walton","10/31/2017","$1,173,975.00","Paul Rosen, John Horel, Jeff Phillips","lifeifei@cs.utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","CSE","1525, 7726, 8074","4444, 7433, 8048, 9150, 9251","$0.00","A fundamental challenge for many research projects is the ability to handle large quantities of heterogeneous data. Data collected from different sources and time periods can be inconsistent, or stored in different formats and data management systems. Thus, a critical step in many projects is to develop a customized query and analytical engine to translate inputs. But for each new dataset, or for each new query type or analytic task for an existing dataset, a new query interface or program must be developed, requiring significant investments of time and effort. This project will develop an automatic engine for searching large, heterogeneous data collections for weather and meteorology, particularly from instruments in the western US, in a regional network called MesoWest. <br/><br/>This project develops an automatic query and analytical engine for large, heterogeneous spatial and temporal data. This capability allows users to automatically deploy a query and analytical engine instance over their large, heterogeneous data with spatial and temporal dimensions. The system supports a simple search-box and map-like query interface that allows numerous powerful analytical queries. Techniques to make these queries robust, relevant, and highly scalable will be developed. The project also enables users to execute queries over multiple data sources simultaneously and seamlessly. The goal of the work is to dramatically simplify the management and analysis of large spatio-temporal data at different institutions, groups, and corporations."
"1053575","XSEDE: eXtreme Science and Engineering Discovery Environment","ACI","FLUID DYNAMICS, INFORMATION TECHNOLOGY RESEARC, COMPUTATIONAL PHYSICS, ETF, EQUIPMENT ACQUISITIONS, PETASCALE - TRACK 1, EarthCube","07/01/2011","06/23/2016","John Towns","IL","University of Illinois at Urbana-Champaign","Cooperative Agreement","Rudolf Eigenmann","12/31/2016","$125,628,751.00","Nancy Wilkins-Diehr, Patricia Kovatch, Ralph Roskies, Gregory Peterson, Philip Andrews, Kelly Gaither, John Boisseau","jtowns@ncsa.illinois.edu","SUITE A","CHAMPAIGN","IL","618207473","2173332187","CSE","1443, 1640, 7244, 7476, 7619, 7781, 8074","058E, 7433, 7476, 7556, 8084, 9263, 1640","$0.00","1053575<br/>Towns<br/> XSEDE: Enabling New Digital Science<br/>The eXtreme Science and Engineering Discovery Environment (XSEDE) partnership will develop an unprecedented, comprehensive advanced digital services cyberinfrastructure (CI) to enable transformative open science and engineering research and innovative training and educational programs. The goal of XSEDE is to offer users tremendous capabilities with maximum productivity, enabling them to advance and share knowledge across domains. The XSEDE architecture, engineering, operations, support, and education activities are co-designed by an unparalleled team to achieve this goal, far surpassing TeraGrid in usability, reliability, capability, performance, and security?and ultimately, in user productivity and science impact. XSEDE will enable scientists, engineers, and educators to exploit powerful digital services and social networking environments to support knowledge exchange and advance understanding across domains. Just a few examples of the advances to science and society include: accurately predicting earthquake damage to urban structures; modeling of protein and nucleic acid folding and structure prediction to understand how drugs interact with target macromolecules to improve health care; developing novel designs for nanoscale microprocessors; advancing scientific understanding of plants to provide a safe and sustainable food supply, as well as benefits in renewable energy; and simulating pandemic spread to create a virtual laboratory where policy decisions such as school closure, vaccine deployment, and quarantine can be explored. The XSEDE partnership will fulfill this vision by creating the most advanced, capable, and robust advanced digital cyberinfrastructure in the world?and supporting it with the most expert and experienced team of CI professionals. XSEDE will accelerate open scientific discovery and enable researchers, educators, and students across disciplines and across campuses to conduct transformational research efforts and innovative education programs. XSEDE will create strong ties with campus personnel spanning technology, workforce development, and policy issues to enhance CI for research and education. Researchers will use XSEDE directly, from campus and personal systems, from other high-end centers and cyberinfrastructure resources, and via science gateways and discovery environments. XSEDE users will be backed by an integrated national user support program offering an array of services from experts in the application of technology to advance science and engineering, including extensive training and advanced user support and collaboration. XSEDE?s governance model will include participation by these users as stakeholders, while providing centralized management to ensure robustness and to facilitate rapid responses to new issues and opportunities. XSEDE will carry out a multifaceted Training, Education, and Outreach Services (TEOS) program to raise the competency of the present and future scientific community. XSEDE will work proactively with the nation?s educational institutions to create a significantly larger and more diverse STEM workforce. TEOS will broaden participation by working with under-represented faculty and students to engage larger numbers of under-represented individuals from among minority-serving and EPSCoR institutions, women, and people with disabilities. TEOS will disseminate best practices, lessons learned, and quality materials and will leverage external partnerships to scale-up successful practices. XSEDE will leverage the XD Technology Insertion Service (TIS) activities?already awarded to the XSEDE team?into continuously advancing CI and will work closely with the Technology Audit Service (TAS) team to ensure that XSEDE can be effectively evaluated and improved. These activities will ensure that XSEDE is robust, easy to use, performing as designed, and evolving constantly to meet the growing demands of scientific research and researchers. Advancing science with the most powerful, diverse, and integrated set of advanced digital services ever?and linking that to other CI projects and to campuses and local research infrastructure?is unprecedented. No engineering and technology plan can anticipate all contingencies and future opportunities. The successful realization of NSF?s vision for XD will require deep expertise and vast experience, as well as focused and passionate effort. The XSEDE team is uniquely experienced and qualified for this incredible opportunity."
"1640829","CIF21 DIBBs: PD: - Metadata Toolkits for Building Multi-Faceted Data - Relationship Models","ACI","PLASMA PHYSICS, COMPUTATIONAL PHYSICS, DATANET, EarthCube","10/01/2016","08/03/2016","Martin Greenwald","MA","Massachusetts Institute of Technology","Standard Grant","Amy Walton","09/30/2019","$500,000.00","","g@psfc.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","1242, 7244, 7726, 8074","7433, 7569, 8048","$0.00","Scientific research is challenged by ever-larger, more complex data sets, stored in disparate form in complicated repositories, making it difficult to discover useful content. One reason is the relative scarcity of 'navigational' metadata - metadata that explicitly reveals the multitude of relationships between data elements. This project develops improved data management tools allowing data managers to create metadata schemas that reveal the multiple and complex relationships existing between data elements. The team develops these tools while collaborating directly with three different research communities: plasma physics (with the MIT Plasma Science and Fusion Center), ocean monitoring and modeling (with the MIT Department of Earth Sciences) and uncertainty quantification (with the University of Texas Institute for Computational Engineering and Sciences). <br/><br/>The project provides tools that allow data managers to easily develop metadata schemas that represent and expose the multiple and complex relationships that exist between data elements and which are typically not well represented in data systems. Such data elements include data source, provenance, physical properties represented in the data, data versioning, annotation threads, data dictionaries, data catalogs and data shape (which typically determines which applications can consume or display the data), and larger organizational entities such as research campaigns, experimental proposals and research products (e.g., publications, presentations and public databases). Schemas and data are manipulated through a Representational State Transfer - Application Programming Interface (RESTful API). Relationships among the data are represented as mathematical graph structures that are all built upon a common meta-schema. There is an emphasis on recording the full data lifecycle using a RESTful API and granular data object uniform resource identifier (URI) schema that facilitate instrumenting complex and varied workflows. A modern web based exploration tool is built upon these technologies in the initial application areas of plasma physics, ocean monitoring and modeling, and uncertainty quantification. By viewing meta-data and programs more generally as a collection of graphs whose nodes are the data files or records, the project creates a set of programs which can explore these graphs and make the system much more general and easily extensible. Also, by allowing users to create data objects at any level of specificity, the graphs of which the data is a member can be used to label object groupings. This ability to represent data relationships would be of use to a broad contingent of the scientific community and could be useful to the scientific enterprise in many domains. <br/><br/>This award by the Advanced Cyberinfrastructure Division is jointly supported by the NSF Directorate for Geosciences, and the NSF Directorate for Mathematical & Physical Sciences (Division of Physics)."
"1338427","Predictability and Prediction of Climate from Days to Decades","AGS","CLIMATE & LARGE-SCALE DYNAMICS, EarthCube","05/01/2014","06/06/2016","James Kinter","VA","George Mason University","Continuing grant","Eric T. DeWeaver","04/30/2017","$5,699,932.00","","ikinter@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","GEO","5740, 8074","1324, 4444, 7433, OTHR","$0.00","This award provides continued funding for the Center for Ocean-Land-Atmosphere Studies (COLA). COLA is a climate science research center established to explore, establish and quantify the variability and predictability of Earth's climate variations on seasonal to decadal time scales, and to harvest this predictability for societally beneficial predictions. The Center is jointly funded by NSF, NOAA and NASA.<br/><br/>Work supported through this award includes activities devoted to 1) basic research on predictability on intraseasonal, seasonal, interannual, and decadal timescales; 2) evaluation of the predictability, skill, and fidelity of US national climate models; and 3) contributions to the development of next generation seamless prediction systems. Research performed under item 1 includes testing of land data assimilation schemes in multiple models, performing hindcasts of El Nino/Southern Oscillation (ENSO) events investigate inter-event diversity of ENSO, performing dynamical prediction experiments for the Indian monsoon, and determining the dependence of drought probability on surface boundary conditions including land cover change. Work under item 2 focuses on the use of optimal spatial structures derived from information theoretic analysis, which represent the most predictable modes, or modes for which predictability differs the most between two models. This activity is intended to support climate prediction efforts at US national centers and contribute to COLA's research-to-operations effort. Work under item 3 involves collaborators at the NOAA National Centers for Environmental Prediction (NCEP) and includes the development of optimal methods of initializing high-resolution coupled models including version 2 of the Coupled Forecast System (CFSv2), a model used operationally at NCEP.<br/><br/>The work has broader impacts due to its focus on research leading to improved climate prediction, given the substantial societal consequences of climate variability and change. In addition, COLA benefits the US climate research enterprise through community integration, education, seminars, workshops, and software and information services. COLA also serves an important function in transferring the results of basic climate science research on predictability and prediction into operational use."
"1435578","Biological and Chemical Oceanography Data Management Office (BCO-DMO): A System for Access to Ecological and Biogeochemical Ocean Data","OCE","LONG TERM ECOLOGICAL RESEARCH, BIOLOGICAL OCEANOGRAPHY, CHEMICAL OCEANOGRAPHY, ANTARCTIC ORGANISMS & ECOSYST, POLAR CYBERINFRASTRUCTURE, EarthCube, SEES Ship Operations","09/01/2014","07/01/2016","Peter Wiebe","MA","Woods Hole Oceanographic Institution","Continuing grant","David L. Garrison","08/31/2019","$6,853,199.00","Robert Groman, David Glover, Cynthia Chandler","pwiebe@whoi.edu","183 OYSTER POND ROAD","WOODS HOLE","MA","025431041","5082893542","GEO","1195, 1650, 1670, 5111, 5407, 8074, 8291","1382, 1389, 1650, 1670, 4444, 7433","$0.00","The Earth System is changing rapidly as a result of growing pressure from human activities that are changing important components of the System. The oceans act as the flywheel of the climate system, playing major roles in the climate, the water cycle, the carbon cycle, global energy budgets, and sea level rise. Study and understanding of this component of the Earth System requires integrated multi-disciplinary investigations with access to oceanographic data of biological, chemical, geological, and physical origin. The Biological and Chemical Oceanography Data Management Office (BCO-DMO) was created to serve PIs funded by the NSF Biological and Chemical Oceanography Sections and the Division of Polar Programs Antarctic Organisms and Ecosystems Program as a facility where marine biogeochemical and ecological data and information developed in the course of scientific research can be managed and made publicly available. BCO-DMO provides integrated chemical, biological and physical data inventories from a number of large and intermediate-sized programs, as well as single investigator projects. BCO-DMO also provides scientific investigators the opportunity to explore complex and multifaceted datasets and supports cross-disciplinary collaboration to address pressing environmental questions, problems, and challenges that are exacerbated with the increasing pace of climate change. The BCO-DMO collection of datasets contributed by researchers funded by NSF and others is a publicly available resource accessible via the BCO-DMO website. BCO-DMO supports synthesis and modeling activities, reuse of oceanographic data for new research endeavors, availability of ""real data"" for classroom use by teachers and students at K-12 and college level, and provides decision-support field data for policy-relevant issues. BCO-DMO outreach activities include participation in community training courses and workshops both national and international, and help to foster long-term collaborative partnerships between data management professionals and research investigators. These outreach activities reduce community barriers by fostering the sharing of ideas among synergistic, but otherwise independent research groups. BCO-DMO actively participates in the exchange of knowledge at oceanographic and informatics meetings, an important mechanism by which standards development and adoption occurs. <br/><br/>The primary goal of the BCO-DMO data management repository is to manage existing and new datasets from NSF funded individual scientific investigators and collaborative groups of investigators, and to make the data available online. The BCO-DMO data management system is composed of a metadata database and the distributed client-server JGOFS/GLOBEC data system, plus text-based and map-based user interfaces and support for machine clients to access the information and data available from the repository. The office works with principal investigators and other data contributors to support all phases of the data lifecycle; maintain an inventory of projects, deployments, and datasets; generate standards-compliant metadata records as required by federal agencies; promote compliance with the NSF Ocean Sciences data policy; ensure submission of data to national data centers for archive; support and encourage data synthesis by providing enhanced data discovery and access systems; facilitate interoperability among distributed data repositories; and facilitate regional, national, and international data and information exchange. The office participates in the development and use of open-source, standards-based technologies that enable interoperable data systems to exchange data and information that will foster next-generation research in all disciplines. As the analysis of ocean processes becomes more and more sophisticated, multidisciplinary data integration will also grow more complex. BCO-DMO fosters information sharing and is committed to being a fundamental component of the ocean science research infrastructure without which the goals of existing and future ocean research programs cannot be met."
"1443062","Beyond Data Discovery: Shared Services for Community Metadata Improvement","ACI","DATANET, EarthCube","05/01/2015","04/27/2015","Ray Habermann","IL","The HDF Group","Standard Grant","Amy Walton","04/30/2018","$1,498,604.00","Matthew Jones","thabermann@hdfgroup.org","1800 S. Oak Street","Champaign","IL","618207059","2175316100","CSE","7726, 8074","7433, 8048","$0.00","Science data and results must be well documented in order to be reproducible and re-usable. Metadata -- ancillary contextual information such as science objectives, data provenance, and uncertainty estimates at each step -- is a fundamental part of the research documentation, reuse, and collaboration process.<br/><br/>This project develops flexible tools for evaluating metadata, using consistent measurement systems that encourage community engagement, integrate guidance for improvement, and are a critical element in cross-community metadata improvement efforts. Provision of these new metadata and data evaluation services across communities will improve the ability to integrate and reuse trustworthy data for crosscutting synthesis and analysis across science communities. The focus on use metadata rather than discovery metadata is a significant shift in focus. Use metadata is a fundamental building block needed to allow effective scientific analysis workflows. The team builds a significant collaboration with several interdisciplinary partner organizations that provide guidance to this project."
"1640775","CIF21 DIBBs: PD: Accelerating Comparative Metagenomics through an Ocean Cloud Commons","ACI","ADVANCES IN BIO INFORMATICS, DATANET, EarthCube","01/01/2017","07/21/2016","Bonnie Hurwitz","AZ","University of Arizona","Standard Grant","Amy Walton","12/31/2019","$496,064.00","John Hartman","bhurwitz@email.arizona.edu","888 N Euclid Ave","Tucson","AZ","857194824","5206266000","CSE","1165, 7726, 8074","7433, 8048, 9102","$0.00","The Tara Oceans Expedition has provided the largest publicly available contiguous dataset available in genomics for any scientific project in the world. Using the research schooner Tara and modern sequencing and state-of-the-art imaging technologies, a multinational team of scientists sampled microscopic plankton at hundreds of sites and depths in all the major oceanic regions. The Tara Oceans Expedition data have been released, but it is a challenge for researchers to access, manipulate, and analyze such large-scale resources. This project creates an Ocean Cloud Commons (OCC), a cloud-based resource and repository allowing researchers to query the Tara Oceans Expedition Data in the cloud; it also makes available comparative metagenomic tools through the Ocean Treasure Box (OTB).<br/><br/>The Ocean Cloud Commons and Ocean Treasure Box build upon established partnerships with organizations such as CyVerse Cyberinfrastructure, Agave Platform, OpenCloud, and computing facilities at the Texas Advanced Computing Center. The Ocean Cloud Commons uses an algorithm based on MapReduce to create a comparative metagenomics data resource in a Hadoop big data framework. The OCC can be widely accessed by researchers using tools developed in the Ocean Treasure Box and implemented as Apps in the CyVerse Cyberinfrastructure. Specifically, OTB tools deploy and compute on OCC data in OpenCloud via the Agave Platform and Developer API from CyVerse. Taken together, the OTB tools and OCC data resources enable researchers to address global-scale questions about the distribution of microbes across the sea that affect climate and ecosystem function.<br/><br/>This award by the Advanced Cyberinfrastructure Division is jointly supported by the NSF Directorate for Biological Sciences (Division of Biological Infrastructure), and the NSF Directorate for Geosciences."
"1541800","Flyover Country, a mobile app for geoscience education","EAR","EDUCATION AND HUMAN RESOURCES, INSTRUMENTATION & FACILITIES, EarthCube","05/01/2015","05/26/2015","Amy Myrbo","MN","University of Minnesota-Twin Cities","Standard Grant","David Lambert","10/31/2016","$146,910.00","Shane Loeffler","amyrbo@umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","GEO","1575, 1580, 8074","7433, 7916","$0.00","This award will develop a mobile app, Flyover Country (FC), that will bring information about relevant points of interest (POI) and map data to the user mid-flight, without the need for in-flight Wi-Fi, by downloading a strip of data based on the flightpath before the user boards the plane. GPS (Global Positioning System), which functions in airplane mode, allows precise flight tracking, making prompts for POI viewing timely and relevant. With around 4.5 million people flying every day, the potential audience for FC is huge, as is its potential for geoscience outreach. The app will directly feed high-quality geoscience information to the user at the very point when curiosity is stimulated, and could thus improve public science literacy as well as inspiring and supporting the development of a generation of geoscientists. FC could also readily be adapted for use in STEM education, and will be structured so as to provide a platform for the exposure of all types of geospatial geoscience data, forming new infrastructure for education and research. <br/><br/>Visualization of geoscience through combining map views, articles, audio, visual aids, and the bird's eye view from a plane window will allow for new questions, ideas, relationships, and inspiration to be cultivated by scientists and the public alike. In addition, FC may improve the current state of data accessibility and the potential for dataset integration while simultaneously increasing the incentives for improving data discovery in the geosciences and beyond. Development of the app will be split into two main tasks: (1) the geospatial acquisition of maps and POI, which may be accomplished off the device (server-side), and (2) an on-device user interface that requests, downloads, and displays the gathered data. FC will be available for both iOS and Android devices. In addition to supporting informal learning from the airplane window, this system has great potential to be adapted for ground level use. Similar in content and scope to the popular Roadside Geology book series, a mobile app could present relevant geoscience information on road trips or hikes, and do so even where connectivity is absent."
"0921084","University-National Oceanographic Laboratory System","OCE","ANTARCTIC INSTRUM & SUPPORT, EDUCATION/HUMAN RESOURCES,OCE, OPERATIONS SUPPORT PROGRAM, ARCTIC RESRCH SUPPRT & LOGISTI, SUBMERSIBLE SUPPORT, OCEANOGRAPHIC TECHNICAL SERVCE, SHIP ACQUISITION AND UPGRADE, OCE SPECIAL PROGRAMS, OCEAN OBSERVATORY SCI & TECH, EarthCube, , , , , , , , , , , ","05/01/2009","09/13/2013","Jonathan Alberts","RI","University of Rhode Island","Cooperative Agreement","Bauke H. Houtman","06/30/2015","$4,165,570.00","Annette DeSilva","jalberts@mail.uri.edu","RESEARCH OFFICE","KINGSTON","RI","028811967","4018742635","GEO","1647, 1690, 5140, 5205, 5412, 5415, 5417, 5418, 7398, 8074, I343, I364, J383, J417, K626, KX36, L663, LX34, M539, M631, MX52","0000, 1079, 7556, OTHR","$0.00","The University-National Oceanographic Laboratory System (UNOLS) is a consortium of sixty-one U.S. academic institutions with research and educational programs in the ocean sciences and dedication to the major shared-use facilities that support these programs. These institutions support a broad array of facilities, which include research vessels, submersibles, remotely operated vehicles, autonomous underwater vehicles, aircraft, icebreakers, major instrumentation, and national facilities. The institution or the supporting federal agencies own these shared-use assets and it is through the UNOLS system that the community is able to access them. <br/><br/>The PI's request funding to host the UNOLS Office beginning in May 2009. As one of the founding institutions of UNOLS, GSO has a long tradition and deep experience with this organization and with the federal agencies that fund it. Since its inception in 1971, UNOLS has played an increasingly important role in coordinating and improving the operations of the nation's academic research fleet. Because the organization functions largely through the voluntary efforts of scientists and professionals from across the country, it is essential that the UNOLS Office be staffed by people who thoroughly understand UNOLS and are committed to its success."
"0930731","Facility Support: OpenTopography - A National Hub for High Resolution Topographic Data, Tools, and Knowledge","EAR","INSTRUMENTATION & FACILITIES, CI REUSE, INFO INTEGRATION & INFORMATICS, EarthCube","09/15/2009","08/08/2014","Viswanath Nandigam","CA","University of California-San Diego","Continuing grant","Russell C. Kelz","08/31/2014","$1,517,073.00","","viswanat@sdsc.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","GEO","1580, 6892, 7364, 8074","0000, 7433, OTHR","$0.00","0930731<br/>Baru<br/><br/>This collaborative grant to the San Diego Supercomputer Center and Arizona State University (PI: Arrowsmith/EAR-0930643) will support a three year Facility project to further develop and scale up the OpenTopography Portal (http://www.opentopography.org) for provision of high-performance, internet-based access to large volumes of high-resolution airborne and ground-based LIDAR topographic data sets and generation of derived data products. The proof-of-concept OpenTopography Portal (OpenTopo) was developed through NSF/Information Technology Research and EAR/Geoinformatics support to the San Diego Supercomputer Center as part of the GEON Project. That portal currently hosts and distributes a limited number of data sets acquired through the NSF/EAR supported National Center for Airborne Laser Swath Mapping (NCALM) at the University of Florida and from USGS and NASA-funded research. This support will enable significant upgrades and assimilation of large volumes of extant and future LIDAR data through: 1) provision of internet-based access to LIDAR topography data in multiple formats, including ?raw? point cloud data, standard LIDAR-derived DEMs, and easily accessible Google Earth products; and 2) development of additional collaborations with existing LIDAR topography data providers and hosts (e.g., NCALM, USGS, regional consortia, states, etc.) to link to their data archives and/or to host and distribute their data and processing software algorithms through a freely accessible web-interface. High-resolution digital elevation models derived from LIDAR (Light Distance And Ranging) methods (both airborne and ground-based) have been revolutionary for Earth science, environmental, and engineering applications. These data are among the most powerful tools available for study of the bare Earth surface, vegetative cover, and civil structures. Capable of generating digital elevation models (DEMs) more than an order of magnitude better resolved than those currently available from digitized USGS topo maps or from Shuttle Radar Topography Mission products, airborne LIDAR (or airborne laser swath mapping - ALSM) provides the ability to acquire meter-scale resolution, decimeter accuracy elevation data sets over large areas at relatively low expense. Ground-based or terrestrial laser scanners (TLS) offers even finer resolution mapping for specific targets. These data enable research on surface processes at fine scales and extents not previously possible yet essential for understanding processes (e.g., erosion, hillslope creep) at the scales at which they operate. OpenTopo will address the challenge of making massive LIDAR data sets and products readily accessible to end users through a freely accessible web-portal."
"0856145","Management and Operation of the National Center for Atmospheric Research, 2008-2018, and Supporting Activities","AGS","NAT CENTER FOR ATMOSPHERIC RES, CLIMATE SIMULATION LAB AT NCAR, CLIMATE & LARGE-SCALE DYNAMICS, PALEOCLIMATE PROGRAM, LOWER ATMOSPHER OBSER FACILITI, PHYSICAL & DYNAMIC METEOROLOGY, OPERATIONS SUPPORT PROGRAM, ULAFOS SPECIAL PROGRAMS, ARCTIC RESRCH SUPPRT & LOGISTI, ATMOSPHERIC CHEMISTRY, UPPER ATMOSPHERIC FACILITIES, CR, Earth System Models, LARS SPECIAL PROGRAMS, POLAR CYBERINFRASTRUCTURE, CI REUSE, UARS SPECIAL PROGRAMS, COLLABORATIVE RESEARCH, ANTARCTIC OCEAN & ATMOSPH SCI, AGS, AERONOMY, SEES Hazards, EarthCube, EDUCATIONAL LINKAGES, EDUCATION/HUMAN RESOURCES,OCE, EDUCATION AND HUMAN RESOURCES","10/01/2008","09/22/2016","Maura Hagan","CO","University Corporation For Atmospheric Res","Cooperative Agreement","Sarah L. Ruth","09/30/2018","$865,435,770.00","","hagan@ucar.edu","3090 Center Green Drive","Boulder","CO","803012252","3034971000","GEO","4200, 4203, 5740, 1530, 1529, 1525, 5140, 7791, 5205, 1524, 4202, 8012, 7790, 5407, 6892, 7789, 7298, 5113, 6897, 1521, 8087, 8074, 7700, 1690, 1575","0000, OTHR, 9196, EGCH, 1314, 1303, 1324, 4444, 4200, 1079, 5740, 8012, 1525, 7433, 5978, 7386, 5113, 1524, 9145, 5407, 7790, 7791, 8060, 7700, 1529, 5140, 5205, 4203, 1530, 6892, 7789, 1521, 1575, 1690","$0.00",""
"1261833","2013-2018 UNAVCO Community Proposal Geodesy Advancing Geosciences and EarthScope: The GAGE Facility","EAR","EARTHSCOPE-OPERATIONS & MAINTE, GEOPHYSICS, EDUCATION AND HUMAN RESOURCES, INSTRUMENTATION & FACILITIES, CONTINENTAL DYNAMICS PROGRAM, ANTARCTIC INSTRUM & SUPPORT, ARCTIC RESRCH SUPPRT & LOGISTI, ANTARCTIC INTEGRATED SYS SCI, GAGE, GEOMORPHOLOGY & LAND USE DYNAM, DEEP EARTH PROCESSES SECTION, ICER, EarthCube, , , , , , ","10/01/2013","10/28/2016","Meghan Miller","CO","UNAVCO, Inc.","Cooperative Agreement","Russell C. Kelz","09/30/2018","$54,138,219.00","Donna Charlevoix, Charles Meertens, Glen Mattioli","Meghan@unavco.org","6350 Nautilus Dr.","Boulder","CO","803015394","3033817636","GEO","016F, 1574, 1575, 1580, 1581, 1647, 5205, 5292, 7113, 7458, 7571, 7699, 8074, M647, N551, O188, O224, O377, P181","1079, 1733, 7433","$0.00","Miller<br/>1261833<br/><br/>The GAGE Facility: Geodesy Advancing Geosciences and EarthScope Cooperative Agreement (CA) supports advancement of cutting-edge community geodetic research around the world. Over the last two decades, space-based geodetic observations have enabled measurement of the motions of the Earth?s surface and crust at many different scales, with unprecedented spatial and temporal detail and increased precision, leading to fundamental discoveries in continental deformation, plate boundary processes, the earthquake cycle, the geometry and dynamics of magmatic systems, continental groundwater storage and hydrologic loading. Space geodesy furthers research on earthquake and tsunami hazards, volcanic eruptions, coastal subsidence, wetlands health, soil moisture and groundwater distribution. Of particular importance are contributions to understanding of processes related to climate dynamics, including hurricane tracking and intensity, sea level rise, and changes in mountain glaciers and large polar ice sheets. As global population disproportionately increases in hazards-prone coastal and tectonically active regions of the US and across the globe, the societal relevance of quantifying, understanding, and potentially mitigating natural hazards grows. Geoscientists using global geodetic infrastructure coupled with leading edge techniques are well poised to advance basic research that is in the U.S. and global public interest as the challenges of living on a dynamic planet escalate.<br/><br/>NSF-funded geodesy investigators are active on every continent, across a broad spectrum of the geosciences, and facilitated by data and engineering services that are now merged under the GAGE Facility. GAGE continues operations of: 1) the EarthScope Plate Boundary Observatory (PBO), an integrated set of geodetic networks that includes 1100 continuous GPS sites (with ~350 high-rate, low-latency data streams and ~125 surface meteorological sensors), 78 borehole strainmeters and seismometers, and 6 long-baseline laser strainmeters, and tiltmeters on several volcanoes; 2) global engineering and data services primarily to NSF-funded investigators who use terrestrial and satellite geodetic technologies in their research and provision of network operations support to community GPS networks and NASA?s Global GNSS Network (GGN); and 3) Education and community outreach actvities. NSF?s Division of Polar Programs (PLR) contributes to the GAGE Facility support of PI research and GPS networks in Greenland and Antarctica. NASA contributes to the GAGE Facility to support the GGN and the activities of the IGS Central Bureau, which underlie the internationally coordinated reference frame products that make high-precision geodesy possible.<br/><br/>***"
"0950477","Geoinformatics Facilities Support: Integrated Data Collections for the Earth & Ocean Sciences: The Marine Geoscience Data System and the Geoinformatics for Geochemistry Program","OCE","PETROLOGY AND GEOCHEMISTRY, MARINE GEOLOGY AND GEOPHYSICS, ANTARCTIC INSTRUM & SUPPORT, ANTARCTIC EARTH SCIENCES, POLAR CYBERINFRASTRUCTURE, OCE SPECIAL PROGRAMS, OCEAN DRILLING PROGRAM, EAR, OCE, CYBERINFRASTRUCTURE, GEOINFORMATICS, COLLABORATIVE RESEARCH, NSF Public Access Initiative, ICER, EarthCube","12/01/2010","10/28/2016","Kerstin Lehnert","NY","Columbia University","Cooperative Agreement","Barbara L. Ransom","09/30/2017","$12,623,687.00","Vicki Ferrini, Stephen Richard, Karin Block, Suzanne Carbotte, William Ryan","lehnert@ldeo.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","GEO","1573, 1620, 1647, 5112, 5407, 5418, 5720, 6898, 6899, 7231, 7255, 7298, 7414, 7699, 8074","0000, 1620, 1733, 5936, 5979, 7433, OTHR, 1647","$0.00","This Cooperative Agreement creates a community-driven facility that consolidates a number of essential cyberinfrastructure activities in the solid-earth geosciences at the Lamont Doherty Earth Observatory of Columbia University. It includes data repositories; author attribution schema; data management, discovery, and visualization tools; web portals and services; and the development and implementation of a sample unique-identifier registration system and database interoperability and metadata standards. The project also includes the creation of geoscience education and outreach modules and workshops. Goals of the facility are to serve the data management and discovery needs of the geoscience community and to provide direct public accessibility to NSF-funded data sets and associated data products. To achieve these goals, the collected activities are overseen by an external advisory structure of users and domain scientists in the geoinformatics, geophysics, igneous petrology, geochemistry, sedimentology, hydrothermal vent fluid, and polar geoscience communities and who work in concert with NSF to best serve community needs and monitor project performance. The broader impacts of the resulting facility and its activities are broad and far-reaching in terms of building infrastructure for science and education in the solid-earth geosciences. The resulting infrastructure and unified data submission procedures and standards will significantly advance the field of geoinformatics and provide essential tools for discovering data and combining disparate datasets such that more complex scientific problems can be tackled by providing a means to efficiently collect and view and model multiple datasets. It also provides an important educational tool for students by allowing them to explore large amounts of data in creative ways."
"1339782","SI2-SSI: Collaborative Research: STORM: A Scalable Toolkit for an Open Community Supporting Near Realtime High Resolution Coastal Modeling","ACI","PHYSICAL OCEANOGRAPHY, SPECIAL PROJECTS - CISE, SPECIAL PROJECTS - CCF, Software Institutes, EarthCube","10/01/2014","08/26/2014","Hartmut Kaiser","LA","Louisiana State University & Agricultural and Mechanical College","Standard Grant","Rajiv Ramnath","09/30/2018","$970,835.00","Robert Twilley","hkaiser@cct.lsu.edu","202 Himes Hall","Baton Rouge","LA","708032701","2255782760","CSE","1610, 1714, 2878, 8004, 8074","7433, 8009, 9150","$0.00","The ADCIRC coastal circulation and storm surge model has a long standing track record of extremely high societal impact. It has been used to define risk (e.g., 100-yr, 500-yr coastal flood levels) for the FEMA National Flood Insurance Program in coastal states from New York to Texas, it has been used to design the multi-billion dollar Hurricane and Storm Damage Risk Reduction System around greater New Orleans and southern Louisiana by the Army Corps of Engineers, it is currently run operationally by NOAA/NWS National Center for Environmental Prediction to forecast storm surge, to name just a few of its current and recent applications. Thus there is a well-established user network in place to convert improvements in ADCIRC into significant broader impacts. The proposed research provides transformative intellectual contributions that focus on applying new parallelization schemes to enable major advances in the algorithms, implementation and utilization of the ADCIRC model. The broadening of ADCIRC to a multi-algorithmic framework and the resulting performance gains that are anticipated will help ensure ADCIRC's sustainability as a core community model for at least the next 20 years. In addition, the proposed collaboration will impact computer science by serving as a high impact use case to inform the design of new approaches to efficient scalable computing. Together, the advancements in coastal modeling and parallelization technology will make a significant contribution to the science of modeling and HPC. The results of the proposed research will be disseminated to a wider community through ongoing educational outreach activities at the participating organizations as well as through refereed conference and journal papers, and invited presentations. The involvement of graduate students and post-doctoral fellows will be crucial towards the success of this project. The PIs have a long history of training and mentoring students and post-docs in computational science and engineering, coastal engineering and marine science. The recruitment and involvement of underrepresented groups in these efforts has always been a high priority. In addition, aspects of the proposed research will be incorporated into the curricula of several courses taught by the PIs in the areas of finite element methods, scientific computation, hydrology and oceanography.<br/>The aim of this project is to broaden the ADCIRC coastal circulation and storm surge model from a successful, but somewhat static coastal modeling tool that is tied to a single solution algorithm and the MPI parallelization paradigm, to a dynamic computational platform that is comprised of multiple solution algorithms, that readily admits new solution algorithms and that is built on a transformational new parallelization scheme that will allow us to scale to at least 256k compute cores on modern high performance computing (HPC) systems. We will do this by creating a living, evolving coastal modeling framework that will continue to lead the community in merging physical science / engineering and high performance computing and we will make the framework available to the broader community as a sustainable long term solution for its coastal modeling needs. In addition we will utilize these advancements in the highly demanding coastal storm surge forecasting system that we presently operate to demonstrate both improved robustness and speed of the model solution. We expect this effort will shorten the time required to provide reliable forecasting results and improve our ability to provide highly resolved, accurate, and physically complete predictions on an unprecedented scale. Concurrently, it should enable the use of smaller resources for simulations of increased scale which improves the usability and widens the applicability of ADCIRC in a broader community. The development of tightly integrated web-oriented products like CERA (www.coastalemergency.org) will enable the wide and timely dissemination of forecast modeling results to reach a broad audience."
"1339738","SI2-SSI: Collaborative Research: STORM: A Scalable Toolkit for an Open Community Supporting Near Realtime High Resolution Coastal Modeling","ACI","PHYSICAL OCEANOGRAPHY, SPECIAL PROJECTS - CISE, SPECIAL PROJECTS - CCF, Software Institutes, EarthCube","10/01/2014","10/20/2014","Joannes Westerink","IN","University of Notre Dame","Standard Grant","Rajiv Ramnath","09/30/2018","$730,000.00","Damrongsak Wirasaet, Tim Stitt","jjw@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","CSE","1610, 1714, 2878, 8004, 8074","7433, 8009","$0.00","The ADCIRC coastal circulation and storm surge model has a long standing track record of extremely high societal impact. It has been used to define risk (e.g., 100-yr, 500-yr coastal flood levels) for the FEMA National Flood Insurance Program in coastal states from New York to Texas, it has been used to design the multi-billion dollar Hurricane and Storm Damage Risk Reduction System around greater New Orleans and southern Louisiana by the Army Corps of Engineers, it is currently run operationally by NOAA/NWS National Center for Environmental Prediction to forecast storm surge, to name just a few of its current and recent applications. Thus there is a well-established user network in place to convert improvements in ADCIRC into significant broader impacts. The proposed research provides transformative intellectual contributions that focus on applying new parallelization schemes to enable major advances in the algorithms, implementation and utilization of the ADCIRC model. The broadening of ADCIRC to a multi-algorithmic framework and the resulting performance gains that are anticipated will help ensure ADCIRC's sustainability as a core community model for at least the next 20 years. In addition, the proposed collaboration will impact computer science by serving as a high impact use case to inform the design of new approaches to efficient scalable computing. Together, the advancements in coastal modeling and parallelization technology will make a significant contribution to the science of modeling and HPC. The results of the proposed research will be disseminated to a wider community through ongoing educational outreach activities at the participating organizations as well as through refereed conference and journal papers, and invited presentations. The involvement of graduate students and post-doctoral fellows will be crucial towards the success of this project. The PIs have a long history of training and mentoring students and post-docs in computational science and engineering, coastal engineering and marine science. The recruitment and involvement of underrepresented groups in these efforts has always been a high priority. In addition, aspects of the proposed research will be incorporated into the curricula of several courses taught by the PIs in the areas of finite element methods, scientific computation, hydrology and oceanography.<br/>The aim of this project is to broaden the ADCIRC coastal circulation and storm surge model from a successful, but somewhat static coastal modeling tool that is tied to a single solution algorithm and the MPI parallelization paradigm, to a dynamic computational platform that is comprised of multiple solution algorithms, that readily admits new solution algorithms and that is built on a transformational new parallelization scheme that will allow us to scale to at least 256k compute cores on modern high performance computing (HPC) systems. We will do this by creating a living, evolving coastal modeling framework that will continue to lead the community in merging physical science / engineering and high performance computing and we will make the framework available to the broader community as a sustainable long term solution for its coastal modeling needs. In addition we will utilize these advancements in the highly demanding coastal storm surge forecasting system that we presently operate to demonstrate both improved robustness and speed of the model solution. We expect this effort will shorten the time required to provide reliable forecasting results and improve our ability to provide highly resolved, accurate, and physically complete predictions on an unprecedented scale. Concurrently, it should enable the use of smaller resources for simulations of increased scale which improves the usability and widens the applicability of ADCIRC in a broader community. The development of tightly integrated web-oriented products like CERA (www.coastalemergency.org) will enable the wide and timely dissemination of forecast modeling results to reach a broad audience."
"1339801","SI2-SSI: Collaborative Research: STORM: A Scalable Toolkit for an Open Community Supporting Near Realtime High Resolution Coastal Modeling","ACI","OFFICE OF MULTIDISCIPLINARY AC, PHYSICAL OCEANOGRAPHY, SPECIAL PROJECTS - CISE, SPECIAL PROJECTS - CCF, Software Institutes, CDS&E-MSS, EarthCube","10/01/2014","02/27/2015","Clinton Dawson","TX","University of Texas at Austin","Standard Grant","Rajiv Ramnath","09/30/2018","$540,012.00","Craig Michoski","clint@ices.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","CSE","1253, 1610, 1714, 2878, 8004, 8069, 8074","7433, 8009, 8251","$0.00","The ADCIRC coastal circulation and storm surge model has a long standing track record of extremely high societal impact. It has been used to define risk (e.g., 100-yr, 500-yr coastal flood levels) for the FEMA National Flood Insurance Program in coastal states from New York to Texas, it has been used to design the multi-billion dollar Hurricane and Storm Damage Risk Reduction System around greater New Orleans and southern Louisiana by the Army Corps of Engineers, it is currently run operationally by NOAA/NWS National Center for Environmental Prediction to forecast storm surge, to name just a few of its current and recent applications. Thus there is a well-established user network in place to convert improvements in ADCIRC into significant broader impacts. The proposed research provides transformative intellectual contributions that focus on applying new parallelization schemes to enable major advances in the algorithms, implementation and utilization of the ADCIRC model. The broadening of ADCIRC to a multi-algorithmic framework and the resulting performance gains that are anticipated will help ensure ADCIRC's sustainability as a core community model for at least the next 20 years. In addition, the proposed collaboration will impact computer science by serving as a high impact use case to inform the design of new approaches to efficient scalable computing. Together, the advancements in coastal modeling and parallelization technology will make a significant contribution to the science of modeling and HPC. The results of the proposed research will be disseminated to a wider community through ongoing educational outreach activities at the participating organizations as well as through refereed conference and journal papers, and invited presentations. The involvement of graduate students and post-doctoral fellows will be crucial towards the success of this project. The PIs have a long history of training and mentoring students and post-docs in computational science and engineering, coastal engineering and marine science. The recruitment and involvement of underrepresented groups in these efforts has always been a high priority. In addition, aspects of the proposed research will be incorporated into the curricula of several courses taught by the PIs in the areas of finite element methods, scientific computation, hydrology and oceanography.<br/>The aim of this project is to broaden the ADCIRC coastal circulation and storm surge model from a successful, but somewhat static coastal modeling tool that is tied to a single solution algorithm and the MPI parallelization paradigm, to a dynamic computational platform that is comprised of multiple solution algorithms, that readily admits new solution algorithms and that is built on a transformational new parallelization scheme that will allow us to scale to at least 256k compute cores on modern high performance computing (HPC) systems. We will do this by creating a living, evolving coastal modeling framework that will continue to lead the community in merging physical science / engineering and high performance computing and we will make the framework available to the broader community as a sustainable long term solution for its coastal modeling needs. In addition we will utilize these advancements in the highly demanding coastal storm surge forecasting system that we presently operate to demonstrate both improved robustness and speed of the model solution. We expect this effort will shorten the time required to provide reliable forecasting results and improve our ability to provide highly resolved, accurate, and physically complete predictions on an unprecedented scale. Concurrently, it should enable the use of smaller resources for simulations of increased scale which improves the usability and widens the applicability of ADCIRC in a broader community. The development of tightly integrated web-oriented products like CERA (www.coastalemergency.org) will enable the wide and timely dissemination of forecast modeling results to reach a broad audience."
"1550229","SI2-SSI: Collaborative Research: ENKI: Software infrastructure that ENables Knowledge Integration for Modeling Coupled Geochemical and Geodynamical Processes","ACI","Software Institutes, EarthCube","09/01/2016","08/19/2016","Everett Shock","AZ","Arizona State University","Standard Grant","Vipin Chaudhary","08/31/2019","$213,345.00","","eshock@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","8004, 8074","7433, 8004, 8009","$0.00","Earth scientists seek to understand the mechanisms of planetary evolution from a process perspective in order to promote the progress of science. They model the chemistry of melting of the interiors of planets as a result of heat flow within the body. They calculate the flows of energy and mass from the interior to the surface. They model the interaction of fluids and rocks, which drives chemical weathering and the formation of ore deposits. They seek to understand the synthesis and stabilities of organic compounds and their economic and biological roles. They study the interactions of atmosphere, oceans, biosphere and land as a dynamically coupled evolving chemical system. To achieve this level of understanding of planetary evolution, Earth scientists use software tools that encode two fundamentally different types of models: (1) thermodynamic models of naturally occurring materials, and (2) models of transport that track physical flows of both fluids and solids. Much of the fundamental science of planetary evolution lies in understanding coupled thermodynamic and transport models. This grant funds development of a software infrastructure that supports this coupled modeling of the chemical evolution of planetary bodies. It is their aim to establish an essential and active community resource that will engage a large number of researchers, especially early career scientists, in the exercise of model building and customization. <br/><br/>This is a project to create ENKI, a collaborative model configuration and testing portal that will transform research and education in the fields of geochemistry, petrology and geophysics. ENKI will provide software tools in computational thermodynamics and fluid dynamics. It will support development and access to thermochemical models of Earth materials, and establish a standard infrastructure of web services and libraries that permit these models to be integrated into fluid dynamical transport codes. This infrastructure will allow scientific questions to be answered by quantitative simulations that are presently difficult to impossible because of the lack of interoperable software frameworks. ENKI, via the adoption of state-of-the-art model interfacing (OpenMI) and deployment environments (HubZero), will modernize how thermodynamic and fluid dynamic models are used by the Earth science community in five fundamental ways: (1) provenance tracking will enable automatic documentation of model development and execution workflows, (2) new tools will assist users in updating thermochemical models as new data become available, with the ability to merge these data and models into existing repositories and frameworks, (3) automated code generation will eliminate the need for users to manually code web services and library modules, (4) visualization tools and standard test suites will facilitate validation of model outcomes against observational data, (5) collaborative groups will be able to share and archive models and modeling workflows with associated provenance for publication. With these tools we seek to transform the large community of model users, who currently depend on a small group of dedicated and experienced researchers for model development and maintenance, into an empowered ensemble of model developers who take ownership of the process and bring their own expertise, intuition and perspective to shaping the software tools they use in daily research. ENKI development will be community driven. Participation of a dedicated and diverse group of early career professionals will guide us in user interface development - insuring portal capabilities are responsive to user needs, and in development of a rich set of documentation, tutorials and examples. All software associated with this project will be released as open source."
"1440005","Collaborative Proposal: ATREX - integrated open source data analysis software for mineral and environmental sciences","EAR","CI REUSE, EarthCube","09/01/2014","09/03/2014","Przemyslaw Dera","HI","University of Hawaii","Standard Grant","Eva E. Zanzerkia","08/31/2017","$468,187.00","Bin Chen","pdera@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","GEO","6892, 8074","7433, 9150","$0.00","Synchrotron radiation user facilities are critical resources which enable state-of-the-art research and training in mineralogy, mineral physics and environmental science. Access to these facilities is very competitive and time allocated for experiments is constrained. The most popular and fundamental type of experiment is X-ray diffraction, which produces information on crystal structure, symmetry, chemical bonding, composition and density of minerals and other crystalline solids. Modern synchrotron-based diffraction experiments are typically conducted with the use of area detectors, in which case the data is recorded as digital diffraction images. Technology used in synchrotron experiments evolves rapidly increasing the speed of the data collection and producing massive volumes of experimental data, posing new serious challenges for data analysis. The experiments are often decision-driven, and require at least partial real time data interpretation to guide the experimenter. Software offering such real time analysis capabilities is currently not available. This proposal is a collaborative effort to provide this scientific community with easily accessible tools and training opportunities for using these codes.<br/><br/>This project focuses on a combination of novel tools for diffraction-based synchrotron research in Earth and environmental sciences including: (IM1) New capabilities for structure determination of unknown phases and identification of known phases in natural and synthetic samples; (IM2) Opening new possibilities for real time analysis in studies of solid state dynamic processes; (IM3) Robust Bayesian analysis of outliers, uncertainties and missing data; and (IM4) Creation of new free advanced tools for utilizing the available mineralogical database in synchrotron research. Utilizing a combination of existing, well-tested and widely used software components developed in the Interactive Data Language , Python, the project creates a new integrated multiplatform, open-source Python software package ATREX (Advanced Tools for Research in Extreme Xtallography), with unique capabilities to process diffraction image data from samples in all forms from glasses and melts, bulk powders, though coarse multi grains, to single crystals, which will support new data types produced by novel ultrafast X-ray imaging detectors, offer extensive automated serial processing capabilities for massive data sets and will allow real time data analysis for time-constrained decision-driven synchrotron experiments. ATREX will include database access capabilities utilizing the free American Mineralogist Crystal Structure Database."
"1450338","Collaborative Research: SI2-SSI: Landlab: A Flexible, Open-Source Modeling Framework for Earth-Surface Dynamics","ACI","GEOMORPHOLOGY & LAND USE DYNAM, Software Institutes, EarthCube","08/01/2015","07/14/2015","Nicole Gasparini","LA","Tulane University","Standard Grant","Rajiv Ramnath","07/31/2020","$532,320.00","","ngaspari@tulane.edu","6823 ST CHARLES AVENUE","NEW ORLEANS","LA","701185698","5048654000","CSE","7458, 8004, 8074","7433, 8009, 9150","$0.00","Earth scientists discover and predict the behavior of the natural world in part through the use of computer models. Models are used to study a wide range of phenomena, such as soil erosion, flooding, plant growth, landslide occurrence, and many other processes. Models can be used to develop scientific understanding by comparing model calculations with the real world. They can also be used to make predictions about how nature will behave under certain conditions. In the areas of geosciences that deal with the earth's surface, one bottleneck in the development and use of models is the effort required to build, test, and debug the necessary software. This project contributes to scientific research and discovery by creating open source software tools that scientists can use to more efficiently create, modify, or combine computer models that represent portions of earth's surface and the processes occurring thereon. The project combines software development with user training and web-based resources, so that the products will be openly accessible, well documented, and widely disseminated within the relevant scientific communities. The project also contributes to K-12, undergraduate, and graduate-level education in computational modeling and earth-surface processes.<br/><br/>This project catalyzes research in earth-surface dynamics by developing a software framework that enables rapid creation, refinement, and reuse of two-dimensional (2D) numerical models. The phrase earth-surface dynamics refers to a remarkably diverse group of science and engineering fields that deal with our planet's surface and near-surface environment: its processes, its management, and its responses to natural and human-made perturbations. Scientists who want to use an earth-surface model often build their own unique model from the ground up, re-coding the basic building blocks of their model rather than taking advantage of codes that have already been written. Whereas the end result may be novel software programs, many person-hours are lost rewriting existing code, and the resulting software is often idiosyncratic, poorly documented, and unable to interact with other software programs in the same scientific community and beyond, leading to lost opportunities for exploring an even wider array of scientific questions than those that can be addressed using a single model. The Landlab model framework seeks to eliminate these redundancies and lost opportunities, and simultaneously lower the bar for entry into numerical modeling, by creating a user- and developer-friendly software library that provides scientists with the fundamental building blocks needed for modeling earth-surface dynamics. The framework takes advantage of the fact that nearly all surface-dynamics models share a set of common software elements, despite the wide range of processes and scales that they encompass. Providing these elements in the context of a popular scientific programming environment, with strong user support and community engagement, contributes to accelerating progress in the diverse sciences of the earth's surface.<br/><br/>The Landlab modeling framework is designed so that grid creation, data storage, and sharing of data among process components is done for the user. The framework is generic enough so that the coupling of two process components, whether they are squarely within a geoscience subdiscipline, or they cross subdisciplines, is the same. This architecture makes it easy to explore a wide range of questions in the geosciences without the need for much coding. Further, the model code is primarily written in Python, a language that is relatively easy for casual programmers to learn. Because of these attributes, the Landlab modeling framework has the potential to add computational modeling to the toolbox of a wide array of geoscientists, and to clear a path for trans-disciplinary earth-surface modeling that explores societally relevant topics, such as land-cover changes in response to climate change, as well as modeling of topics that currently require the coupling of sophisticated but harder-to-use models, such as sediment source-to-sink dynamics. The project will generate several proof-of-concept studies that are interesting in their own right, and demonstrate the capabilities of the modeling framework. Community engagement is fostered by presenting clinics and demonstrations at professional venues aimed at hydrologists, sedimentologists, critical zone scientists, and the broader earth and environmental sciences community. The team also supports visits by individual scientists for on-site training beyond these clinics. Input/output tools allow compatibility with data from relevant NSF-supported research. The project supports four graduate students and three postdoctoral researchers, and also includes modeling workshops for fifth to seventh grade girls in a community that has a greater than 50% minority population."
"1532236","MRI Collaborative Consortium: Acquisition of a Shared Supercomputer by the Rocky Mountain Advanced Computing Consortium","ACI","MAJOR RESEARCH INSTRUMENTATION, CYBERINFRASTRUCTURE, EarthCube","09/01/2015","08/19/2015","Thomas Hauser","CO","University of Colorado at Boulder","Standard Grant","Edward Walker","08/31/2018","$2,030,000.00","Peter Ruprecht, Kenneth Jansen, Anna Hasenfratz, James Syvitski","thomas.hauser@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","CSE","1189, 7231, 8074","1189, 7433","$0.00","A cluster supercomputer is deployed by the University of Colorado Boulder (CU-Boulder) and Colorado State University (CSU) for the Rocky Mountain Advanced Computing Consortium (RMACC). This high-performance computing (HPC) system supports multiple research groups across the Rocky Mountain region in fields including astrophysics, bioinformatics, chemistry, computational fluid dynamics, earth system science, life science, material science, physics, and social sciences with advanced computing capabilities. It also provides a platform to investigate and address the impact of many-core processors on the applications that support research in these fields. <br/><br/>The system integrates nodes populated with Intel's conventional multicore Xeon processors and Many-Integrated-Core (MIC) 'Knights Landing' Phi processors interconnected by Intel's new Omni-Path networking technology. Users of the new HPC system have access to existing data management services including data storage, data sharing, metadata consulting, and data publishing, leveraging the NSF-funded high-performance networking infrastructure and long term storage system, as well as additional cyberinfrastructure, at CU-Boulder and CSU. The many-core feature of this HPC system enhances graduate and undergraduate students' education and training as they develop, deploy, test, and run optimized applications for next generation many-core architectures. Training for researchers and students is provided through workshops appropriate for introducing diverse audiences to the efficient and effective use of HPC systems, the challenges of vectorization for single core performance, shared memory parallelism, and issues of data management. Additionally, advanced workshops on large-scale distributed computing, high-throughput computing, and data-intensive computing are offered during the year and at the annual RMACC student-centric HPC Symposium. The Symposium brings together hundreds of students, researchers, and professionals from universities, national laboratories and industry to exchange ideas and best practices in all areas of cyberinfrastructure. For-credit HPC classes will be delivered for online participation, educating the next generation of computational scientists in state-of-the-art computational techniques."
"1101100","Bridging Data, New Technologies, and Communities to Enable and Communicate EarthScope Exploration and Discovery","EAR","EARTHSCOPE-SCIENCE UTILIZATION, ICER, EarthCube","05/01/2011","07/08/2014","J Ramon Arrowsmith","AZ","Arizona State University","Cooperative Agreement","Gregory J. Anderson","04/30/2016","$2,615,614.00","Matthew Fouch, Steven Semken, Edward Garnero, Wendy Taylor","ramon.arrowsmith@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","GEO","017F, 7699, 8074","017F, 1733, 7433, 8076","$0.00","EarthScope enables the exploration of the structure and evolution of the North American continent by scientists accessing a range of seismological, geodetic, in situ fault zone sampling, and geochronology and high resolution topography resources. EarthScope science is notable for its interdisciplinarity. Science results from EarthScope go beyond narrow analyses of individual datasets, and combine diverse observational datasets with innovative experimental and theoretical exploration. These results produce transformative knowledge for studying earth's structures and processes and in understanding hazards and guiding exploration of resources. In addition, these data and technologies offer superb opportunities to enhance formal and informal science education in the solid Earth sciences. The EarthScope National Office (ESNO) at Arizona State University serves the broad and diverse community of EarthScope stakeholders, including EarthScope researchers, formal and informal educators in Earth science, and the general public. <br/><br/>The ESNO will serve the scientific community through leadership and support of the EarthScope Steering committee, via close communication with the EarthScope program at NSF and the EarthScope Facilities (USArray, PBO, SAFOD), and by frequent solicitation of feedback and new ideas. The ESNO will maintain these activities as well as further promote EarthScope by assuming a meta-leadership role in coordinating current and new earth science initiatives (such as a major focus on Cascadia, the eastward movement of the Transportable Array, developing a plan for Alaskan EarthScope investigation, impending Frontiers in Earth System Dynamics projects, and earthquakes directly affecting the US). The need to integrate EarthScope and related data and other geoscience tools remains a critical need which can be addressed using the tools of cyberinfrastructure. Interesting new and unexpected applications of the EarthScope observational systems will be encouraged (e.g., atmosphere, hydrosphere, and cryosphere).<br/><br/>The ESNO foregrounds education and outreach (E&O): giving it attention, expertise, and resources at the same level as EarthScope science. This is accomplished by maintaining and expanding on effective services such as the EarthScope E&O website, Newsletters, Speaker Series, Interpretive Workshops for informal educators, and the biannual EarthScope National Meeting. Further, ESNO adds value to the programmatic E&O portfolio through new initiatives to:<br/><br/>- Rapidly channel EarthScope science through new social media such as Facebook, Twitter, and the 'Geoblogosphere'; <br/>- Pilot and disseminate exemplary new solid-Earth science content and inquiry-driven pedagogy for K-12 STEM teacher development (in partnership with organizations such as AGI and PRI);<br/>- Catalyze the use of regional and local results from EarthScope research in promoting place-based Earth science teaching at all levels to better engage and retain diverse students; and<br/>- Deliver a new continuing professional education service for EarthScope researchers and educators at the university and graduate levels: the University of EarthScope.<br/><br/>E&O at ESNO, infused with a place-based and educator-centered ethos, coordinates the compilation and presentation of the spectacular findings and scientific legacy of the EarthScope program, and is a reliable and effective partner to stakeholders.<br/><br/>Intellectual merit: Exploration of the 4-D structure of the North American continent is spectacularly underway with EarthScope by a vigorous community of scientists. The results are fundamental to increasing our understanding of the Earth, for characterizing how we live with potentially hazardous Earth processes, and for guiding exploration of resources. They are transformative in Earth science and technology education. The ESNO at ASU will be well-situated, planned, and configured to foster continued Earth exploration and discovery. <br/><br/>Broader impacts: The ESNO at ASU will enhance and continue to expand a high-profile public identity for EarthScope, establish a sense of ownership among scientific, professional, and educational communities, promote science literacy and understanding of EarthScope and Earth science in general, advance formal Earth science education, and foster use of EarthScope data, discoveries, and new technology in resolving challenging problems and improving our quality of life. Scientists, educators, students, decision makers, and our fellow citizens, in the Southwest as well as across the US and abroad, will all benefit from these activities.<br/><br/><br/>Non-technical explanation of broader significance and importance: Exploration of the four dimensional structure of the North American continent and Earth processes operating on and within it is spectacularly underway with EarthScope by a vigorous community of scientists. The results are fundamental to increasing our understanding of Earth, for characterizing how we live with potentially hazardous Earth processes, and for guiding exploration of natural resources. They are transformative in Earth science and technology education. The EarthScope National Office at Arizona State University will be well-situated, planned, and configured to foster continued Earth exploration and discovery. It will enhance and continue to expand a high-profile public identity for EarthScope, establish a sense of ownership among scientific, professional, and educational communities, promote science literacy and understanding of EarthScope and Earth science in general, advance formal Earth science education, and foster use of EarthScope data, discoveries, and new technology in resolving challenging problems and improving our quality of life. Scientists, educators, students, decision makers, and our fellow citizens, in the Southwest as well as across the U.S. and abroad, will all benefit from these activities."
"1442997","CIF21 DIBBs: An Infrastructure for Computer Aided Discovery in Geoscience","ACI","AERONOMY, DATANET, EarthCube","11/01/2014","08/14/2014","Victor Pankratius","MA","Massachusetts Institute of Technology","Standard Grant","Amy Walton","10/31/2017","$1,424,765.00","Frank Lind, Philip Erickson","vpankratius@haystack.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","1521, 7726, 8074","7433, 8048","$0.00","Next-generation Geoscience needs to handle rapidly growing data volumes from ground-based and space-based sensor networks. As real-world phenomena are mapped to data, the scientific discovery process essentially becomes a search process across multidimensional data sets. The extraction of meaningful discoveries from this sea of data therefore requires highly efficient and scalable machine assistance to enhance human contextual understanding. This is necessary both for testing new hypotheses as well as for the detection of novel events and monitoring for natural hazards.<br/><br/>This project develops a computer-aided discovery approach that provides scientists with better support to answer questions such as: What inferences can be drawn from an identified feature? What does a finding mean and how does it fit into the big theoretical picture? Does it contradict or confirm previously established models and findings? How can concepts and ideas be tested effectively? To achieve this, scientists can programmatically express hypothesized Geoscience scenarios, constraints, and model variations. This approach helps delegate the automatic exploration of the combinatorial search space of possible explanations in parallel on a variety of data sets. Furthermore, programmable crawlers can scale the search and discovery of interesting phenomena on cloud-based infrastructures. The computer-aided discovery prototype is evaluated in case studies from Geospace science, including the exploration of structures in space and time using combined GPS, optics, and Geospace radar data."
"1440811","SI2-SSE: Development and Implementation of Software Elements using State-of-the-Art Computational Methodology to Advance Modeling Heterogeneities and Mixing in Earth's Mantle","ACI","GEOPHYSICS, Software Institutes, EarthCube","08/01/2014","08/18/2016","Elbridge Puckett","CA","University of California-Davis","Standard Grant","Rajiv Ramnath","07/31/2017","$502,715.00","Magali Billen","egpuckett@ucdavis.edu","OR/Sponsored Programs","Davis","CA","956186134","5307547700","CSE","1574, 8004, 8074","7433, 8004, 8005, 9251","$0.00","This project involves the development and implementation of scientific software elements (SSEs), based on modern, high-resolution numerical methods for modeling steep gradients and sharp interfaces of material properties in viscous fluids in the presence of thermal convection. The goal of this project is to address a compelling need in geodynamics, in which continuum mechanics is applied to the study of geophysical processes, such as convection in the Earth?s mantle. A primary tool of geodynamics research is computational models of the flow of the extremely viscous interior of the Earth over hundreds of millions to billions of years. A long-standing challenge for these models is the need to accurately model sharp interfaces in temperature, viscosity, and other properties. These arise when, for example, modeling subduction (in which a cold tectonic plate plunges into the hot interior) or rising plumes (in which a hot boundary layer instability rises through the mantle and encounters the cold boundary layer of the tectonic plates). The project will foster interdisciplinary communication and the application of state-of-the-art applied and computational mathematics to fundamental problems in geophysics. It involves early-career mathematical scientists in the application of state-of-the-art numerical algorithms to geodynamics and, in particular, will provide an opportunity to increase the participation of women in mathematics and geodynamics research.<br/><br/>This project involves the design and implementation of state-of-the-art SSEs for computing the evolution of significant processes in the Earth's mantle in which an essential feature of the problem is the presence of one or more moving boundaries, interfaces, or steep gradients in temperature, composition, or viscosity. The SSEs will address two critical issues that currently limit modern mantle convection simulations. All computational models of mantle convection currently in use produce significant overshoot and undershoot in the neighborhood of sharp gradients in temperature and viscosity. The cause of these overshoots and undershoots is a numerical artifact, which is well-known and well-understood in other fields, such as the computational shock physics community. Over the past thirty years researchers in computational shock physics have developed a variety of high-order accurate, monotone numerical methods, which preserve the physically correct maximum and minimum values of the computed quantities, while producing a high-order accurate numerical approximation of these quantities. Another compelling need in computational geodynamics is the ability to track discontinuous jumps in quantities such as material composition. Here high-order accurate interface tracking algorithms are required, since these fields undergo large-scale deformation, yet quantities such as the viscosity must be accurately approximated at the interface between two materials."
"1324760","RCN: Building a Sediment Experimentalist Network (SEN)","EAR","GEOMORPHOLOGY & LAND USE DYNAM, SEDIMENTARY GEO & PALEOBIOLOGY, EarthCube","08/01/2013","04/13/2016","Wonsuck Kim","TX","University of Texas at Austin","Standard Grant","Justin Lawrence","07/31/2017","$440,559.00","Leslie Hsu, Brandon McElroy","delta@jsg.utexas.edu","101 E. 27th Street, Suite 5.300","Austin","TX","787121532","5124716424","GEO","7458, 7459, 8074","","$0.00","Our dynamic landscape evolves as sediment travels a path through mountain slopes, rivers, and deltas in events like landslides, floods, and hurricanes. In nature, these processes typically occur over vast length and time scales, making them difficult to study directly. Laboratory sedimentary experiments enable improved control and observation of these Earth-surface processes. However, such investigations often occur in isolation, and there is little if any coordination for our scientific community. We will form a Sediment Experimentalist Network (SEN) to help integrate the efforts of sediment experimentalists and build a knowledge base for guidance on best practices for data collection and management. We will also facilitate cross-institutional collaborative experiments, and communicate with and educate the research community about data and metadata standards for sediment-based experiments. This effort will improve the efficiency and transparency of sedimentary research for field geologists and modelers as well as experimentalists.<br/><br/>Major outcomes from SEN will be 1) creation of a Knowledge Base (SEN-KB), 2) coordination of Experimental Collaboratories (SEN-EC), and 3) integration of Educational efforts and Data standards development (SEN-ED) with tools for propagating new technology and methods. SEN-KB will be a collection of online resources for management and discovery of experimental data, metadata, analysis tools, methodologies, and other user-driven needs. SEN-EC will pilot infrastructure to foster multi-laboratory collaborations on experiments addressing broad and interdisciplinary grand challenges that are difficult to solve in a single laboratory: 1) extrapolation of experiments to natural systems and theory, 2) comparability of experimental results from disparate facilities, and 3) decoupling of external versus intrinsic processes observed in experiments. SEN-ED will provide training for data management through workshops and outreach for collecting and sharing experimental data. The project will facilitate access and use of new and existing data for a wide range of users in the experimentalist community and beyond toward modelers and field geologists."
"1443085","C1F21 DIBBS: Porting Practical Natural Language Processing (NLP) and Machine Learning (ML) Semantics from Biomedicine to the Earth, Ice and Life Sciences","ACI","ADVANCES IN BIO INFORMATICS, POLAR CYBERINFRASTRUCTURE, DATANET, EarthCube","11/01/2014","07/17/2015","Christopher Jenkins","CO","University of Colorado at Boulder","Standard Grant","Amy Walton","10/31/2017","$1,497,785.00","Martha Palmer, James Martin, Ruth Duerr","chris.jenkins@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","CSE","1165, 5407, 7726, 8074","7433, 8048","$0.00","Semantics is the study of word-based information. The sciences are filled with word-based descriptive data: field observations, materials and habitat identifications, parameter names and units, events and processes. Semantics are also important in medicine, where the human body and illnesses have to be described. To enhance interoperability among these word-based (semantic) systems, and to more readily explore the rapidly growing quantities of semantic data, there has been a movement towards organizing word-based data in ways that allow machine-assisted, automated analysis. Biomedicine has made great progress in organizing and using semantic information because of substantial funding investments. This project builds upon extensive investments in the biomedical field, providing an opportunity to rapidly develop the organization of semantic concepts for other domain sciences. <br/><br/>A toolkit developed by the Center for Computational Language and Education Research (CLEAR TK) will be used to build semantic resources (taxonomies, ontologies, and semantic networks) for three science domains (geology, cryology, and biology). CLEAR TK is a state-of-the-art natural language processing (NLP) and machine learning (ML) system that also has essential tools for machine-assisted annotation, validation, document tagging, and event extraction. The CLEAR TK system has been used operationally for biomedical semantic applications, including in high-profile hospitals. In this project, developments are focused upon the science fields of geology, ice and snow, and biology. In these fields, accurate extraction of semantic information from the word-based data is required so users can quickly find the data they really need. This project provides a valuable opportunity to expand and evaluate semantic capabilities in conjunction with several scientific domain experts."
"1442095","DYNAmics of the Madden-Julian Oscillation (DYNAMO) Legacy Data Products","AGS","CLIMATE & LARGE-SCALE DYNAMICS, EarthCube, PHYSICAL & DYNAMIC METEOROLOGY","04/15/2015","04/08/2015","Chidong Zhang","FL","University of Miami Rosenstiel School of Marine&Atmospheric Sci","Standard Grant","Eric T. DeWeaver","03/31/2017","$788,836.00","Steven Rutledge, James Moum, Robert Houze, Courtney Schumacher","czhang@rsmas.miami.edu","4600 RICKENBACKER CSWY","KEY BISCAYNE","FL","331491031","3054214089","GEO","5740, 8074, 1525","4444, 7433, OTHR","$0.00","This award supports the creation of a legacy dataset for data collected during the DYNAmics of the Madden-julian Oscillation (DYNAMO) field campaign. The goal of DYNAMO was to observe the initiation of the Madden-Julian Oscillation (MJO). The MJO is a large-scale pattern of precipitation and atmospheric circulation that forms in the Indian Ocean and propagates slowly eastward affecting weather and climate across a large portion of the globe. The campaign took place in the Indian Ocean from 1 October 2011 until 9 February 2012 and was a massive undertaking involving ships, aircraft, sounding systems, and an island-based radar ""supersite"". Several US agencies and international partners were involved, as documented in the abstract for NSF award AGS-1022899. The campaign was a success in that three MJO events occurred during the deployment, of which the first occurred during the Special Observing Period when all the field assets were deployed together. Overall about 10 terabytes of data were collected.<br/><br/>Given the success of the campaign and the large investments made in it, a further investment is warranted to enhance the accessibility of the campaign data and facilitate its used by the research community. Three categories of data products will be developed on this award, characterized by the type of instrumentation used to collect the observations: radar-based, aircraft-based, and sounding-based products. A fourth category consists of data products processed in ways consistent with specific interests of the research community, for instance sounding data processed into variables like precipitable water, convective available potential energy, convective inhibition, lifting condensation level, and the level of free convection. The entire collection will be hosted by the Earth Observing Laboratory at the National Center for Atmospheric Research.<br/><br/>This project is somewhat unusual in that the goal is to develop and serve a dataset for the research community, rather than to conducted research to address a scientific hypothesis. Thus all of the effort can be regarded as a broader impact to the research community. It should also be noted that the MJO has a number of societal consequences, as it is a dominant driver of weather in the tropics and also affects on the US. Among other impacts, the MJO influences the number of hurricanes that form in the Gulf of Mexico. Research leading to better representation of the MJO in weather forecasting models is thus desirable. In addition, the data products will facilitate research on tropical convection in general, which will be of value for developing better models to predict weather and make projections of future climate change."
"1225810","Collaborative Research: OpenTopography: A Cyberinfrastructure-Enabled Facility for High-Resolution Topographic Data and Tools","EAR","GEOINFORMATICS, EarthCube","04/01/2013","07/13/2015","J Ramon Arrowsmith","AZ","Arizona State University","Continuing grant","Russell C. Kelz","03/31/2017","$198,158.00","","ramon.arrowsmith@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","GEO","7255, 8074","7433","$0.00","1225810 <br/>Arrowsmith<br/><br/>This Geoinformatics award to Arizona State University (PI: Arrowsmith) supports a three year development project that is collaborative with the University of California, San Diego (PI: Baru). The project plan will improve upon and refine the capabilities of the OpenTopography Light Detection and Ranging (LiDAR) data services web portal that was previously jointly supported by NSF/EAR, NSF/OCI and NSF/CISE (EAR-0930731/EAR-0930643). <br/><br/>OpenTopography (OT) was designed to allow users web-based access Lidar generated high resolution topographic data sets and analysis tools in support of surface Earth process research, research training and education. This award will develop OT2, an extensible interface and platform that will allow scientists to develop and plug in functional modules, and a scalable system that will allow archive growth and computer services provided by cloud computing modalities. OT2 will expand capabilities to handle full waveform LiDAR, TLS data and bathymetric data. OT2 will continue to ingest extant airborne LiDAR and terrestrial laser scanning (TLS) data sets from numerous sources beyond airborne LiDAR and TLS data sets produced by continued and expanding use of the National Center for Airborne Laser Swath Mapping Facility (NCALM) and the UNVACO hosted TLS instrument pool. Hosted data now at OT includes also airborne LiDAR data sets flown for EarthScope science projects, Critical Zone Observatories, NOAA, US Bureau of Reclamation, USGS, Bureau of Land Management, the US Forest Service and numerous state airborne LiDAR data sets. <br/><br/>Currently, OT hosts some 200 billion LiDAR returns and thousands of pre-computed digital elevation models (DEMs) and Google Earth readable kmz files. OT management has documented high volume use of the web portal. There are over 1,500 registered users, the site gets between 5,000 and 25,000 page view per month and more than 12,000 automated job runs have accessed over 250 billion LiDAR returns. OT PIs also report that more than 35,000 pre-computed DEM tiles have been downloaded and over 70 Gb of Google Earth imagery is streamed per month. The user base is approximately 22% students, 27% academic researchers, 24% government scientists and 15% commercial sector. <br/><br/>***"
"1226353","Collaborative Research: OpenTopography: A Cyberinfrastructure-Enabled Facility for High-Resolution Topographic Data and Tools","EAR","INSTRUMENTATION & FACILITIES, GEOINFORMATICS, EarthCube","04/01/2013","04/08/2016","Viswanath Nandigam","CA","University of California-San Diego","Continuing grant","Russell C. Kelz","03/31/2017","$1,471,339.00","Viswanath Nandigam, Christopher Crosby","viswanat@sdsc.edu","Office of Contract & Grant Admin","La Jolla","CA","920930934","8585344896","GEO","1580, 7255, 8074","7433","$0.00","1226353 <br/>Baru<br/><br/>This Geoinformatics award to the University of California San Diego (PI: Baru) supports a three year development project that is collaborative with Arizona State University (PI: Arrowsmith). The project plan will improve upon and refine the capabilities of the OpenTopography Light Detection and Ranging (LiDAR) data services web portal that was previously jointly supported by NSF/EAR, NSF/OCI and NSF/CISE (EAR-0930731/EAR-0930643). <br/><br/>OpenTopography (OT) was designed to allow users web-based access Lidar generated high resolution topographic data sets and analysis tools in support of surface Earth process research, research training and education. This award will develop OT2, an extensible interface and platform that will allow scientists to develop and plug in functional modules, and a scalable system that will allow archive growth and computer services provided by cloud computing modalities. OT2 will expand capabilities to handle full waveform LiDAR, TLS data and bathymetric data. OT2 will continue to ingest extant airborne LiDAR and terrestrial laser scanning (TLS) data sets from numerous sources beyond airborne LiDAR and TLS data sets produced by continued and expanding use of the National Center for Airborne Laser Swath Mapping Facility (NCALM) and the UNVACO hosted TLS instrument pool. Hosted data now at OT includes also airborne LiDAR data sets flown for EarthScope science projects, Critical Zone Observatories, NOAA, US Bureau of Reclamation, USGS, Bureau of Land Management, the US Forest Service and numerous state airborne LiDAR data sets. <br/><br/>Currently, OT hosts some 200 billion LiDAR returns and thousands of pre-computed digital elevation models (DEMs) and Google Earth readable kmz files. OT management has documented high volume use of the web portal. There are over 1,500 registered users, the site gets between 5,000 and 25,000 page view per month and more than 12,000 automated job runs have accessed over 250 billion LiDAR returns. OT PIs also report that more than 35,000 pre-computed DEM tiles have been downloaded and over 70 Gb of Google Earth imagery is streamed per month. The user base is approximately 22% students, 27% academic researchers, 24% government scientists and 15% commercial sector. <br/><br/>***"
